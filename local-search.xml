<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Book Note: Chapter 3 Storage and Retrieval</title>
    <link href="/2023/10/20/Chapter%203%20Storage%20and%20Retrieval/"/>
    <url>/2023/10/20/Chapter%203%20Storage%20and%20Retrieval/</url>
    
    <content type="html"><![CDATA[<p>这一章主要讲的是数据库更底层的一些东西。</p><p>In order to tune a storage engine to perform well on your kind of workload, you need to have a rough idea of what the storage engine is doing under the hood.</p><h2 id="Data-Structures-That-Power-Your-Database"><a href="#Data-Structures-That-Power-Your-Database" class="headerlink" title="Data Structures That Power Your Database"></a>Data Structures That Power Your Database</h2><h3 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h3><p>Any kind of index usually slows down writes, because the index also needs to be updated every time data is written.</p><p>This is an important trade-off in storage systems: <strong>well-chosen indexes speed up read queries, but every index slows down writes.</strong></p><p>所以在默认情况下，数据库不会对所有 key 都建立索引，一般都由应用的开发者来确定。</p><h4 id="Hash-Index"><a href="#Hash-Index" class="headerlink" title="Hash Index"></a>Hash Index</h4><p>以最简单的方式实现一个 key-value store, 每次 Put 就是在数据文件后面追加，每次 Get 就依次遍历数据文件寻找对应数据。</p><p>遍历寻找数据太慢了，所以我们可以为这个简单的数据库增加索引，即在内存中维护一个 Hashmap，key 为键值对的键，value 为该键值对在数据文件中的字节偏移值。</p><p>Whenever you append a new key-value pair to the file, you also update the hash map to reflect the offset of the data you just wrote (this works both for inserting new keys and for updating existing keys).</p><p>在这种情况下，无论新增还是修改，都是在文件末尾追加。</p><p>A storage engine like Bitcask is well suited to situations where the value for each key is updated frequently.</p><p>文件太大后自然需要压缩：</p><blockquote><p>Compaction means throwing away duplicate keys in the log, and keeping only the most recent update for each key.</p></blockquote><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231020212531910.png" alt="image-20231020212531910"></p><p>我们自然地可以将整个数据文件分为一个个大小固定的文件，当一个文件写满之后，就去写下一个文件，如果文件数量过多，就可以另起一个线程去压缩合并。由于只是在生成新文件，所以压缩合并的同时也可以依旧进行查询，压缩完成后，再用新文件去替换旧文件。</p><p>在实现这个简单的 key-value store 时有几点需要注意：</p><ul><li><em>Crash recovery</em><ul><li>If the database is restarted, the in-memory hash maps are lost. Bitcask speeds up recovery by storing a snapshot of each segment’s hash map on disk, which can be loaded into memory more quickly.</li></ul></li><li><em>Partially written records</em><ul><li>The database may crash at any time, including halfway through appending a record to the log. Bitcask files include checksums, allowing such corrupted parts of the log to be detected and ignored.</li></ul></li><li><em>Concurrency control</em><ul><li>As writes are appended to the log in a strictly sequential order, a common implementation choice is to have only one writer thread.</li></ul></li></ul><p>Append-only 模式也有自己的优点：</p><ul><li>Appending and segment merging are sequential write operations, which are generally <strong>much faster than random writes</strong>, especially on magnetic spinning-disk hard drives.</li><li>Concurrency and crash recovery are <strong>much simpler</strong> if segment files are appendonly or immutable.</li><li>Merging old segments avoids the problem of data files getting fragmented over time.</li></ul><p>缺点也有：</p><ul><li>The hash table must fit in memory.</li><li>Range queries are not efficient.<ul><li>只能遍历整个 Hashmap</li></ul></li></ul><h4 id="SSTables-and-LSM-Trees"><a href="#SSTables-and-LSM-Trees" class="headerlink" title="SSTables and LSM-Trees"></a>SSTables and LSM-Trees</h4><p>我们对上文提到的数据文件做一点小小的改进：要求所有的键值对都以键来排序，这种格式就是 Sorted String Table (SSTable).</p><p>SSTable’s advantages over log segments with hash index:</p><ul><li>Merging segments is simple and efficient, even if the files are bigger than the available memory.<ul><li>合并两个有序的列表只需要 $O(n)$ 的时间复杂度</li><li>并且可以在外部使用归并排序</li></ul></li><li>In order to find a particular key in the file, you no longer need to keep an index of all the keys in memory.<ul><li>由于记录的键是有序的，我们可以每隔一定间隔记录一个，寻找某个记录时，根据它的键去遍历一个小区间就行</li><li><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231020214252490.png" alt="image-20231020214252490"></li><li>Since read requests need to scan over several key-value pairs in the requested range anyway, it is possible to group those records into a block and compress it before writing it to disk.</li></ul></li></ul><p>数据文件中的记录是有序的，在写入数据时，我们肯定不能每次直接往文件中写入，而是应该先在内存中处理，到达一定大小后再写入到文件中。</p><p>We can now make our storage engine work as follows: </p><ul><li>When a write comes in, add it to an in-memory balanced tree data structure (for example, a red-black tree). This in-memory tree is sometimes called a <em>memtable</em>.</li><li>When the memtable gets bigger than some threshold—typically a few megabytes — write it out to disk as an SSTable file. This can be done efficiently because the tree already maintains the key-value pairs sorted by key. The new SSTable file becomes the most recent segment of the database. While the SSTable is being written out to disk, writes can continue to a new memtable instance.</li><li>In order to serve a read request, first try to find the key in the memtable, then in the most recent on-disk segment, then in the next-older segment, etc.</li><li>From time to time, run a merging and compaction process in the background to combine segment files and to discard overwritten or deleted values.</li></ul><p>注意，这样只能保证单个文件内的记录是有序的，而不能在多个文件之间来保证有序性。</p><p>当数据库崩溃时，memtable 中的记录也会消失，所以我们可以在磁盘上维护一个日志，用来记录这个 memtable 的写入情况。</p><p>这种算法即是 LSM-Tree 的原型。</p><p>The LSM-tree algorithm can be slow when looking up keys that do not exist in the database. In order to optimize this kind of access, storage engines often use additional Bloom filters.</p><p>There are also different strategies to determine the order and timing of how SSTables are compacted and merged. The most common options are size-tiered and leveled compaction.</p><p>Because the disk writes are sequential the LSM-tree can support remarkably high write throughput.</p><h3 id="B-Trees"><a href="#B-Trees" class="headerlink" title="B-Trees"></a>B-Trees</h3><p>The most widely used indexing structure is quite different: the B-tree.</p><p>By contrast, B-trees break the database down into fixed-size blocks or pages, traditionally 4 KB in size (sometimes bigger), and read or write one page at a time.</p><p>In order to make the database resilient to crashes, it is common for B-tree implementations to include an additional data structure on disk: a write-ahead log (WAL, also known as a redo log). This is an append-only file to which <strong>every B-tree modification must be written before it can be applied to the pages</strong> of the tree itself. When the database comes back up after a crash, this log is used to restore the B-tree back to a consistent state.</p><h3 id="Comparing-B-Trees-and-LSM-Trees"><a href="#Comparing-B-Trees-and-LSM-Trees" class="headerlink" title="Comparing B-Trees and LSM-Trees"></a>Comparing B-Trees and LSM-Trees</h3><p>As a rule of thumb, <strong>LSM-trees are typically faster for writes, whereas B-trees are thought to be faster for reads</strong>.<br>Reads are typically slower on LSM-trees because they have to check several different data structures and SSTables at different stages of compaction.</p><h4 id="Advantages-of-LSM-trees"><a href="#Advantages-of-LSM-trees" class="headerlink" title="Advantages of LSM-trees"></a>Advantages of LSM-trees</h4><p>A B-tree index must write every piece of data at least twice: once to the write-ahead log, and once to the tree page itself (and perhaps again as pages are split).</p><p>Log-structured indexes also rewrite data multiple times due to repeated compaction and merging of SSTables. This effect — one write to the database resulting in multiple writes to the disk over the course of the database’s lifetime — is known as <em>write amplification</em>. It is of particular concern on SSDs, which can only overwrite blocks a limited number of times before wearing out.</p><p>Moreover, LSM-trees are typically able to sustain higher write throughput than B-trees, partly because they sometimes have <strong>lower write amplification</strong>, and partly because they <strong>sequentially write</strong> compact SSTable files rather than having to overwrite several pages in the tree.</p><p>Since LSM-trees are not page-oriented and periodically rewrite SSTables to remove fragmentation, they have lower storage overheads, especially when using leveled compaction</p><h4 id="Downsides-of-LSM-trees"><a href="#Downsides-of-LSM-trees" class="headerlink" title="Downsides of LSM-trees"></a>Downsides of LSM-trees</h4><p>A downside of log-structured storage is that the compaction process can sometimes interfere with the performance of ongoing reads and writes.</p><p>The impact on throughput and average response time is usually small, but at higher percentiles the response time of queries to log-structured storage engines can sometimes be quite high, and B-trees can be more predictable.</p><p>If write throughput is high and compaction is not configured carefully, it can happen that compaction cannot keep up with the rate of incoming writes. In this case, the number of unmerged segments on disk keeps growing until you run out of disk space, and reads also slow down because they need to check more segment files.</p><h3 id="Keeping-everything-in-memory"><a href="#Keeping-everything-in-memory" class="headerlink" title="Keeping everything in memory"></a>Keeping everything in memory</h3><p>Counterintuitively, the performance advantage of in-memory databases is not due to the fact that they don’t need to read from disk. Even a disk-based storage engine may never need to read from disk if you have enough memory, because the operating system caches recently used disk blocks in memory anyway. Rather, they can be faster because they can <strong>avoid the overheads of encoding in-memory data structures in a form that can be written to disk.</strong></p><p>Besides performance, another interesting area for in-memory databases is providing data models that are difficult to implement with disk-based indexes. For example, Redis offers a database-like interface to various data structures such as priority queues and sets. Because it keeps all data in memory, its implementation is comparatively simple.</p><h2 id="Transaction-Processing-or-Analytics"><a href="#Transaction-Processing-or-Analytics" class="headerlink" title="Transaction Processing or Analytics?"></a>Transaction Processing or Analytics?</h2><p>这一节也很有意思，数据库大体上可以分为两种用途：transaction processing and data analytics.</p><blockquote><p>Transaction processing just means allowing clients to make low-latency reads and writesas opposed to batch processing jobs, which only run periodically (for example, once per day).</p></blockquote><p>An application typically looks up a small number of records by some key, using an index. Records are inserted or updated based on the user’s input. Because these applications are interactive, the access pattern became known as online transaction processing (OLTP).</p><p>However, databases also started being increasingly used for data analytics, which has very different access patterns. Usually an analytic query needs to scan over a huge number of records, only reading a few columns per record, and calculates aggregate statistics (such as count, sum, or average) rather than returning the raw data to the user.</p><p>In order to differentiate this pattern of using databases from transaction processing, it has been called online analytic processing (OLAP).</p><p>两者还是有很大不同的：</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231020221030359.png" alt="image-20231020221030359"></p><h3 id="Data-Warehousing"><a href="#Data-Warehousing" class="headerlink" title="Data Warehousing"></a>Data Warehousing</h3><p>专门针对数据分析的数据库被叫做数据仓库。</p><p>A data warehouse, by contrast, is a separate database that analysts can query to their hearts’ content, without affecting OLTP operations. The data warehouse contains a read-only copy of the data in all the various OLTP systems in the company.</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231020221221532.png" alt="image-20231020221221532"></p><p>Many data warehouses are used in a fairly formulaic style, known as a star schema (also known as dimensional modeling).</p><p>Example:</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231020221306520.png" alt="image-20231020221306520"></p><p>As each row in the fact table represents an event, the dimensions represent the <em>who</em>, <em>what</em>, <em>where</em>, <em>when</em>, <em>how</em>, and <em>why</em> of the event.</p><p>The name “star schema” comes from the fact that when the table relationships are visualized, the fact table is in the middle, surrounded by its dimension tables; the connections to these tables are like the rays of a star.</p><h3 id="Column-Oriented-Storage"><a href="#Column-Oriented-Storage" class="headerlink" title="Column-Oriented Storage"></a>Column-Oriented Storage</h3><p>数据仓库存储的数据有以下特点：</p><ul><li>数量多</li><li>Fact table 的列非常多</li></ul><p>查询的特点是：</p><ul><li>查询所有数据</li><li>只访问其中的几列</li></ul><p>In most OLTP databases, storage is laid out in a row-oriented fashion: all the values from one row of a table are stored next to each other. Document databases are similar: an entire document is typically stored as one contiguous sequence of bytes.</p><p>The idea behind column-oriented storage is simple: don’t store all the values from one row together, but store all the values from each column together instead. If each column is stored in a separate file, a query only needs to read and parse those columns that are used in that query, which can save a lot of work.</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231020222218346.png" alt="image-20231020222218346"></p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>There are big differences between the access patterns in those use cases:</p><ul><li>OLTP systems are typically user-facing, which means that they may see a huge volume of requests. In order to handle the load, applications usually only touch a small number of records in each query. The application requests records using some kind of key, and the storage engine uses an index to find the data for the requested key. Disk seek time is often the bottleneck here.</li><li>Data warehouses and similar analytic systems are less well known, because they are primarily used by business analysts, not by end users. They handle a much lower volume of queries than OLTP systems, but each query is typically very demanding, requiring many millions of records to be scanned in a short time. Disk bandwidth (not seek time) is often the bottleneck here, and columnoriented storage is an increasingly popular solution for this kind of workload.</li></ul>]]></content>
    
    
    <categories>
      
      <category>Design Data-Intensive Applications</category>
      
    </categories>
    
    
    <tags>
      
      <tag>BookNote</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Book Note: Chapter 2 Data Models and Query Languages</title>
    <link href="/2023/10/20/Chapter%202%20Data%20Models%20and%20Query%20Languages/"/>
    <url>/2023/10/20/Chapter%202%20Data%20Models%20and%20Query%20Languages/</url>
    
    <content type="html"><![CDATA[<h2 id="Relational-Model-Versus-Document-Model"><a href="#Relational-Model-Versus-Document-Model" class="headerlink" title="Relational Model Versus Document Model"></a>Relational Model Versus Document Model</h2><p>首先谈到了 NoSQL 的诞生：</p><p>There are several driving forces behind the adoption of NoSQL databases, including: </p><ul><li>A need for greater scalability than relational databases can easily achieve, includ‐ ing very large datasets or very high write throughput</li><li>A widespread preference for free and open source software over commercial database products</li><li>Specialized query operations that are not well supported by the relational model</li><li>Frustration with the restrictiveness of relational schemas, and a desire for a more dynamic and expressive data model</li></ul><p>然后通过下图的这份简历来说明了 one-to-many 这种关系</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231019222823030.png" alt="image-20231019222823030"></p><p>One-to-many 关系在关系数据库中可以有许多种表达方式：</p><ul><li>通过正则化将 “many” 放入其他表中</li><li>Later versions of the SQL standard added support for structured datatypes and XML data; this allowed multi-valued data to be stored within a single row, with support for querying and indexing inside those documents.</li><li>将 “many” 的信息先编码为 JSON 或者 XML，直接存入到数据库中的一个文本列中，缺点是无法利用数据库进行查询</li></ul><p>如果把简历表示为 JSON 数据的话：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;user_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">251</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;first_name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Bill&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;last_name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Gates&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;summary&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Co-chair of the Bill &amp; Melinda Gates... Active blogger.&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;region_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;us:91&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;industry_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">131</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;photo_url&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;/p/7/000/253/05b/308dd6e.jpg&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;positions&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;job_title&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Co-chair&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;organization&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Bill &amp; Melinda Gates Foundation&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;job_title&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Co-founder, Chairman&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;organization&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Microsoft&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;education&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;school_name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Harvard University&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;start&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1973</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;end&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1975</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;school_name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Lakeside School, Seattle&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;start&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">null</span></span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;end&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">null</span></span><br>        <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;contact_info&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;blog&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;http://thegatesnotes.com&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;twitter&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;http://twitter.com/BillGates&quot;</span><br>    <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>The lack of a schema is often cited as an advantage. The JSON representation has better <strong>locality</strong> than the multi-table schema in Figure 2-1. If you want to fetch a profile in the relational example, you need to either perform multiple queries (query each table by user_id) or perform a messy multi- way join between the users table and its subordinate tables. In the JSON representa‐ tion, all the relevant information is in one place, and one query is sufficient.</p><p>然后本章谈到了第三种关系，也是最难处理的一种关系：many-to-one.</p><p>In relational databases, it’s normal to refer to rows in other tables by ID, because joins are easy. In document databases, joins are not needed for one-to-many tree structures, and support for joins is often weak.</p><p>one-to-many 是一个树的结构，从某种意义上来说，它是自洽的，每个子节点都只属于一个父节点，此时用 document database 就是比较容易的,而 many-to-one 则必须通过 join 来获得完整信息。</p><p>Document database 虽然在最近十多年才开始兴起，其实从历史的角度来说，它才是最早数据库的模样：</p><ul><li>IMS 系统的数据模型是一个简单的层次模型，one-to-one 和 one-to-many 都能支持得很好，但无法支持 many-to-many</li><li>为了解决层次模型的缺陷，有两种方案被提了出来：relational model 和 network model<ul><li>network model 有点像现在的 graph model，但要原始得多，书上也专门花了一些篇幅来说明两者的不一样</li></ul></li></ul><p>However, when it comes to representing many-to-one and many-to-many relation‐ ships, relational and document databases are not fundamentally different: in both cases, the related item is referenced by a unique identifier, which is called a foreign key in the relational model and a document reference in the document model. That identifier is resolved at read time by using a join or follow-up queries.</p><h2 id="relational-versus-document-database"><a href="#relational-versus-document-database" class="headerlink" title="relational versus document database"></a>relational versus document database</h2><p>The main arguments in favor of the document data model are <strong>schema flexibility, better performance due to locality</strong>, and that for some applications it <strong>is closer to the data structures</strong> used by the application. The relational model counters by providing <strong>better support for joins, and many-to-one and many-to-many relationships</strong>.</p><p>这其实就体现了两种类型的数据库的使用范围的不同，书中先谈到了 document database 的缺陷：</p><p>The document model has limitations: for example, you cannot refer directly to a nested item within a document, but instead you need to say something like “the second item in the list of positions for user 251” (much like an access path in the hierarchical model). However, as long as documents are not too deeply nested, that is not usually a problem.</p><p>However, if your application does use many-to-many relationships, the document model becomes less appealing. It’s possible to reduce the need for joins by denormal‐ izing, but then the application code needs to do additional work to keep the denor‐ malized data consistent.</p><blockquote><p>[!summary]<br>Denormalizing means more efforts to keep data consistent.</p></blockquote><p>再谈到了它的优点：</p><p><strong>Schema Flexibility</strong></p><p>Document databases are sometimes called schemaless, but that’s misleading, as the code that reads the data usually assumes some kind of structure—i.e., there is an implicit schema, but it is not enforced by the database. A more accurate term is schema-on-read (the structure of the data is implicit, and only interpreted when the data is read), in contrast with schema-on-write (the traditional approach of relational databases, where the schema is explicit and the database ensures all written data con‐ forms to it).</p><p>The schema-on-read approach is advantageous if the items in the collection don’t all have the same structure for some reason (i.e., the data is heterogeneous) for example, because there are many different types of objects, and it is not practical to put each type of object in its own table.</p><p>Schema-on-read 和 schema-on-write 的说法我是第一次遇见，挺有意思的，和编程语言中的静态检查以及动态检查非常类似。</p><p><strong>Data locality for queries</strong></p><p>A document is usually stored as a single continuous string, encoded as JSON, XML, or a binary variant thereof (such as MongoDB’s BSON). If your application often needs to access the entire document (for example, to render it on a web page), there is a performance advantage to this storage locality.</p><p>Locality 带来了好处，也带来了坏处：<strong>读必须一起读，写必须一起写</strong></p><p>The locality advantage only applies if you need large parts of the document at the same time. The database typically needs to load the entire document, even if you access only a small portion of it, which can be wasteful on large documents. On updates to a document, the entire document usually needs to be rewritten—only modifications that don’t change the encoded size of a document can easily be per‐ formed in place. For these reasons, it is generally recommended that you keep documents fairly small and avoid writes that increase the size of a document.</p><p>最后谈到了两种不同数据库都在往对方的领域发展：</p><p>On the document database side, RethinkDB supports relational-like joins in its query language, and some MongoDB drivers automatically resolve database references (effectively performing a client-side join, although this is likely to be slower than a join performed in the database since it requires additional network round-trips and is less optimized).</p><h2 id="Query-Languages-for-Data"><a href="#Query-Languages-for-Data" class="headerlink" title="Query Languages for Data"></a>Query Languages for Data</h2><p>这里首先谈到了编写代码的两种方式：</p><p>Let’s generalize and say that there are two ways in which we can write code: imperative and declarative. We could define the difference as follows:</p><ul><li><strong>Imperative programming</strong>: telling the “machine” <em>how</em> to do something, and as a result <em>what</em> you want to happen will happen.</li><li><strong>Declarative programming</strong>: telling the “machine” <em>what</em> you would like to happen, and let the computer figure out <em>how</em> to do it.</li></ul><p>具体的可以查看 [[Imperative vs Declarative]]</p><p>A declarative query language is attractive because it is typically more concise and easier to work with than an imperative API. But more importantly, it also hides implementation details of the database engine, which makes it possible for the database system to introduce performance improvements without requiring any changes to queries.</p><p>The fact that SQL is more limited in functionality gives the database much more room for automatic optimizations.</p><p>Imperative code is very hard to parallelize across multiple cores and multiple machines, because it specifies instructions that must be performed in a particular order. Declarative languages have a better chance of getting faster in parallel execution because they specify only the pattern of the results, not the algorithm that is used to determine the results. The database is free to use a parallel implementation of the query language, if appropriate.</p><p>这一段也说明了声明式代码的优点：</p><ul><li>精确简单</li><li>隐藏了具体的实现细节，方便系统自动优化<ul><li>A declarative query language offers more opportunities for a query optimizer to improve the performance of a query.</li></ul></li><li>性能更好</li></ul><h3 id="MapReduce-Querying"><a href="#MapReduce-Querying" class="headerlink" title="MapReduce Querying"></a>MapReduce Querying</h3><p>MapReduce is neither a declarative query language nor a fully imperative query API, but somewhere in between: the logic of the query is expressed with snippets of code, which are called repeatedly by the processing framework. It is based on the map (also known as collect) and reduce (also known as fold or inject) functions that exist in many functional programming languages.</p><p>The map and reduce functions are somewhat restricted in what they are allowed to do. They must be pure functions, which means <strong>they only use the data that is passed to them as input, they cannot perform additional database queries, and they must not have any side effects.</strong> These restrictions allow the database to run the functions anywhere, in any order, and rerun them on failure.</p><p>MapReduce is a fairly low-level programming model for distributed execution on a cluster of machines. Higher-level query languages like SQL can be implemented as a pipeline of MapReduce operations.</p><h2 id="Graph-Like-Data-Models"><a href="#Graph-Like-Data-Models" class="headerlink" title="Graph-Like Data Models"></a>Graph-Like Data Models</h2><p>如果 many-to-many 关系在你的数据中非常常见，你可能就要考虑使用 graph-like data model 了。</p><p>The relational model can handle simple cases of many-to-many relationships, but as the connections within your data become more complex, it becomes more natural to start modeling your data as a graph.</p><p>Graphs are good for evolvability: as you add features to your application, a graph can easily be extended to accommodate changes in your application’s data structures.</p><p>后文说了两种不同的图模型：</p><ul><li>property graph model</li><li>triple-store model</li></ul><p>以及三种图模型中的声明式查询语言</p><p>由于不是经常用到图模型，后面的内容也就简单看了看，有需要时再倒回来看看。</p>]]></content>
    
    
    <categories>
      
      <category>Design Data-Intensive Applications</category>
      
    </categories>
    
    
    <tags>
      
      <tag>BookNote</tag>
      
      <tag>Design Data-Intensive Applications</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2023/10/20/hello-world/"/>
    <url>/2023/10/20/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
