<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Transaction Anomalies</title>
    <link href="/2024/03/31/Talks/transaction-anomalies/"/>
    <url>/2024/03/31/Talks/transaction-anomalies/</url>
    
    <content type="html"><![CDATA[<h2 id="Non-Repeatable-Read">Non-Repeatable Read</h2><p>A non-repeatable read occurs, when during the course of a transaction, a row is retrieved twice and the values within the row differ between reads.</p><h2 id="Phantom-Read">Phantom Read</h2><p>A phantom read occurs when, in the course of a transaction, two identical queries are executed, and the collection of rows returned by the second query is different from the first.</p><h2 id="Read-Skew">Read Skew</h2><p>Read skew is that with two different queries, a transaction reads inconsistent data because between the 1st and 2nd queries, other transactions insert, update or delete data and commit. Finally, an inconsistent result is produced by the inconsistent data.</p><h2 id="Non-Repeatable-Read-vs-Phantom-Read">Non-Repeatable Read vs Phantom Read</h2><p>Non-repeatable reads are when your transaction reads committed <strong>UPDATES</strong> from another transaction. <strong>The same row now has different values</strong> than it did when your transaction began.</p><p>Phantom reads are similar but when reading from committed <strong>INSERTS</strong> and/or <strong>DELETES</strong> from another transaction. <strong>There are new rows or rows that have disappeared</strong> since you began the transaction.</p><blockquote><ul><li>不可重复读：两次相同的查询前后<strong>同一条记录</strong>的值不同。</li><li>幻读：两次相同的查询前后<strong>同一个范围内</strong>的记录数量不同。</li></ul></blockquote><h2 id="Non-Repeatable-Read-vs-Read-Skew">Non-Repeatable Read vs Read Skew</h2><p>We have two data - let x and y, and there is a relation between them.(e.g parent/child)</p><p>Transaction T1 reads x, and then a second transaction T2 updates x and y to new values and commits. If now T1 reads y, it may see an inconsistent state, and therefore produce an inconsistent state as output.</p><p>Acceptable consistent states:</p><ul><li>x and y</li><li>*x and *y</li></ul><blockquote><p>Note: * denotes the updated value of the variable</p></blockquote><p>When x and y are the same data, it leads to the problem of non-repeatable.</p><blockquote><p>We may call read skew is a generalization form of a non-repeatable problem.</p></blockquote><h2 id="Lost-Updates">Lost Updates</h2><p>由于未提交事务之间看不到对方的修改，因此都以一个旧前提去更新同一个数据，导致最后的提交结果是错误值。</p><p>假设有支付宝账户X，余额100元，事务A、B同时向X分别充值10元、20元，最后结果应该为130元，但是由于丢失更新，最后是110元。</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20240331173155756.png" alt="image-20240331173155756"></p><h2 id="Write-Skew">Write Skew</h2><p>当前事务之间看不到并发事务对数据的修改，以一个旧前提去更新数据，最后导致了数据状态的不一致。</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231027212947963.png" alt="image-20240331173155756"></p><h2 id="Lost-Updates-vs-Write-Skew">Lost Updates vs Write Skew</h2><p>丢失更新与写偏斜很相似，都是由于写前提被改变，他们区别是:</p><ul><li>丢失更新是在同一个数据的最终不一致。</li><li>写偏斜的冲突不在同一个数据，在不同数据中的最终不一致。</li></ul>]]></content>
    
    
    <categories>
      
      <category>Transactions</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Talk</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Paper Note: Taking Omid to the Clouds: Fast, Scalable Transactions for Real-Time Cloud Analytics</title>
    <link href="/2024/03/25/Papers/Distributed%20Transactions/taking-omid-to-the-clouds/"/>
    <url>/2024/03/25/Papers/Distributed%20Transactions/taking-omid-to-the-clouds/</url>
    
    <content type="html"><![CDATA[<p>Designing a TPS for clouds will meet these challenges:</p><ul><li><strong>Diverse functionality</strong>.<ul><li>The concept of <em>translytics</em> as “a unified and integrated data platform that supports multi-workloads such as transactional, operational, and analytical simultaneously in realtime, … and ensures full transactional integrity and data consistency”.</li></ul></li><li><strong>Scale</strong><ul><li>Cloud-first data platforms are designed to scale well beyond the limits of a single application.</li></ul></li><li><strong>Latency</strong><ul><li>With the thrust into new interactive domains like social networks, messaging and algorithmic trading,latency becomes essential.</li></ul></li><li><strong>Multi-tenancy</strong><ul><li>Maintaining access rights is therefore an important design consideration for TPSs.</li></ul></li></ul><p>论文的工作集中于以下几点：</p><ul><li>重新设计了一个 Omid Low Latency (Omid LL) 协议，解决了 Omid2 中的性能瓶颈。</li><li>对只涉及到单个记录的事务设计了一套新算法，Omid Fast Path (Omid FP)，能以原生 HBase 的性能运行单个记录的事务。</li><li>为 Omid 增加了 SQL 支持。</li></ul><h2 id="Omid-Low-Latency">Omid Low Latency</h2><p>下表列出来相近的几个分布式事务协议在设计上的不同选择。</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20240325171927065.png" alt="image-20240325171927065"></p><p>这里解释一下<em>提交条目（Commit Entry）</em>：</p><p>所有的事务实现本质上都体现了 <em><strong>downscale</strong></em> 的思想，将某个原子操作降级为对更小 scope（或临界区）的原子操作：</p><ul><li>分布式事务可以利用中心节点，降级为中心节点状态的单机事务。</li><li>单机事务可以降级为某个mutex的原子操作。</li><li>mutex的原子操作可以降级为一次CAS操作。</li></ul><p>执行这个原子操作的时间节点可以称为<em><strong>状态同步点</strong></em>，在此时间节点之前，事务的状态为 Pending，在此时间节点之后，该事务<strong>对外界的可见性</strong>要么为 Commit 要么为 Abort。</p><p>在 Omid 中，提交条目的更新时间点就为这个事务的状态同步点。</p><p>“Commit Entry Updates” 这一栏就是在说明提交条目的存在形式。</p><p>Omid LL 采用了：</p><ul><li><strong>Centralized validation</strong>: 集中式的验证（在TM里集中进行冲突检测）避免了在数据存储中使用悲观锁，并且拥有良好的可扩展性。（在Omid 2017中已经得到验证）</li><li><strong>Distributed commit entry updates with multi-tenancy</strong>:<ul><li>Omid 2014 将提交条目复制到客户端中，显然在消耗高带宽的同时失去了更好的扩展性；为了降低 TM 写入的性能瓶颈，Omid 2014 以批量写入的方式增加吞吐量，同时也提高了延迟。</li><li>Omid 2017 中，低延时是工作的一个重要目标。工作将写入提交条目的操作均分到了客户端上。</li></ul></li><li><strong>Write intent resolution</strong>: 这涉及到的决策是：在执行事务读操作时，如果读到了一个事务状态不确定的记录，本事务是选择等待还是中止事务。Omid LL 选择了 “reads to force aborts”。</li></ul><p>OMid LL 的提交操作也分为两个阶段：</p><ol><li>客户端向 TM 发送写集和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><msub><mi>s</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">ts_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7651em;vertical-align:-0.15em;"></span><span class="mord mathnormal">t</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，等待 TM 进行决策。如果结果为通过，则客户端向 CT(Commit Table) 中写入一条记录（同时检查自己是否被其他事务中止了），写入成功则代表提交操作成功。</li><li>对于写集中的记录，事务将其 commit 字段修改为自身的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><msub><mi>s</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">ts_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7651em;vertical-align:-0.15em;"></span><span class="mord mathnormal">t</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>；全部完成后删除 CT 中的记录。</li></ol><p>高可用部分，Omid LL 使用了主从两个进程，并使用 epoch 来分块划分时间戳，保证后任 TM 所分配的时间戳一定大于前任 TM，并使用了一个 “locally-checkable lease” 来确保 “no client will be able to commit a transaction in an old epoch after the new TM has started using a new one”。</p><h2 id="Omid-Fast-Path">Omid Fast Path</h2><blockquote><p>The goal of our fast path is to forgo the overhead associated with communicating with the TM to begin and commit transactions.</p></blockquote><p>FP的优化策略聚焦于单键值的事务：</p><ul><li><code>brc(key)</code>：开启事务，读最新已提交的版本。<ul><li>可能会忽略掉正在进行 post-commit 的事务，但论文中说这种行为是符合 FP 语义的。</li></ul></li><li><code>bwc(key, val)</code>：直接写入一个新版本，要求其 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><msub><mi>s</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">ts_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7651em;vertical-align:-0.15em;"></span><span class="mord mathnormal">t</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 大于已有版本。</li><li><code>br(key)</code>：开启事务，读最新已提交的版本。</li><li><code>wc(ver, key, val)</code>： 验证自返回 ver 的 br 调用以来未对 key 进行写操作，将 val 写入 key 的新版本，并提交。</li></ul><p><code>bwc</code> 和 <code>wc</code>操作需要产生一个新版本，需要保证以下性质</p><ul><li>新 version 大于所有旧 version，但小于未来 TM 产生的 version。</li><li>能检测出与普通事务的冲突。</li></ul><p>为了在不访问 TM 的情况下产生一个新版本，Omid FP 采用了 HLC（Hybrid Logical Clock）。</p><blockquote><p>What is HLC?</p><p>An HLC timestamp typically includes two parts:</p><ol><li>A physical component which is assigned by the TM.</li><li>A logical component that behaves like a locally advancing sequence number.</li></ol></blockquote><p>在 FP 中改变版本时只增加 logical ts 即可（通过 <code>putVersion</code> 函数）。</p><p>现在考虑 FP 事务与普通事务写操作的冲突检测：</p><ul><li>如果普通事务早于 FP 事务写入，FP 事务会 abort。（如果 FP 事务在写入时发现存在一个暂时的版本，就会直接 abort）。</li><li>如果 FP 事务在某个普通事务的读和提交之间完成了，如下图：</li></ul><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20240325202221348.png" alt="image-20240325202221348"></p><p>FP 事务并没有记录在 CT 中，旧的检测机制失效了。为了能让T1提交时检测出冲突，Omid FP做了以下改动：</p><ul><li>每个 key 对应一个 maxVersion，保证 maxVersion <strong>大于等于</strong>这个 key 的任何已提交版本。</li><li><code>putVersion</code> 会提升 maxVersion。</li><li>普通事务的读会提升 maxVersion 到<strong>不小于</strong>事务的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><msub><mi>s</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">ts_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7651em;vertical-align:-0.15em;"></span><span class="mord mathnormal">t</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。</li><li>普通事务的写会检查 maxVersion <strong>不大于</strong>事务的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><msub><mi>s</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">ts_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7651em;vertical-align:-0.15em;"></span><span class="mord mathnormal">t</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，检查未通过说明有 FP 事务与它发生了写冲突。</li></ul><p>这个改动增加了普通路径的开销，为每个记录都维护一个 maxVersion 字段开销非常大，所以 OMid 在每个 HBase 的 region server 上维护一个 Local Version Clock (LVC)，作为该区域所有记录的 maxVersion，以增加 false abortion 的代价降低了性能开销：“a transactional read modifies the LVC only if its tsr exceeds it”。</p>]]></content>
    
    
    <categories>
      
      <category>Distributed</category>
      
      <category>Transactions</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PaperNote</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Paper Note: Omid, Reloaded: Scalable and Highly-Available Transaction Processing</title>
    <link href="/2024/03/22/Papers/Distributed%20Transactions/omid-reloaded/"/>
    <url>/2024/03/22/Papers/Distributed%20Transactions/omid-reloaded/</url>
    
    <content type="html"><![CDATA[<p>An entirely re-designed version of Omid1.</p><p>Omid’s job is to manage the transaction control plane.</p><p>The transaction metadata includes:</p><ul><li>A dedicated table(Commit Tabla, CT) holds a single record per committing transaction.</li><li>Per-row metadata for items accessed by transactions.</li></ul><p>Feature: A middleware oriented.</p><p>Snapshot isolate should provide:</p><ul><li>Visibility check rules.</li><li>Write conflicts detection.</li></ul><h3 id="Visibility-Check-Rules">Visibility Check Rules</h3><blockquote><p>Intuitively, with SI, a transaction’s reads all appear to occur the time when it begins(<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><msub><mi>s</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">ts_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7651em;vertical-align:-0.15em;"></span><span class="mord mathnormal">t</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>)<br>while its writes appear to execute when it commits(<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><msub><mi>s</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">ts_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7651em;vertical-align:-0.15em;"></span><span class="mord mathnormal">t</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>).</p></blockquote><p>Omid uses <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>x</mi><mi>i</mi><mi>d</mi></mrow><annotation encoding="application/x-tex">txid</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">x</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span></span></span></span> as the version number.</p><p><strong>To commit a transaction, the TM writes the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>t</mi><mi>x</mi><mi>i</mi><mi>d</mi><mo separator="true">,</mo><mi>t</mi><msub><mi>s</mi><mi>c</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(txid,ts_c)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mord mathnormal">x</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">t</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> pair to Commit Table(CT), which makes the transaction durable, and is considered its commit point.</strong></p><p>When running visibility checks, client get <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow><annotation encoding="application/x-tex">version</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal">ers</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>f</mi></mrow><annotation encoding="application/x-tex">cf</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span> directly from the data table:</p><ul><li>version is just the txid.</li><li>cf is the corresponding time when the transaction commits.</li></ul><p><strong>Following a commit, the transaction updates the commit fields of its written data items with its <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><msub><mi>s</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">ts_c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7651em;vertical-align:-0.15em;"></span><span class="mord mathnormal">t</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, and then removes itself from the CT.</strong></p><h3 id="Write-Conflict-Detection">Write Conflict Detection</h3><p>This is done by the TM(Transaction Manager).</p><p>When a transaction wants to commit, it sends its txid and write set to TM.<br>TM runs a <code>CONFLICTDETECT</code> function which checks for conflicts using a hash table in main memory.</p><p>Here comes two problems:</p><ul><li>Find and replace operation needs to be atomic, but locking the whole table will severely limit concurrency.<ul><li>The paper limits the granularity of atomicity to a single bucket.</li></ul></li><li>The table may be too big to fit in the main memory.<ul><li>Each bucket holds a <strong>fixed</strong> array of the most recent pairs. Like Omid1, reduce the table size while increasing the possibility of false aborts.</li></ul></li></ul><h3 id="High-Availablity">High Availablity</h3><p>This is achieved via the primary-backup paradigm: during normal operation, a single primary TM handles client requests, while a backup TM runs in hot standby mode.<br>Upon detecting the primary’s failure, the backup performs a failover and becomes the new primary.</p>]]></content>
    
    
    <categories>
      
      <category>Distributed</category>
      
      <category>Transactions</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PaperNote</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Rust Learning Note</title>
    <link href="/2024/02/10/learning/Explore_Rust/"/>
    <url>/2024/02/10/learning/Explore_Rust/</url>
    
    <content type="html"><![CDATA[<h1>Explore Rust</h1><h2 id="Chapter-3-Types">Chapter 3 Types</h2><h3 id="Arrays">Arrays</h3><p>不支持动态开数组：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-comment">// an array of 100 int32 elements, all set to 1</span><br><span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">arr1</span> = [<span class="hljs-number">1</span>;<span class="hljs-number">100</span>]; <span class="hljs-comment">// correct</span><br><span class="hljs-keyword">let</span> <span class="hljs-variable">n</span> = <span class="hljs-number">100</span>;<br><span class="hljs-keyword">let</span> <span class="hljs-variable">mur</span> arr2 = [<span class="hljs-number">1</span>;c]; <span class="hljs-comment">// error</span><br></code></pre></td></tr></table></figure><h3 id="Vectors">Vectors</h3><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">arr</span> = <span class="hljs-built_in">vec!</span>[<span class="hljs-number">0</span>,<span class="hljs-number">6</span>,<span class="hljs-number">4</span>,<span class="hljs-number">8</span>,<span class="hljs-number">1</span>];<br>arr.<span class="hljs-title function_ invoke__">sort</span>() <span class="hljs-comment">// increasing order</span><br>arr.<span class="hljs-title function_ invoke__">sort_by</span>(|a,b| b.<span class="hljs-title function_ invoke__">cmp</span>(a)) <span class="hljs-comment">// decreasing order</span><br></code></pre></td></tr></table></figure><p>If you know the number of elements a vector will need in advance, instead of <code>Vec::new</code> you can call <code>Vec::with_capacity</code> to create a vector with a buffer large enough to hold them all, right from the start.</p><h3 id="String">String</h3><p>A String or &amp;str’s .len() method returns its length. The length is measured in bytes, not characters:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-built_in">assert_eq!</span>(<span class="hljs-string">&quot;ಠ_ಠ&quot;</span>.<span class="hljs-title function_ invoke__">len</span>(), <span class="hljs-number">7</span>); <br><span class="hljs-built_in">assert_eq!</span>(<span class="hljs-string">&quot;ಠ_ಠ&quot;</span>.<span class="hljs-title function_ invoke__">chars</span>().<span class="hljs-title function_ invoke__">count</span>(), <span class="hljs-number">3</span>);<br></code></pre></td></tr></table></figure><h3 id="Type-Aliases">Type Aliases</h3><p>The type keyword can be used like typedef in C++ to declare a new name for an existing type:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">type</span> <span class="hljs-title class_">Bytes</span> = <span class="hljs-type">Vec</span>&lt;<span class="hljs-type">u8</span>&gt;;<br></code></pre></td></tr></table></figure><h2 id="Chapter-4-Ownership">Chapter 4 Ownership</h2><h3 id="Moves">Moves</h3><p>What if you really do want to move an element out of a vector? You need to find a method that does so in a way that respects the limitations of the type. Here are three possibilities:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-comment">// Build a vector of the strings &quot;101&quot;, &quot;102&quot;, ... &quot;105&quot; </span><br><span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">v</span> = <span class="hljs-type">Vec</span>::<span class="hljs-title function_ invoke__">new</span>(); <br><span class="hljs-keyword">for</span> <span class="hljs-variable">i</span> <span class="hljs-keyword">in</span> <span class="hljs-number">101</span> .. <span class="hljs-number">106</span> &#123; v.<span class="hljs-title function_ invoke__">push</span>(i.<span class="hljs-title function_ invoke__">to_string</span>()); &#125; <br><br><span class="hljs-comment">// 1. Pop a value off the end of the vector: </span><br><span class="hljs-keyword">let</span> <span class="hljs-variable">fifth</span> = v.<span class="hljs-title function_ invoke__">pop</span>().<span class="hljs-title function_ invoke__">expect</span>(<span class="hljs-string">&quot;vector empty!&quot;</span>); <br><span class="hljs-built_in">assert_eq!</span>(fifth, <span class="hljs-string">&quot;105&quot;</span>); <br><br><span class="hljs-comment">// 2. Move a value out of a given index in the vector, </span><br><span class="hljs-comment">// and move the last element into its spot: </span><br><span class="hljs-keyword">let</span> <span class="hljs-variable">second</span> = v.<span class="hljs-title function_ invoke__">swap_remove</span>(<span class="hljs-number">1</span>); <br><span class="hljs-built_in">assert_eq!</span>(second, <span class="hljs-string">&quot;102&quot;</span>); <br><br><span class="hljs-comment">// 3. Swap in another value for the one we&#x27;re taking out: </span><br><span class="hljs-keyword">let</span> <span class="hljs-variable">third</span> = std::mem::<span class="hljs-title function_ invoke__">replace</span>(&amp;<span class="hljs-keyword">mut</span> v[<span class="hljs-number">2</span>], <span class="hljs-string">&quot;substitute&quot;</span>.<span class="hljs-title function_ invoke__">to_string</span>()); <br><span class="hljs-built_in">assert_eq!</span>(third, <span class="hljs-string">&quot;103&quot;</span>); <br><br><span class="hljs-comment">// Let&#x27;s see what&#x27;s left of our vector. </span><br><span class="hljs-built_in">assert_eq!</span>(v, <span class="hljs-built_in">vec!</span>[<span class="hljs-string">&quot;101&quot;</span>, <span class="hljs-string">&quot;104&quot;</span>, <span class="hljs-string">&quot;substitute&quot;</span>]);<br></code></pre></td></tr></table></figure><h3 id="Copy-Types">Copy Types</h3><p>The standard <code>Copy</code> types include all the machine integer and floating-point numeric types, the <code>char</code> and <code>bool</code> types, and a few others. A tuple or fixed-size array of <code>Copy</code> types is itself a <code>Copy</code> type.</p><blockquote><p>As a rule of thumb, any type that needs to do something special when a value is dropped cannot be Copy: a Vec needs to free its elements, a File needs to close its file handle, a MutexGuard needs to unlock its mutex, and so on.</p></blockquote><p>By default, struct and enum types are not <code>Copy</code>.</p><p>If all the fields of your struct are themselves Copy, then you can make the type Copy as well by placing the attribute <code>#[derive(Copy, Clone)]</code> above the definition, like so:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-meta">#[derive(Copy, Clone)]</span> <br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">Label</span> &#123; number: <span class="hljs-type">u32</span> &#125;<br></code></pre></td></tr></table></figure><h3 id="Rc-and-Arc-Shared-Ownership">Rc and Arc: Shared Ownership</h3><p>In some cases it’s difficult to find every value a single owner that has the lifetime you need; you’d like the value to simply live until everyone’s done using it. For these cases, Rust provides the reference-counted pointer types <code>Rc</code> and <code>Arc</code>.</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">use</span> std::rc::Rc; <br><span class="hljs-comment">// Rust can infer all these types; written out for clarity </span><br><span class="hljs-keyword">let</span> <span class="hljs-variable">s</span>: Rc&lt;<span class="hljs-type">String</span>&gt; = Rc::<span class="hljs-title function_ invoke__">new</span>(<span class="hljs-string">&quot;shirataki&quot;</span>.<span class="hljs-title function_ invoke__">to_string</span>()); <br><span class="hljs-keyword">let</span> <span class="hljs-variable">t</span>: Rc&lt;<span class="hljs-type">String</span>&gt; = s.<span class="hljs-title function_ invoke__">clone</span>(); <br><span class="hljs-keyword">let</span> <span class="hljs-variable">u</span>: Rc&lt;<span class="hljs-type">String</span>&gt; = s.<span class="hljs-title function_ invoke__">clone</span>();<br></code></pre></td></tr></table></figure><p>For any type T, an <code>Rc&lt;T&gt;</code> value is a pointer to a heap-allocated T that has had a reference count affixed to it.</p><p><strong>Cloning an <code>Rc&lt;T&gt;</code> value does not copy the T; instead, it simply creates another pointer to it and increments the reference count.</strong></p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20240204161742664.png" alt="image-20240204161742664"></p><p><strong>A value owned by an Rc pointer is immutable.</strong></p><h2 id="Chapter-5-References">Chapter 5 References</h2><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">type</span> <span class="hljs-title class_">Table</span> = HashMap&lt;<span class="hljs-type">String</span>, <span class="hljs-type">Vec</span>&lt;<span class="hljs-type">String</span>&gt;&gt;;<br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">show</span>(table: &amp;Table) &#123; <br>    <span class="hljs-keyword">for</span> (artist, works) <span class="hljs-keyword">in</span> table &#123; <br>        <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;works by &#123;&#125;:&quot;</span>, artist); <br>        <span class="hljs-keyword">for</span> <span class="hljs-variable">work</span> <span class="hljs-keyword">in</span> works &#123; <br>            <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot; &#123;&#125;&quot;</span>, work); <br>        &#125; <br>    &#125; <br>&#125;<br></code></pre></td></tr></table></figure><p>This code is fine. Are you wondering why <code>for work in works</code> does not consume the <code>String</code>?</p><p>It receives a shared reference to the HashMap. Iterating over a shared reference to a <code>HashMap</code> is defined to produce shared references to each entry’s key and value: artist has changed from a String to a &amp;String, and works from a <code>Vec&lt;String&gt;</code> to a <code>&amp;Vec&lt;String&gt;</code>. Iterating over a shared reference to a <code>vector</code> is defined to produce shared references to its elements, too.</p><ul><li>Since references are so widely used in Rust, the <code>.</code> operator implicitly dereferences its left operand.</li><li>The <code>.</code> operator can also implicitly borrow a reference to its left operand, if needed for a method call.</li></ul><h2 id="Chapter-6-Expressions">Chapter 6 Expressions</h2><h3 id="An-Expression-Language">An Expression Language</h3><p>In C, <code>if</code> and <code>switch</code> are statements. They don’t produce a value, and they can’t be used in the middle of an expression. In Rust, <code>if</code> and <code>match</code> can produce values.</p><blockquote><p>This explains why Rust does not have C’s ternary operator (<code>expr 1 ? expr 2 : expr 3</code>). In C, it is a handy expression-level analogue to the <code>if</code> statement. It would be redundant in Rust: the <code>if</code> expression handles both cases.</p></blockquote><h3 id="Blocks-and-Semicolons">Blocks and Semicolons</h3><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-variable">msg</span> = &#123; <br>    <span class="hljs-comment">// let-declaration: semicolon is always required </span><br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">dandelion_control</span> = puffball.<span class="hljs-title function_ invoke__">open</span>(); <br><br>    <span class="hljs-comment">// expression + semicolon: method is called, return value dropped </span><br>    dandelion_control.<span class="hljs-title function_ invoke__">release_all_seeds</span>(launch_codes); <br><br>    <span class="hljs-comment">// expression with no semicolon: method is called, </span><br>    <span class="hljs-comment">// return value stored in `msg` </span><br>    dandelion_control.<span class="hljs-title function_ invoke__">get_status</span>() <br>&#125;;<br></code></pre></td></tr></table></figure><p>A block can also contain item declarations. An item is simply any declaration that could appear globally in a program or module, such as a <code>fn</code>, <code>struct</code>, or <code>use</code>.</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">use</span> std::io; <br><span class="hljs-keyword">use</span> std::cmp::Ordering; <br><br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">show_files</span>() <span class="hljs-punctuation">-&gt;</span> io::<span class="hljs-type">Result</span>&lt;()&gt; &#123; <br>    <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">v</span> = <span class="hljs-built_in">vec!</span>[]; <br>    ... <br>    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">cmp_by_timestamp_then_name</span>(a: &amp;FileInfo, b: &amp;FileInfo) <span class="hljs-punctuation">-&gt;</span> Ordering &#123; <br>        a.timestamp.<span class="hljs-title function_ invoke__">cmp</span>(&amp;b.timestamp) <span class="hljs-comment">// first, compare timestamps </span><br>            .<span class="hljs-title function_ invoke__">reverse</span>() <span class="hljs-comment">// newest file first </span><br>            .<span class="hljs-title function_ invoke__">then</span>(a.path.<span class="hljs-title function_ invoke__">cmp</span>(&amp;b.path)) <span class="hljs-comment">// compare paths to break ties </span><br>        &#125; <br>        <br>        v.<span class="hljs-title function_ invoke__">sort_by</span>(cmp_by_timestamp_then_name); <br>        ... <br>    &#125;<br></code></pre></td></tr></table></figure><h3 id="if-let">if let</h3><p>There is one more <code>if</code> form, the <code>if let</code> expression:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">if</span> <span class="hljs-keyword">let</span> <span class="hljs-variable">pattern</span> = expr &#123;<br> block1 <br>&#125; <span class="hljs-keyword">else</span> &#123; <br> block2 <br>&#125;<br></code></pre></td></tr></table></figure><h3 id="Loops">Loops</h3><p>There are four looping expressions:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">while</span> condition &#123; <br>    block <br>&#125; <br><br><span class="hljs-keyword">while</span> <span class="hljs-keyword">let</span> <span class="hljs-variable">pattern</span> = expr &#123; <br>    block <br>&#125; <br><br><span class="hljs-keyword">loop</span> &#123; <br>    block <br>&#125; <br><br><span class="hljs-keyword">for</span> <span class="hljs-variable">pattern</span> <span class="hljs-keyword">in</span> iterable &#123; <br>    block <br>&#125;<br></code></pre></td></tr></table></figure><p>Loops are expressions in Rust, but the value of a <code>while</code> or <code>for</code> loop is always <code>()</code>, so their value isn’t very useful. A <code>loop</code> expression can produce a value if you specify one.</p><h3 id="Function-and-Method-Calls">Function and Method Calls</h3><p>Rust usually makes a sharp distinction between references and the values they refer to.</p><ul><li>If you pass a <code>&amp;i32</code> to a function that expects an <code>i32</code>, that’s a type error.</li><li>You’ll notice that the <code>.</code> operator relaxes those rules a bit.<ul><li>In the method call <code>player.location()</code>, player might be a<code>Player</code>, a reference of type <code>&amp;Player</code>, or a smart pointer of type <code>Box&lt;Player&gt;</code> or <code>Rc&lt;Player&gt;</code>.</li></ul></li></ul><h3 id="Fields-and-Elements">Fields and Elements</h3><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs rust">.. b <span class="hljs-comment">// RangeTo &#123; end: b &#125; </span><br>a .. b <span class="hljs-comment">// Range &#123; start: a, end: b &#125;</span><br><br>..= b <span class="hljs-comment">// RangeToInclusive &#123; end: b &#125; </span><br>a ..= b <span class="hljs-comment">// RangeInclusive::new(a, b)</span><br></code></pre></td></tr></table></figure><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">quicksort</span>&lt;T: <span class="hljs-built_in">Ord</span>&gt;(slice: &amp;<span class="hljs-keyword">mut</span> [T]) &#123; <br>    <span class="hljs-keyword">if</span> slice.<span class="hljs-title function_ invoke__">len</span>() &lt;= <span class="hljs-number">1</span> &#123; <br>    <span class="hljs-keyword">return</span>; <span class="hljs-comment">// Nothing to sort. </span><br>    &#125; <br><br>    <span class="hljs-comment">// Partition the slice into two parts, front and back. </span><br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">pivot_index</span> = <span class="hljs-title function_ invoke__">partition</span>(slice); <br><br>    <span class="hljs-comment">// Recursively sort the front half of `slice`. </span><br>    <span class="hljs-title function_ invoke__">quicksort</span>(&amp;<span class="hljs-keyword">mut</span> slice[.. pivot_index]); <br>    <br>    <span class="hljs-comment">// And the back half. </span><br>    <span class="hljs-title function_ invoke__">quicksort</span>(&amp;<span class="hljs-keyword">mut</span> slice[pivot_index + <span class="hljs-number">1</span> ..]); <br>&#125;<br></code></pre></td></tr></table></figure><h3 id="Reference-Operators">Reference Operators</h3><p>The unary <code>*</code> operator is used to access the value pointed to by a reference. As we’ve seen, Rust automatically follows references when you use the <code>.</code> operator to access a field or method, <em><strong>so the <code>*</code> operator is necessary only when we want to read or write the entire value that the reference points to.</strong></em></p><h3 id="Type-Casts">Type Casts</h3><p>Converting a value from one type to another usually requires an explicit cast in Rust. Casts use the <code>as</code> keyword:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-variable">x</span> = <span class="hljs-number">17</span>; <span class="hljs-comment">// x is type i 32 </span><br><span class="hljs-keyword">let</span> <span class="hljs-variable">index</span> = x <span class="hljs-keyword">as</span> <span class="hljs-type">usize</span>; <span class="hljs-comment">// convert to usize</span><br></code></pre></td></tr></table></figure><p>Several more significant automatic conversions can happen, though:</p><ul><li>Values of type <code>&amp;String</code> auto-convert to type<code>&amp;str</code> without a cast.</li><li>alues of type <code>&amp;Vec&lt;i32&gt;</code> auto-convert to <code>&amp;[i32]</code>.</li><li>Values of type <code>&amp;Box&lt;Chessboard&gt;</code> auto-convert to <code>&amp;Chessboard</code>.</li></ul><p>These are called <em><strong>deref coercions</strong></em>, because they apply to types that implement the <code>Deref</code> built-in trait. The purpose of <code>Deref</code> coercion is to make smart pointer types, like <code>Box</code>, behave as much like the underlying value as possible. Using a <code>Box&lt;Chessboard&gt;</code> is mostly just like using a plain <code>Chessboard</code>, thanks to <code>Deref</code>.</p><h2 id="Chapter-7-Error-Handling">Chapter 7 Error Handling</h2><h3 id="Panic">Panic</h3><p>Perhaps <code>panic</code> is a misleading name for this orderly process. A panic is not a crash. It’s not undefined behavior. It’s more like a <code>RuntimeException</code> in Java or a <code>std::logic_error</code> in C++. <strong>The behavior is well-defined; it just shouldn’t be happening.</strong></p><h3 id="Result">Result</h3><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">get_weather</span>(location: LatLng) <span class="hljs-punctuation">-&gt;</span> <span class="hljs-type">Result</span>&lt;WeatherReport, io::Error&gt;<br></code></pre></td></tr></table></figure><h4 id="Catching-Errors">Catching Errors</h4><p>The most thorough way of dealing with a <code>Result</code> is to use a <code>match</code> expression.</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">match</span> <span class="hljs-title function_ invoke__">get_weather</span>(hometown) &#123;<br>    <span class="hljs-title function_ invoke__">Ok</span>(report) =&gt; &#123;<br>        <span class="hljs-title function_ invoke__">display_weather</span>(hometown, &amp;report);<br>    &#125;<br>    <span class="hljs-title function_ invoke__">Err</span>(err) =&gt; &#123;<br>        <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;error querying the weather: &#123;&#125;&quot;</span>, err);<br>        <span class="hljs-title function_ invoke__">schedule_weather_retry</span>();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><code>Result&lt;T, E&gt;</code> offers a variety of methods that are useful in particular common cases. Each of these methods has a <code>match</code> expression in its implementation:</p><ul><li><code>result.is_ok()</code>, <code>result.is_err()</code><ul><li>Return a <code>bool</code> telling if <code>result</code> is a success result or an error result.</li></ul></li><li><code>result.ok()</code><ul><li>Returns the success value, if any, as an <code>Option&lt;T&gt;</code>. If result is a success result, this returns <code>Some(success_value)</code>; otherwise, it returns None, discarding the <code>error</code> value.</li></ul></li><li><code>result.err()</code><ul><li>Returns the error value, if any, as an <code>Option&lt;E&gt;</code>.</li></ul></li><li><code>result.unwrap_or(fallback)</code><ul><li>Returns the success value, if result is a success result. Otherwise, it returns <code>fallback</code>, discarding the error value.</li></ul></li></ul><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-comment">// A fairly safe prediction for Southern California. </span><br>    <span class="hljs-keyword">const</span> THE_USUAL: WeatherReport = WeatherReport::<span class="hljs-title function_ invoke__">Sunny</span>(<span class="hljs-number">72</span>); <br>    <span class="hljs-comment">// Get a real weather report, if possible. </span><br>    <span class="hljs-comment">// If not, fall back on the usual. </span><br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">report</span> = <span class="hljs-title function_ invoke__">get_weather</span>(los_angeles).<span class="hljs-title function_ invoke__">unwrap_or</span>(THE_USUAL); <span class="hljs-title function_ invoke__">display_weather</span>(los_angeles, &amp;report);<br></code></pre></td></tr></table></figure><ul><li><code>result.unwrap_or_else(fallback_fn)</code><ul><li>This is the same, but instead of passing a fallback value directly, you pass a function or closure. This is for cases where it would be wasteful to compute a fallback value if you’re not going to use it. The <code>fallback_fn</code> is called only if we have an error result.</li></ul></li></ul><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-variable">report</span> = <br>    <span class="hljs-title function_ invoke__">get_weather</span>(hometown)<br>    .<span class="hljs-title function_ invoke__">unwrap_or_else</span>(|_err| <span class="hljs-title function_ invoke__">vague_prediction</span>(hometown));<br></code></pre></td></tr></table></figure><ul><li><code>result.unwrap()</code><ul><li>Also returns the success value, if <code>result</code> is a success result. However, if result is an error result, this method panics.</li></ul></li><li><code>result.expect(message)</code><ul><li>This the same as <code>.unwrap()</code>, but lets you provide a message that it prints in case of panic.</li></ul></li><li><code>result.as_ref()</code><ul><li>Converts a <code>Result&lt;T, E&gt;</code> to a <code>Result&lt;&amp;T, &amp;E&gt;</code>.</li></ul></li><li><code>result.as_mut()</code><ul><li>This is the same, but borrows a mutable reference. The return type is <code>Result&lt;&amp;mut T, &amp;mut E&gt;</code>.</li></ul></li></ul><blockquote><p>For example, suppose you’d like to call <code>result.ok()</code>, but you need result to be left intact. You can write <code>result.as_ref().ok()</code>, which merely borrows result, returning an <code>Option&lt;&amp;T&gt;</code> rather than an <code>Option&lt;T&gt;</code>.</p></blockquote><h3 id="Result-Type-Aliases">Result Type Aliases</h3><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">remove_file</span>(path: &amp;Path) <span class="hljs-punctuation">-&gt;</span> <span class="hljs-type">Result</span>&lt;()&gt;<br></code></pre></td></tr></table></figure><p>This means that a <code>Result</code> type alias is being used.</p><p>Modules often define a Result type alias to avoid having to repeat an error type that’s used consistently by almost every function in the module. For example, the standard library’s std::io module includes this line of code:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">pub</span> <span class="hljs-keyword">type</span> <span class="hljs-title class_">Result</span>&lt;T&gt; = result::<span class="hljs-type">Result</span>&lt;T, Error&gt;;<br></code></pre></td></tr></table></figure><p>Printing an error value does not also print out its source. If you want to be sure to print all the available information, use this function:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">use</span> std::error::Error;<br><span class="hljs-keyword">use</span> std::io::&#123;stderr, Write&#125;;<br><span class="hljs-comment">/// Dump an error message to `stderr`.</span><br><span class="hljs-comment">///</span><br><span class="hljs-comment">/// If another error happens while building the error message or</span><br><span class="hljs-comment">/// riting to `stderr`, it is ignored.</span><br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">print_error</span>(<span class="hljs-keyword">mut</span> err: &amp;<span class="hljs-keyword">dyn</span> Error) &#123;<br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">_</span> = <span class="hljs-built_in">writeln!</span>(<span class="hljs-title function_ invoke__">stderr</span>(), <span class="hljs-string">&quot;error: &#123;&#125;&quot;</span>, err);<br>    <span class="hljs-keyword">while</span> <span class="hljs-keyword">let</span> <span class="hljs-variable">Some</span>(source) = err.<span class="hljs-title function_ invoke__">source</span>() &#123;<br>        <span class="hljs-keyword">let</span> <span class="hljs-variable">_</span> = <span class="hljs-built_in">writeln!</span>(<span class="hljs-title function_ invoke__">stderr</span>(), <span class="hljs-string">&quot;caused by: &#123;&#125;&quot;</span>, source);<br>        err = source;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="Propagating-Errors">Propagating Errors</h4><p>Rust has a <code>?</code> operator that does this.</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-variable">weather</span> = <span class="hljs-title function_ invoke__">get_weather</span>(hometown)?;<br></code></pre></td></tr></table></figure><ul><li>On success, it unwraps the Result to get the success value inside. The type of weather here is not <code>Result&lt;WeatherReport, io::Error&gt;</code> but simply <code>WeatherReport</code>.</li><li>On error, it immediately returns from the enclosing function, passing the error result up the call chain. To ensure that this works, <code>?</code> can only be used on a <code>Result</code> in functions that have a <code>Result</code> return type.</li></ul><p><code>?</code> also works similarly with the <code>Option</code> type. In a function that returns Option, you can use <code>?</code> to unwrap a value and return early in the case of <code>None</code>:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-variable">weather</span> = <span class="hljs-title function_ invoke__">get_weather</span>(hometown).<span class="hljs-title function_ invoke__">ok</span>()?;<br></code></pre></td></tr></table></figure><h4 id="Working-with-Multiple-Error-Types">Working with Multiple Error Types</h4><p>All of the standard library error types can be converted to the type <code>Box&lt;dyn std::error::Error + Send + Sync + 'static&gt;</code>：</p><ul><li><code>dyn std::error::Error</code> represents “any error”</li><li><code>Send + Sync + 'static</code> makes it safe to pass between threads</li></ul><p>For convenience, you can define type aliases:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">type</span> <span class="hljs-title class_">GenericError</span> = <span class="hljs-type">Box</span>&lt;<span class="hljs-keyword">dyn</span> std::error::Error + <span class="hljs-built_in">Send</span> + <span class="hljs-built_in">Sync</span> + <span class="hljs-symbol">&#x27;static</span>&gt;; <br><span class="hljs-keyword">type</span> <span class="hljs-title class_">GenericResult</span>&lt;T&gt; = <span class="hljs-type">Result</span>&lt;T, GenericError&gt;;<br></code></pre></td></tr></table></figure><p>To convert any error to the GenericError type, call <code>GenericError::from()</code>:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-variable">io_error</span> = io::Error::<span class="hljs-title function_ invoke__">new</span>(io::ErrorKind::Other, <span class="hljs-string">&quot;timed out&quot;</span>); <span class="hljs-comment">// make our own io::Error </span><br><span class="hljs-keyword">return</span> <span class="hljs-title function_ invoke__">Err</span>(GenericError::<span class="hljs-title function_ invoke__">from</span>(io_error)); <span class="hljs-comment">// manually convert to GenericError</span><br></code></pre></td></tr></table></figure><h2 id="Chapter-8-Crates-and-Modules">Chapter 8 Crates and Modules</h2><h3 id="Crates">Crates</h3><p>Rust programs are made of <strong>crates</strong>. Each crate is a complete, cohesive unit: all the source code for a single library or executable, plus any associated tests, examples, tools, configuration, and other junk.</p><h3 id="Editions">Editions</h3><p>Rust promises that the compiler will always accept all extant editions of the language, and programs can freely mix crates written in different editions.</p><p>It’s even fine for a 2015 edition crate to depend on a 2018 edition crate. In other words, a crate’s edition only affects how its source code is construed; <em><strong>edition distinctions are gone by the time the code has been compiled.</strong></em> This means there’s no pressure to update old crates just to continue to participate in the modern Rust ecosystem.</p><h3 id="Modules">Modules</h3><p>Whereas crates are about code sharing between projects, <strong>modules</strong> are about code organization <strong>within</strong> a project.</p><p>They act as Rust’s namespaces, containers for the functions, types, constants, and so on that make up your Rust program or library.</p><p>Anything that isn’t marked <code>pub</code> is private and can only be used in the same module in which it is defined, or any child modules.</p><p>It’s also possible to specify <code>pub(super)</code>, making an item visible to the parent module only, and <code>pub(in &lt;path&gt;)</code>, which makes it visible in a specific parent module and its descendants.</p><p>A module can have its own directory. When Rust sees <code>mod spores;</code>, it checks for both <code>spores.rs</code> and <code>spores/mod.rs</code>; if neither file exists, or both exist, that’s an error.</p><p>The code in <code>src/lib.rs</code> forms the <strong>root module</strong> of the library. Other crates that use our library can only access the public items of this root module.</p><h4 id="The-src-bin-Directory">The src/bin Directory</h4><p>Cargo has some built-in support for small programs that live in the same crate as a library.</p><p>We can keep our program and our library in the same crate, too. Put this code into a file named <code>src/bin/efern.rs</code></p><h3 id="Test-and-Documentation">Test and Documentation</h3><p>Rust’s test harness uses multiple threads to run several tests at a time, a nice side benefit of your Rust code being thread-safe by default. To disable this, either run a single test, <code>cargo test testname</code>, or run <code>cargo test -- --test-threads 1</code>. (The first <code>--</code> ensures that cargo test passes the <code>--test-threads</code> option through to the test executable.)</p><h4 id="Integration-Tests">Integration Tests</h4><p><strong>Integration tests</strong> are <code>.rs</code> files that live in a <em><strong>tests</strong></em> directory alongside your project’s src directory. When you run <code>cargo test</code>, Cargo compiles each integration test as a separate, standalone crate, linked with your library and the Rust test harness.</p><blockquote><p>Integration tests are valuable in part because they see your crate from the outside, just as a user would. They test the crate’s public API.</p></blockquote><h4 id="Documentation">Documentation</h4><p>When Rust sees comments that start with three slashes, it treats them as a <code>#[doc]</code> attribute instead.</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-comment">/// Simulate the production of a spore by meiosis. </span><br><span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">produce_spore</span>(factory: &amp;<span class="hljs-keyword">mut</span> Sporangium) <span class="hljs-punctuation">-&gt;</span> Spore &#123; ... &#125;<br></code></pre></td></tr></table></figure><p>Comments starting with <code>//!</code> are treated as <code>#![doc]</code> attributes and are attached to the enclosing feature, typically a module or crate. For example, your <code>fern_sim/src/lib.rs</code> file might begin like this:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-comment">//! Simulate the growth of ferns, from the level of </span><br><span class="hljs-comment">//! individual cells on up.</span><br></code></pre></td></tr></table></figure><p>The content of a doc comment is treated as Markdown.</p><h4 id="Doc-Tests">Doc-Tests</h4><p>When you run tests in a Rust library crate, Rust checks that all the code that appears in your documentation actually runs and works.</p><p>It does this by taking each block of code that appears in a doc comment, compiling it as a separate executable crate, linking it with your library, and running it.</p><p>Very often a minimal working example includes some details, such as imports or setup code, that are necessary to make the code compile, but just aren’t important enough to show in the documentation. To hide a line of a code sample, put a <code>#</code> followed by a space at the beginning of that line:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-comment">/// Let the sun shine in and run the simulation for a given </span><br><span class="hljs-comment">/// amount of time. </span><br><span class="hljs-comment">/// </span><br><span class="hljs-comment">///     # use fern_sim::Terrarium; </span><br><span class="hljs-comment">///     # use std::time::Duration; </span><br><span class="hljs-comment">///     # let mut tm = Terrarium::new(); </span><br><span class="hljs-comment">///     tm.apply_sunlight(Duration::from_secs(60)); </span><br><span class="hljs-comment">/// </span><br><span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">apply_sunlight</span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>, time: Duration) &#123; ... &#125;<br></code></pre></td></tr></table></figure><p>Testing can be disabled for specific blocks of code. To tell Rust to compile your example, but stop short of actually running it, use a fenced code block with the <code>no_run</code> annotation:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-comment">/// Upload all local terrariums to the online gallery. </span><br><span class="hljs-comment">/// </span><br><span class="hljs-comment">/// ```no_run </span><br><span class="hljs-comment">/// let mut session = fern_sim::connect(); </span><br><span class="hljs-comment">/// session.upload_all(); </span><br><span class="hljs-comment">/// ``` </span><br><span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">upload_all</span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>) &#123; ... &#125;<br></code></pre></td></tr></table></figure><h2 id="Chapter-9-Structs">Chapter 9 Structs</h2><h3 id="Interior-Mutability">Interior Mutability</h3><p>Now suppose you want to add a little logging to the <code>SpiderRobot</code> struct, using the standard <code>File</code> type. There’s a problem: a <code>File</code> has to be <em>mut</em>. All the methods for writing to it require a mut reference.</p><p>This sort of situation comes up fairly often. What we need is a little bit of mutable data (a <code>File</code>) inside an otherwise immutable value (the <code>SpiderRobot</code> struct)</p><p>This is called <em><strong>interior mutability</strong></em>. Rust offers several flavors of it:</p><ul><li><code>Cell&lt;T&gt;</code></li><li><code>RefCell&lt;T&gt;</code></li></ul><p>A <code>Cell&lt;T&gt;</code> is a struct that contains a single private value of type <code>T</code>. The only special thing about a Cell is that <strong>you can get and set the field even if you don’t have mut access to the Cell itself</strong>:</p><ul><li><code>cell.get()</code><ul><li>Returns a copy of the value in the <code>cell</code>.</li></ul></li><li><code>cell.set(value)</code><ul><li>Stores the given <code>value</code> in the cell, dropping the previously stored value.</li><li>This method takes <code>self</code> as a <code>non-mut</code> reference:</li><li>They’re simply a safe way of bending the rules on immutability—no more, no less.</li></ul></li></ul><p>A <code>Cell</code> would be handy if you were adding a simple counter to your SpiderRobot. You could write:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">use</span> std::cell::Cell; <br><br><span class="hljs-keyword">pub</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">SpiderRobot</span> &#123; <br>    ... <br>    hardware_error_count: Cell&lt;<span class="hljs-type">u32</span>&gt;, <br>    ... <br>&#125;<br></code></pre></td></tr></table></figure><p>Then even non-mut methods of SpiderRobot can access that <code>u32</code>, using the <code>.get()</code> and <code>.set()</code> methods:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">impl</span> <span class="hljs-title class_">SpiderRobot</span> &#123; <br>    <span class="hljs-comment">/// Increase the error count by 1. </span><br>    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">add_hardware_error</span>(&amp;<span class="hljs-keyword">self</span>) &#123; <br>        <span class="hljs-keyword">let</span> <span class="hljs-variable">n</span> = <span class="hljs-keyword">self</span>.hardware_error_count.<span class="hljs-title function_ invoke__">get</span>(); <br>        <span class="hljs-keyword">self</span>.hardware_error_count.<span class="hljs-title function_ invoke__">set</span>(n + <span class="hljs-number">1</span>); <br>    &#125; <br><br>    <span class="hljs-comment">/// True if any hardware errors have been reported. </span><br>    <span class="hljs-keyword">pub</span> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">has_hardware_errors</span>(&amp;<span class="hljs-keyword">self</span>) <span class="hljs-punctuation">-&gt;</span> <span class="hljs-type">bool</span> &#123;<br>        <span class="hljs-keyword">self</span>.hardware_error_count.<span class="hljs-title function_ invoke__">get</span>() &gt; <span class="hljs-number">0</span> <br>    &#125; <br>&#125;<br></code></pre></td></tr></table></figure><p><code>Cell</code> does not let you call mut methods on a shared value. The <code>.get()</code> method returns a copy of the value in the cell, so <strong>it works only if <code>T</code> implements the Copy trait.</strong></p><p>The right tool in this case is a <code>RefCell</code>. Like <code>Cell&lt;T&gt;</code>, <code>RefCell&lt;T&gt;</code> is a generic type that contains a single value of type <code>T</code>. Unlike Cell, RefCell supports borrowing references to its <code>T</code> value:</p><ul><li><code>RefCell::new(value)</code><ul><li>Creates a new <code>RefCell</code>, <strong>moving value into it</strong>.</li></ul></li><li><code>ref_cell.borrow()</code><ul><li>Returns a <code>Ref&lt;T&gt;</code>, which is essentially just a shared reference to the value stored in ref_cell.</li></ul></li><li><code>ref_cell.borrow_mut()</code><ul><li>Returns a <code>RefMut&lt;T&gt;</code>, essentially a mutable reference to the value in ref_cell.</li></ul></li><li><code>ref_cell.try_borrow()</code>, <code>ref_cell.try_borrow_mut()</code><ul><li>Work just like <code>borrow()</code> and <code>borrow_mut()</code>, but return a <code>Result</code>. Instead of panicking if the value is already mutably borrowed, they return an <code>Err</code> value.</li></ul></li></ul><p>The only difference is that normally, when you borrow a reference to a variable, Rust <strong>checks at compile time</strong> to ensure that you’re using the reference safely. If the checks fail, you get a compiler error. RefCell enforces the same rule <strong>using run-time checks</strong>.</p><p>Cells are easy to use. Having to call <code>.get()</code> and <code>.set()</code> or <code>.borrow()</code> and <code>.borrow_mut()</code> is slightly awkward, but that’s just the price we pay for bending the rules.</p><h2 id="Chapter-10-Enums-and-Patterns">Chapter 10 Enums and Patterns</h2><h3 id="Enums-with-Data">Enums with Data</h3><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-meta">#[derive(Copy, Clone, Debug, PartialEq)]</span><br><span class="hljs-keyword">enum</span> <span class="hljs-title class_">RoughTime</span> &#123; <br>    <span class="hljs-title function_ invoke__">InThePast</span>(TimeUnit, <span class="hljs-type">u32</span>), <br>    JustNow, <br>    <span class="hljs-title function_ invoke__">InTheFuture</span>(TimeUnit, <span class="hljs-type">u32</span>), <br>&#125;<br></code></pre></td></tr></table></figure><p>Two of the variants in this enum, <code>InThePast</code> and <code>InTheFuture</code>, take arguments. These are called <em><strong>tuple variants</strong></em>.</p><p>Enums can also have <em><strong>struct variants</strong></em>, which contain named fields, just like ordinary structs:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">enum</span> <span class="hljs-title class_">Shape</span> &#123; <br>    Sphere &#123; center: Point3d, radius: <span class="hljs-type">f32</span> &#125;, <br>    Cuboid &#123; corner1: Point3d, corner2: Point3d &#125;, <br>&#125; <br><br><span class="hljs-keyword">let</span> <span class="hljs-variable">unit_sphere</span> = Shape::Sphere &#123; center: ORIGIN, radius: <span class="hljs-number">1.0</span>, &#125;;<br></code></pre></td></tr></table></figure><p>A single enum can have variants of all three kinds:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">enum</span> <span class="hljs-title class_">RelationshipStatus</span> &#123; <br>    Single, <br>    InARelationship, <br>    <span class="hljs-title function_ invoke__">ItsComplicated</span>(<span class="hljs-type">Option</span>&lt;<span class="hljs-type">String</span>&gt;), <br>    ItsExtremelyComplicated &#123; <br>  car: DifferentialEquation, <br>  cdr: EarlyModernistPoem, <br> &#125;, <br>&#125;<br></code></pre></td></tr></table></figure><h3 id="Patterns">Patterns</h3><p>Suppose you have a <code>RoughTime</code> value and you’d like to display it on a web page. You need to access the TimeUnit and <code>u32</code> fields inside the value. Rust doesn’t let you access them directly, by writing <code>rough_time.0</code> and <code>rough_time.1</code>, because after all, the value might be <code>RoughTime::JustNow</code>, which has no fields.</p><p>You need a <code>match</code> expression.</p><p><code>other</code> can serve as a catchall pattern:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-variable">calendar</span> = <span class="hljs-keyword">match</span> settings.<span class="hljs-title function_ invoke__">get_string</span>(<span class="hljs-string">&quot;calendar&quot;</span>) &#123; <br>    <span class="hljs-string">&quot;gregorian&quot;</span> =&gt; Calendar::Gregorian, <br>    <span class="hljs-string">&quot;chinese&quot;</span> =&gt; Calendar::Chinese, <br>    <span class="hljs-string">&quot;ethiopian&quot;</span> =&gt; Calendar::Ethiopian, <br>    other =&gt; <span class="hljs-keyword">return</span> <span class="hljs-title function_ invoke__">parse_error</span>(<span class="hljs-string">&quot;calendar&quot;</span>, other), <br>&#125;;<br></code></pre></td></tr></table></figure><p>If you need a catchall pattern, but you don’t care about the matched value, you can use a single underscore <code>_</code> as a pattern, the <em><strong>wildcard pattern</strong></em>:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-variable">caption</span> = <span class="hljs-keyword">match</span> photo.<span class="hljs-title function_ invoke__">tagged_pet</span>() &#123; <br>    Pet::Tyrannosaur =&gt; <span class="hljs-string">&quot;RRRAAAAAHHHHHH&quot;</span>, <br>    Pet::Samoyed =&gt; <span class="hljs-string">&quot;*dog thoughts*&quot;</span>, <br>    _ =&gt; <span class="hljs-string">&quot;I&#x27;m cute, love me&quot;</span>, <span class="hljs-comment">// generic caption, works for any pet </span><br>&#125;;<br></code></pre></td></tr></table></figure><h4 id="Tuple-and-Struct-Patterns">Tuple and Struct Patterns</h4><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">describe_point</span>(x: <span class="hljs-type">i32</span>, y: <span class="hljs-type">i32</span>) <span class="hljs-punctuation">-&gt;</span> &amp;<span class="hljs-symbol">&#x27;static</span> <span class="hljs-type">str</span> &#123;<br>    <span class="hljs-keyword">use</span> std::cmp::Ordering::*;<br>    <span class="hljs-keyword">match</span> (x.<span class="hljs-title function_ invoke__">cmp</span>(&amp;<span class="hljs-number">0</span>), y.<span class="hljs-title function_ invoke__">cmp</span>(&amp;<span class="hljs-number">0</span>)) &#123;<br>        (Equal, Equal) =&gt; <span class="hljs-string">&quot;at the origin&quot;</span>,<br>        (_, Equal) =&gt; <span class="hljs-string">&quot;on the x axis&quot;</span>,<br>        (Equal, _) =&gt; <span class="hljs-string">&quot;on the y axis&quot;</span>,<br>        (Greater, Greater) =&gt; <span class="hljs-string">&quot;in the first quadrant&quot;</span>,<br>        (Less, Greater) =&gt; <span class="hljs-string">&quot;in the second quadrant&quot;</span>,<br>        _ =&gt; <span class="hljs-string">&quot;somewhere else&quot;</span>,<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>Struct patterns use curly braces, just like struct expressions. They contain a subpattern for each field:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">match</span> balloon.location &#123; <br>    Point &#123; x: <span class="hljs-number">0</span>, y: height &#125; =&gt; <br>        <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;straight up &#123;&#125; meters&quot;</span>, height), <br>    Point &#123; x: x, y: y &#125; =&gt; <br>        <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;at (&#123;&#125;m, &#123;&#125;m)&quot;</span>, x, y), <br>&#125;<br></code></pre></td></tr></table></figure><p>Use <code>..</code> to tell Rust you don’t care about any of the other fields:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-title function_ invoke__">Some</span>(Account &#123; name, language, .. &#125;) =&gt; <br>    language.<span class="hljs-title function_ invoke__">show_custom_greeting</span>(name),<br></code></pre></td></tr></table></figure><h4 id="Array-and-Slice-Patterns">Array and Slice Patterns</h4><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">hsl_to_rgb</span>(hsl: [<span class="hljs-type">u8</span>; <span class="hljs-number">3</span>]) <span class="hljs-punctuation">-&gt;</span> [<span class="hljs-type">u8</span>; <span class="hljs-number">3</span>] &#123;<br>    <span class="hljs-keyword">match</span> hsl &#123;<br>        [_, _, <span class="hljs-number">0</span>] =&gt; [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],<br>        [_, _, <span class="hljs-number">255</span>] =&gt; [<span class="hljs-number">255</span>, <span class="hljs-number">255</span>, <span class="hljs-number">255</span>],<br>        ...<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>Slice patterns are similar, but unlike arrays, slices have variable lengths, so slice patters match not only on values but also on length.</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">greet_people</span>(names: &amp;[&amp;<span class="hljs-type">str</span>]) &#123;<br>    <span class="hljs-keyword">match</span> names &#123;<br>        [] =&gt; &#123;<br>            <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;Hello, nobody.&quot;</span>)<br>        &#125;<br>        [a] =&gt; &#123;<br>            <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;Hello, &#123;&#125;.&quot;</span>, a)<br>        &#125;<br>        [a, b] =&gt; &#123;<br>            <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;Hello, &#123;&#125; and &#123;&#125;.&quot;</span>, a, b)<br>        &#125;<br>        [a, .., b] =&gt; &#123;<br>            <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;Hello, everyone from &#123;&#125; to &#123;&#125;.&quot;</span>, a, b)<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="Reference-Patterns">Reference Patterns</h4><p>Rust patterns support two features for working with references:</p><ul><li><code>ref</code> patterns borrow parts of a matched value.</li><li><code>&amp;</code> patterns match references.</li></ul><p>Matching a noncopyable value moves the value. Continuing with the account example, this code would be invalid:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">match</span> account &#123; <br>    Account &#123; name, language, .. &#125; =&gt; &#123; <br>        ui.<span class="hljs-title function_ invoke__">greet</span>(&amp;name, &amp;language); <br>        ui.<span class="hljs-title function_ invoke__">show_settings</span>(&amp;account); <span class="hljs-comment">// error: borrow of moved value: `account` </span><br>    &#125; <br>&#125;<br></code></pre></td></tr></table></figure><blockquote><p>Suppose <code>name</code> and <code>language</code> are Strings. What can we do?</p></blockquote><p>We need a kind of pattern that <strong>borrows</strong> matched values instead of moving them. The ref keyword does just that:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">match</span> account &#123; <br>    Account &#123; <span class="hljs-keyword">ref</span> name, <span class="hljs-keyword">ref</span> language, .. &#125; =&gt; &#123; <br>        ui.<span class="hljs-title function_ invoke__">greet</span>(name, language); <br>        ui.<span class="hljs-title function_ invoke__">show_settings</span>(&amp;account); <span class="hljs-comment">// ok </span><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>You can use <code>ref mut</code> to borrow mut references:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">match</span> line_result &#123; <br>    <span class="hljs-title function_ invoke__">Err</span>(<span class="hljs-keyword">ref</span> err) =&gt; <span class="hljs-title function_ invoke__">log_error</span>(err), <span class="hljs-comment">// `err` is &amp;Error (shared ref) </span><br>    <span class="hljs-title function_ invoke__">Ok</span>(<span class="hljs-keyword">ref</span> <span class="hljs-keyword">mut</span> line) =&gt; &#123;           <span class="hljs-comment">// `line` is &amp;mut String (mut ref) </span><br>        <span class="hljs-title function_ invoke__">trim_comments</span>(line);        <span class="hljs-comment">// modify the String in place </span><br>        <span class="hljs-title function_ invoke__">handle</span>(line); <br>    &#125; <br>&#125;<br></code></pre></td></tr></table></figure><p>A pattern starting with <code>&amp;</code> matches a reference:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">match</span> sphere.<span class="hljs-title function_ invoke__">center</span>() &#123; <br>    &amp;Point3d &#123; x, y, z &#125; =&gt; ... <br>&#125;<br></code></pre></td></tr></table></figure><blockquote><p>In an expression, <code>&amp;</code> creates a reference. In a pattern, <code>&amp;</code> matches a reference.</p></blockquote><h4 id="Match-Guards">Match Guards</h4><p>This doesn’t work as expected:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">check_move</span>(current_hex: Hex, click: Point) <span class="hljs-punctuation">-&gt;</span> game::<span class="hljs-type">Result</span>&lt;Hex&gt; &#123;<br>    <span class="hljs-keyword">match</span> <span class="hljs-title function_ invoke__">point_to_hex</span>(click) &#123;<br>        <span class="hljs-literal">None</span> =&gt; <span class="hljs-title function_ invoke__">Err</span>(<span class="hljs-string">&quot;That&#x27;s not a game space.&quot;</span>),<br>        <span class="hljs-title function_ invoke__">Some</span>(current_hex) =&gt;<br>        <span class="hljs-comment">// try to match if user clicked the current_hex</span><br>        <span class="hljs-comment">// (it doesn&#x27;t work: see explanation below)</span><br>        &#123;<br>            <span class="hljs-title function_ invoke__">Err</span>(<span class="hljs-string">&quot;You are already there! You must click somewhere else.&quot;</span>)<br>        &#125;<br>        <span class="hljs-title function_ invoke__">Some</span>(other_hex) =&gt; <span class="hljs-title function_ invoke__">Ok</span>(other_hex),<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>This fails because identifiers in patterns introduce new variables.</p><p>One way to fix this is simply to use an if expression in the match arm:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">check_move</span>(current_hex: Hex, click: Point) <span class="hljs-punctuation">-&gt;</span> game::<span class="hljs-type">Result</span>&lt;Hex&gt; &#123;<br>    <span class="hljs-keyword">match</span> <span class="hljs-title function_ invoke__">point_to_hex</span>(click) &#123;<br>        <span class="hljs-literal">None</span> =&gt; <span class="hljs-title function_ invoke__">Err</span>(<span class="hljs-string">&quot;That&#x27;s not a game space.&quot;</span>),<br>        <span class="hljs-title function_ invoke__">Some</span>(hex) =&gt; &#123;<br>            <span class="hljs-keyword">if</span> hex == current_hex &#123;<br>                <span class="hljs-title function_ invoke__">Err</span>(<span class="hljs-string">&quot;You are already there! You must click somewhere else&quot;</span>)<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                <span class="hljs-title function_ invoke__">Ok</span>(hex)<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>But Rust also provides <strong>match guards</strong>, extra conditions that must be true in order for a match arm to apply:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">check_move</span>(current_hex: Hex, click: Point) <span class="hljs-punctuation">-&gt;</span> game::<span class="hljs-type">Result</span>&lt;Hex&gt; &#123;<br>    <span class="hljs-keyword">match</span> <span class="hljs-title function_ invoke__">point_to_hex</span>(click) &#123;<br>        <span class="hljs-literal">None</span> =&gt; <span class="hljs-title function_ invoke__">Err</span>(<span class="hljs-string">&quot;That&#x27;s not a game space.&quot;</span>),<br>        <span class="hljs-title function_ invoke__">Some</span>(hex) <span class="hljs-keyword">if</span> hex == current_hex =&gt; &#123;<br>            <span class="hljs-title function_ invoke__">Err</span>(<span class="hljs-string">&quot;You are already there! You must click somewhere else&quot;</span>)<br>        &#125;<br>        <span class="hljs-title function_ invoke__">Some</span>(hex) =&gt; <span class="hljs-title function_ invoke__">Ok</span>(hex),<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>The vertical bar (<code>|</code>) can be used to combine several patterns in a single match arm:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-variable">at_end</span> = <span class="hljs-keyword">match</span> chars.<span class="hljs-title function_ invoke__">peek</span>() &#123;<br>    <span class="hljs-title function_ invoke__">Some</span>(&amp;<span class="hljs-string">&#x27;\r&#x27;</span>) | <span class="hljs-title function_ invoke__">Some</span>(&amp;<span class="hljs-string">&#x27;\n&#x27;</span>) | <span class="hljs-literal">None</span> =&gt; <span class="hljs-literal">true</span>, <br>    _ =&gt; <span class="hljs-literal">false</span>, <br>&#125;;<br></code></pre></td></tr></table></figure><h2 id="Chapter-11-Traits-and-Generics">Chapter 11 Traits and Generics</h2><h3 id="Traits">Traits</h3><p>There is one unusual rule about trait methods: the trait itself must be in scope. Otherwise, all its methods are hidden:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">buf</span>: <span class="hljs-type">Vec</span>&lt;<span class="hljs-type">u8</span>&gt; = <span class="hljs-built_in">vec!</span>[]; <br>buf.<span class="hljs-title function_ invoke__">write_all</span>(<span class="hljs-string">b&quot;hello&quot;</span>)?; <span class="hljs-comment">// error: no method named `write_all`</span><br></code></pre></td></tr></table></figure><p>Instead, you can write:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">use</span> std::io::Write; <br><br><span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">buf</span>: <span class="hljs-type">Vec</span>&lt;<span class="hljs-type">u8</span>&gt; = <span class="hljs-built_in">vec!</span>[]; <br>buf.<span class="hljs-title function_ invoke__">write_all</span>(<span class="hljs-string">b&quot;hello&quot;</span>)?; <span class="hljs-comment">// ok</span><br></code></pre></td></tr></table></figure><h4 id="Trait-Objects">Trait Objects</h4><p>There are two ways of using traits to write polymorphic code in Rust:</p><ul><li>Trait objects</li><li>Generics</li></ul><p>This doesn’t work:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">use</span> std::io::Write; <br><br><span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">buf</span>: <span class="hljs-type">Vec</span>&lt;<span class="hljs-type">u8</span>&gt; = <span class="hljs-built_in">vec!</span>[]; <br><span class="hljs-keyword">let</span> <span class="hljs-variable">writer</span>: <span class="hljs-keyword">dyn</span> Write = buf; <span class="hljs-comment">// error: `Write` does not have a constant size</span><br></code></pre></td></tr></table></figure><p>A variable’s size has to be known at compile time, and types that implement Write can be any size.</p><blockquote><p>In Java, a variable of type OutputStream (the Java standard interface analogous to std::io::Write) is a reference to any object that implements OutputStream. The fact that it’s a reference goes without saying.</p></blockquote><p>What we want in Rust is the same thing, but in Rust, references are explicit:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">buf</span>: <span class="hljs-type">Vec</span>&lt;<span class="hljs-type">u8</span>&gt; = <span class="hljs-built_in">vec!</span>[]; <br><span class="hljs-keyword">let</span> <span class="hljs-variable">writer</span>: &amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">dyn</span> Write = &amp;<span class="hljs-keyword">mut</span> buf; <span class="hljs-comment">// ok</span><br></code></pre></td></tr></table></figure><p>A reference to a trait type, like <code>writer</code>, is called a <em><strong>trait object</strong></em>.</p><p>In memory, a trait object is a fat pointer consisting of a pointer to the value, plus a pointer to a table representing that value’s type. Each trait object therefore takes up two machine words:</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20240207104118126.png" alt="image-20240207104118126"></p><h4 id="Generic-Functions-and-Type-Parameters">Generic Functions and Type Parameters</h4><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">say_hello</span>(out: &amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">dyn</span> Write) <span class="hljs-comment">// plain function </span><br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">say_hello</span>&lt;W: Write&gt;(out: &amp;<span class="hljs-keyword">mut</span> W) <span class="hljs-comment">// generic function</span><br></code></pre></td></tr></table></figure><h4 id="Self-in-Traits">Self in Traits</h4><p>A trait can use the keyword <code>Self</code> as a type.</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">pub</span> <span class="hljs-keyword">trait</span> <span class="hljs-title class_">Clone</span> &#123; <br>    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">clone</span>(&amp;<span class="hljs-keyword">self</span>) <span class="hljs-punctuation">-&gt;</span> <span class="hljs-keyword">Self</span>; <br>    ... <br>&#125;<br></code></pre></td></tr></table></figure><p>A trait that uses the <code>Self</code> type is <em><strong>incompatible</strong></em> with trait objects:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-comment">// error: the trait `Spliceable` cannot be made into an object </span><br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">splice_anything</span>(left: &amp;<span class="hljs-keyword">dyn</span> Spliceable, right: &amp;<span class="hljs-keyword">dyn</span> Spliceable) &#123; <br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">combo</span> = left.<span class="hljs-title function_ invoke__">splice</span>(right); <br>    <span class="hljs-comment">// ... </span><br>&#125;<br></code></pre></td></tr></table></figure><h4 id="Subtraits">Subtraits</h4><p>We can declare that a trait is an extension of another trait:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-comment">/// Someone in the game world, either the player or some other </span><br><span class="hljs-comment">/// pixie, gargoyle, squirrel, ogre, etc. </span><br><span class="hljs-keyword">trait</span> <span class="hljs-title class_">Creature</span>: Visible &#123; <br>    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">position</span>(&amp;<span class="hljs-keyword">self</span>) <span class="hljs-punctuation">-&gt;</span> (<span class="hljs-type">i32</span>, <span class="hljs-type">i32</span>); <br>    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">facing</span>(&amp;<span class="hljs-keyword">self</span>) <span class="hljs-punctuation">-&gt;</span> Direction; <br>    ... <br>&#125;<br></code></pre></td></tr></table></figure><p>The phrase trait <code>Creature: Visible</code> means that all creatures are visible. Every type that implements <code>Creature</code> must also implement the <code>Visible</code> trait.</p><h4 id="Associated-Types">Associated Types</h4><p>Rust has a standard <code>Iterator</code> trait, defined like this:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">pub</span> <span class="hljs-keyword">trait</span> <span class="hljs-title class_">Iterator</span> &#123; <br>    <span class="hljs-keyword">type</span> <span class="hljs-title class_">Item</span>; <br>    <br>    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">next</span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>) <span class="hljs-punctuation">-&gt;</span> <span class="hljs-type">Option</span>&lt;<span class="hljs-keyword">Self</span>::Item&gt;;<br>    ...<br>&#125;<br></code></pre></td></tr></table></figure><p>The first feature of this trait, <code>type Item;</code>, is an associated type. Each type that implements Iterator must specify what type of item it produces.</p><p>Here’s what it looks like to implement Iterator for a type:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-comment">// (code from the std::env standard library module) </span><br><span class="hljs-keyword">impl</span> <span class="hljs-title class_">Iterator</span> <span class="hljs-keyword">for</span> <span class="hljs-title class_">Args</span> &#123; <br>    <span class="hljs-keyword">type</span> <span class="hljs-title class_">Item</span> = <span class="hljs-type">String</span>; <br>    <br>    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">next</span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>) <span class="hljs-punctuation">-&gt;</span> <span class="hljs-type">Option</span>&lt;<span class="hljs-type">String</span>&gt; &#123; ... &#125; <br>    ... <br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">dump</span>(iter: &amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">dyn</span> <span class="hljs-built_in">Iterator</span>&lt;Item = <span class="hljs-type">String</span>&gt;) &#123;<br>    <span class="hljs-keyword">for</span> (index, s) <span class="hljs-keyword">in</span> iter.<span class="hljs-title function_ invoke__">enumerate</span>() &#123;<br>        <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;&#123;&#125;: &#123;:?&#125;&quot;</span>, index, s);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Chapter-13-Utility-Traits">Chapter 13 Utility Traits</h2><h3 id="Deref-and-DerefMut">Deref and DerefMut</h3><p>Pointer types like <code>Box&lt;T&gt;</code> and <code>Rc&lt;T&gt;</code> implement these traits so that they can behave as Rust’s built-in pointer types do.</p><p>The traits are defined like this:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">trait</span> <span class="hljs-title class_">Deref</span> &#123; <br>    <span class="hljs-keyword">type</span> <span class="hljs-title class_">Target</span>: ?<span class="hljs-built_in">Sized</span>; <br>    <br>    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">deref</span>(&amp;<span class="hljs-keyword">self</span>) <span class="hljs-punctuation">-&gt;</span> &amp;<span class="hljs-keyword">Self</span>::Target; <br>&#125; <br><br><span class="hljs-keyword">trait</span> <span class="hljs-title class_">DerefMut</span>: Deref &#123; <br>    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">deref_mut</span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>) <span class="hljs-punctuation">-&gt;</span> &amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">Self</span>::Target; <br>&#125;<br></code></pre></td></tr></table></figure><p>The <code>deref</code> and <code>deref_mut</code> methods take a <code>&amp;Self</code> reference and return a <code>&amp;Self::Target</code> reference. <code>Target</code> should be something that <code>Self</code> contains, owns, or refers to: for <code>Box&lt;Complex&gt;</code> the <code>Target</code> type is <code>Complex</code>.</p><h2 id="Chapter-14-Closures">Chapter 14 Closures</h2><h3 id="Capturing-Variables">Capturing Variables</h3><h4 id="Closures-That-Borrow">Closures That Borrow</h4><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-comment">/// Sort by any of several different statistics. </span><br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">sort_by_statistic</span>(cities: &amp;<span class="hljs-keyword">mut</span> <span class="hljs-type">Vec</span>&lt;City&gt;, stat: Statistic) &#123; <br>    cities.<span class="hljs-title function_ invoke__">sort_by_key</span>(|city| -city.<span class="hljs-title function_ invoke__">get_statistic</span>(stat)); <br>&#125;<br></code></pre></td></tr></table></figure><p>In this case, when Rust creates the closure, it automatically borrows a reference to stat.</p><p>Since the closure contains a reference to stat, Rust won’t let it outlive stat. Since the closure is only used during sorting, this example is fine.</p><h4 id="Closures-That-Steal">Closures That Steal</h4><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">use</span> std::thread; <br><br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">start_sorting_thread</span>(<span class="hljs-keyword">mut</span> cities: <span class="hljs-type">Vec</span>&lt;City&gt;, stat: Statistic) <br>    <span class="hljs-punctuation">-&gt;</span> thread::JoinHandle&lt;<span class="hljs-type">Vec</span>&lt;City&gt;&gt; &#123; <br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">key_fn</span> = |city: &amp;City| <span class="hljs-punctuation">-&gt;</span> <span class="hljs-type">i64</span> &#123; -city.<span class="hljs-title function_ invoke__">get_statistic</span>(stat) &#125;; <br>    thread::<span class="hljs-title function_ invoke__">spawn</span>(|| &#123; <br>        cities.<span class="hljs-title function_ invoke__">sort_by_key</span>(key_fn); <br>        cities <br>    &#125;) <br>&#125;<br></code></pre></td></tr></table></figure><p>Rust will reject this program because “closure may outlive the current function, but it borrows <code>stat</code>, which is owned by the current function”.</p><p>Tell Rust to <em><strong>move</strong></em> cities and stat into the closures that use them instead of borrowing references to them.</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">start_sorting_thread</span>(<span class="hljs-keyword">mut</span> cities: <span class="hljs-type">Vec</span>&lt;City&gt;, stat: Statistic) <br>    <span class="hljs-punctuation">-&gt;</span> thread::JoinHandle&lt;<span class="hljs-type">Vec</span>&lt;City&gt;&gt; &#123; <br>        <span class="hljs-keyword">let</span> <span class="hljs-variable">key_fn</span> = <span class="hljs-keyword">move</span> |city: &amp;City| <span class="hljs-punctuation">-&gt;</span> <span class="hljs-type">i64</span> &#123; -city.<span class="hljs-title function_ invoke__">get_statistic</span>(stat) &#125;; <br>        thread::<span class="hljs-title function_ invoke__">spawn</span>(<span class="hljs-keyword">move</span> || &#123; <br>            cities.<span class="hljs-title function_ invoke__">sort_by_key</span>(key_fn); <br>            cities <br>        &#125;) <br>&#125;<br></code></pre></td></tr></table></figure><p>The <code>move</code> keyword tells Rust that a closure doesn’t borrow the variables it uses: it steals them.</p><p>Rust thus offers two ways for closures to get data from enclosing scopes: moves and borrowing. A few case in point:</p><ul><li>Just as everywhere else in the language, if a closure would move a value of a copyable type, like i 32, it copies the value instead.</li><li>Values of noncopyable types, like <code>Vec&lt;City&gt;</code>, really are moved: the preceding code transfers cities to the new thread, by way of the <em><strong>move</strong></em> closure.</li></ul><blockquote><p>We get something important by accepting Rust’s strict rules: thread safety. It is precisely because the vector is moved, rather than being shared across threads, that we know the old thread won’t free the vector while the new thread is modifying it.</p></blockquote><h3 id="Function-and-Closure-Types">Function and Closure Types</h3><p>A function can take another function as an argument.</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-comment">/// Given a list of cities and a test function, </span><br><span class="hljs-comment">/// return how many cities pass the test. </span><br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">count_selected_cities</span>(cities: &amp;<span class="hljs-type">Vec</span>&lt;City&gt;, <br>                        test_fn: <span class="hljs-title function_ invoke__">fn</span>(&amp;City) <span class="hljs-punctuation">-&gt;</span> <span class="hljs-type">bool</span>) <span class="hljs-punctuation">-&gt;</span> <span class="hljs-type">usize</span> &#123; <br>    <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">count</span> = <span class="hljs-number">0</span>; <br>    <span class="hljs-keyword">for</span> <span class="hljs-variable">city</span> <span class="hljs-keyword">in</span> cities &#123; <br>        <span class="hljs-keyword">if</span> <span class="hljs-title function_ invoke__">test_fn</span>(city) &#123; <br>            count += <span class="hljs-number">1</span>;<br>        &#125;<br>    &#125;<br>    count<br>&#125;<br><br><span class="hljs-comment">/// An example of a test function. Note that the type of </span><br><span class="hljs-comment">/// this function is `fn(&amp;City) -&gt; bool`, the same as /// the `test_fn` argument to `count_selected_cities`. </span><br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">has_monster_attacks</span>(city: &amp;City) <span class="hljs-punctuation">-&gt;</span> <span class="hljs-type">bool</span> &#123; <br>    city.monster_attack_risk &gt; <span class="hljs-number">0.0</span> <br>&#125; <br><br><span class="hljs-comment">// How many cities are at risk for monster attack? </span><br><span class="hljs-keyword">let</span> <span class="hljs-variable">n</span> = <span class="hljs-title function_ invoke__">count_selected_cities</span>(&amp;my_cities, has_monster_attacks);<br></code></pre></td></tr></table></figure><p>After all this, it may come as a surprise that <em><strong>closures do not have the same type as functions</strong></em>:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-variable">n</span> = <span class="hljs-title function_ invoke__">count_selected_cities</span>( <br> &amp;my_cities, <br> |city| city.monster_attack_risk &gt; limit); <span class="hljs-comment">// error: type mismatch</span><br></code></pre></td></tr></table></figure><p>To support closures, we must change the type signature of this function.</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">count_selected_cities</span>&lt;F&gt;(cities: &amp;<span class="hljs-type">Vec</span>&lt;City&gt;, test_fn: F) <span class="hljs-punctuation">-&gt;</span> <span class="hljs-type">usize</span> <br>    <span class="hljs-keyword">where</span> F: <span class="hljs-title function_ invoke__">Fn</span>(&amp;City) <span class="hljs-punctuation">-&gt;</span> <span class="hljs-type">bool</span> &#123; <br>    <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">count</span> = <span class="hljs-number">0</span>; <br>    <span class="hljs-keyword">for</span> <span class="hljs-variable">city</span> <span class="hljs-keyword">in</span> cities &#123; <br>        <span class="hljs-keyword">if</span> <span class="hljs-title function_ invoke__">test_fn</span>(city) &#123; <br>            count += <span class="hljs-number">1</span>; <br>        &#125; <br>    &#125; <br>    count <br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-title function_ invoke__">fn</span>(&amp;City) <span class="hljs-punctuation">-&gt;</span> <span class="hljs-type">bool</span> <span class="hljs-comment">// fn type (functions only) </span><br><span class="hljs-title function_ invoke__">Fn</span>(&amp;City) <span class="hljs-punctuation">-&gt;</span> <span class="hljs-type">bool</span> <span class="hljs-comment">// Fn trait (both functions and closures)</span><br></code></pre></td></tr></table></figure><blockquote><p>In fact, every closure you write has its own type, because a closure may contain data: values either borrowed or stolen from enclosing scopes. This could be any number of variables, in any combination of types. <em><strong>So every closure has an ad hoc type created by the compiler, large enough to hold that data.</strong></em></p></blockquote><h3 id="Closures-and-Safety">Closures and Safety</h3><h4 id="Closures-That-Kill">Closures That Kill</h4><p><em><strong>A closure that can be called only once</strong></em> may seem like a rather extraordinary thing, but we’ve been talking throughout this book about ownership and lifetimes. The idea of values being used up (that is, moved) is one of the core concepts in Rust. It works the same with closures as with everything else.</p><h4 id="FnOnce">FnOnce</h4><p>Closures that drop values implement a less powerful trait, <code>FnOnce</code>, <em><strong>the trait of closures that can be called once</strong></em>.</p><p>The first time you call a <code>FnOnce</code> closure, <em><strong>the closure itself is used up</strong></em>.</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-comment">// Pseudocode for `Fn` and `FnOnce` traits with no arguments. </span><br><span class="hljs-keyword">trait</span> <span class="hljs-title class_">Fn</span>() <span class="hljs-punctuation">-&gt;</span> R &#123; <br> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">call</span>(&amp;<span class="hljs-keyword">self</span>) <span class="hljs-punctuation">-&gt;</span> R; <br>&#125; <br><br><span class="hljs-keyword">trait</span> <span class="hljs-title class_">FnOnce</span>() <span class="hljs-punctuation">-&gt;</span> R &#123; <br> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">call_once</span>(<span class="hljs-keyword">self</span>) <span class="hljs-punctuation">-&gt;</span> R; <br>&#125;<br></code></pre></td></tr></table></figure><h4 id="FnMut">FnMut</h4><p>There is one more kind of closure, the kind that contains mutable data or <code>mut</code> references.</p><p>Rust considers non-mut values safe to share across threads. But it wouldn’t be safe to share non-mut closures that contain <code>mut</code> data: calling such a closure from multiple threads could lead to all sorts of race conditions as multiple threads try to read and write the same data at the same time.</p><p><code>FnMut</code> closures are called by mut reference:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">trait</span> <span class="hljs-title class_">FnMut</span>() <span class="hljs-punctuation">-&gt;</span> R &#123; <br> <span class="hljs-keyword">fn</span> <span class="hljs-title function_">call_mut</span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>) <span class="hljs-punctuation">-&gt;</span> R; <br>&#125;<br></code></pre></td></tr></table></figure><p><em><strong>Any closure that requires mut access to a value, but doesn’t drop any values, is an <code>FnMut</code> closure.</strong></em></p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">i</span> = <span class="hljs-number">0</span>; <br><span class="hljs-keyword">let</span> <span class="hljs-variable">incr</span> = || &#123; <br> i += <span class="hljs-number">1</span>; <span class="hljs-comment">// incr borrows a mut reference to i </span><br> <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;Ding! i is now: &#123;&#125;&quot;</span>, i); <br>&#125;; <br><span class="hljs-title function_ invoke__">call_twice</span>(incr);<br></code></pre></td></tr></table></figure><p>A summary:</p><ul><li><code>Fn</code> is the family of closures and functions that you can call multiple times without restriction. This highest category also includes all fn functions.</li><li><code>FnMut</code> is the family of closures that can be called multiple times if the closure itself is declared mut.</li><li><code>FnOnce</code> is the family of closures that can be called once, if the caller owns the closure.</li></ul><p>Every <code>Fn</code> meets the requirements for <code>FnMut</code>, and every <code>FnMut</code> meets the requirements for <code>FnOnce</code>.</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20240209184800948.png" alt="image-20240209184800948"></p><h4 id="Copy-and-Clone-for-Closures">Copy and Clone for Closures</h4><p>The rules for <code>Copy</code> and <code>Clone</code> on closures are just like the <code>Copy</code> and <code>Clone</code> rules for regular structs:</p><ul><li>A non-move closure that doesn’t mutate variables holds only shared references, which are both <code>Clone</code> and <code>Copy</code>, so that closure is both <code>Clone</code> and <code>Copy</code> as well.</li><li>A non-move closure that <em><strong>does</strong></em> mutate values has mutable references within its internal representation. Mutable references are neither <code>Clone</code> nor <code>Copy</code>, so neither is a closure that uses them.</li><li>For a <em><strong>move</strong></em> closure, the rules are even simpler. If everything a move closure captures is <code>Copy</code>, it’s <code>Copy</code>. If everything it captures is <code>Clone</code>, it’s <code>Clone</code>.</li></ul><h2 id="Chapter-15-Iterators">Chapter 15 Iterators</h2><p>An <em><strong>iterator</strong></em> is a value that produces a sequence of values, typically for a loop to operate on.</p><p>here’s some terminology for iterators:</p><ul><li>An iterator is any type that implements <code>Iterator</code>.</li><li>An iterable is any type that implements <code>IntoIterator</code>: you can get an iterator over it by calling its <code>into_iter</code> method.<ul><li>The vector reference &amp;v is the iterable in this case.</li></ul></li><li>An iterator produces values.</li><li>The values an iterator produces are <code>items</code>.</li><li>The code that receives the items an iterator produces is the consumer.</li></ul><h3 id="Creating-Iterators">Creating Iterators</h3><p>Most collection types provide <code>iter</code> and <code>iter_mut</code> methods that return the natural iterators over the type, <em><strong>producing a shared or mutable reference to each item</strong></em>.</p><h4 id="IntoIterator-Implementations">IntoIterator Implementations</h4><p>When a type implements IntoIterator, you can call its into_iter method yourself, just as a for loop would.</p><p>Most collections actually provide several implementations of IntoIterator, for shared references (&amp;T), mutable references (&amp;mut T), and moves (T):</p><ul><li>Given a shared reference to the collection, <code>into_iter</code> returns an iterator that produces shared references to its items. For example, in the preceding code, (&amp;favorites).into_iter() would return an iterator whose Item type is <code>&amp;String</code>.</li><li>Given a mutable reference to the collection, <code>into_iter</code> returns an iterator that produces mutable references to the items. For example, if vector is some <code>Vec&lt;String&gt;</code>, the call <code>(&amp;mut vector).into_iter()</code> returns an iterator whose Item type is <code>&amp;mut String</code>.</li><li>When passed the collection by value, into_iter returns an iterator that takes ownership of the collection and returns items by value; the items’ ownership moves from the collection to the consumer, and the original collection is consumed in the process. For example, the call <code>favorites.into_iter()</code> in the preceding code returns an iterator that produces each string by value; the consumer receives ownership of each string. When the iterator is dropped, any elements remaining in the BTreeSet are dropped too, and the set’s now-empty husk is disposed of.</li></ul><p>Just like:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">for</span> <span class="hljs-variable">element</span> <span class="hljs-keyword">in</span> &amp;collection &#123; ... &#125; <br><span class="hljs-keyword">for</span> <span class="hljs-variable">element</span> <span class="hljs-keyword">in</span> &amp;<span class="hljs-keyword">mut</span> collection &#123; ... &#125; <br><span class="hljs-keyword">for</span> <span class="hljs-variable">element</span> <span class="hljs-keyword">in</span> collection &#123; ... &#125;<br></code></pre></td></tr></table></figure><blockquote><p><code>IntoIterator</code> is what makes <code>for</code> loops work, so that’s obviously necessary. But when you’re not using a for loop, it’s clearer to write <code>favorites.iter()</code> than <code>(&amp;favorites).into_iter()</code>. Iteration by shared reference is something you’ll need frequently, so iter and iter_mut are still valuable for their ergonomics.</p></blockquote><p><code>IntoIterator</code> can also be useful in generic code: you can use a bound like <code>T: IntoIterator</code> to restrict the type variable <code>T</code> to types that can be iterated over. Or, you can write <code>T: IntoIterator&lt;Item=U&gt;</code> to further require the iteration to produce a particular type <code>U</code>.</p><h2 id="Chapter-18-Collections">Chapter 18 Collections</h2><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20240210111243798.png" alt="image-20240210111243798"></p><h3 id="Vec-T"><code>Vec&lt;T&gt;</code></h3><h2 id="Chapter-18-Input-and-Output">Chapter 18 Input and Output</h2><p>Rust’s standard library features for input and output are organized around three traits, <code>Read</code>, <code>BufRead</code>, and <code>Write</code>:</p><ul><li>Values that implement <code>Read</code> have methods <em><strong>for byte-oriented input</strong></em>. They’re called <em><strong>readers</strong></em>.</li><li>Values that implement <code>BufRead</code> are buffered readers. <em><strong>They support all the methods of <code>Read</code>, plus methods for reading lines of text and so forth</strong></em>.</li><li>Values that implement <code>Write</code> support both byte-oriented and UTF-8 text output. They’re called <em><strong>writers</strong></em>.</li></ul><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20240210112953117.png" alt="image-20240210112953117"></p><h3 id="Readers-and-Writers">Readers and Writers</h3><h4 id="Reader">Reader</h4><p><code>std::io::Read</code> has several methods for reading data. All of them take the reader itself by <code>mut</code> reference.</p><ul><li><code>reader.read(&amp;mut buffer)</code><ul><li>Reads some bytes from the data source and stores them in the given <code>buffer</code>.</li></ul></li><li><code>reader.read_to_end(&amp;mut byte_vec)</code><ul><li>Reads all remaining input from this reader, appending it to <code>byte_vec</code>, which is a <code>Vec&lt;u8&gt;</code>.</li></ul></li><li><code>reader.read_to_string(&amp;mut string)</code><ul><li>This is the same, but appends the data to the given <code>String</code>.</li></ul></li><li><code>reader.read_exact(&amp;mut buf)</code><ul><li>Reads exactly enough data to fill the given buffer. If the reader runs out of data before reading <code>buf.len()</code> bytes, this returns an error.</li></ul></li></ul><h3 id="Buffered-Readers">Buffered Readers</h3><ul><li><code>reader.read_line(&amp;mut line)</code><ul><li>Reads a line of text and appends it to line, which is a <code>String</code>.</li></ul></li><li><code>reader.lines()</code><ul><li>Returns an iterator over the lines of the input.</li></ul></li></ul><h2 id="Chapter-19-Concurrency">Chapter 19 Concurrency</h2><h3 id="Fork-Join-Parallelism">Fork-Join Parallelism</h3><h4 id="spawn-and-join">spawn and join</h4><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">use</span> std::&#123;io, thread&#125;;<br><br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">process_files_in_parallel</span>(filenames: <span class="hljs-type">Vec</span>&lt;<span class="hljs-type">String</span>&gt;) <span class="hljs-punctuation">-&gt;</span> io::<span class="hljs-type">Result</span>&lt;()&gt; &#123;<br>    <span class="hljs-comment">// Divide the work into several chunks.</span><br>    <span class="hljs-keyword">const</span> NTHREADS: <span class="hljs-type">usize</span> = <span class="hljs-number">8</span>;<br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">worklists</span> = <span class="hljs-title function_ invoke__">split_vec_into_chunks</span>(filenames, NTHREADS);<br><br>    <span class="hljs-comment">// Fork: Spawn a thread to handle each chunk.</span><br>    <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">thread_handles</span> = <span class="hljs-built_in">vec!</span>[];<br>    <span class="hljs-keyword">for</span> <span class="hljs-variable">worklist</span> <span class="hljs-keyword">in</span> worklists &#123;<br>        thread_handles.<span class="hljs-title function_ invoke__">push</span>(thread::<span class="hljs-title function_ invoke__">spawn</span>(<span class="hljs-keyword">move</span> || <span class="hljs-title function_ invoke__">process_files</span>(worklist)));<br>    &#125; <span class="hljs-comment">// Join: Wait for all threads to finish.</span><br>    <span class="hljs-keyword">for</span> <span class="hljs-variable">handle</span> <span class="hljs-keyword">in</span> thread_handles &#123;<br>        handle.<span class="hljs-title function_ invoke__">join</span>().<span class="hljs-title function_ invoke__">unwrap</span>()?;<br>    &#125;<br>    <span class="hljs-title function_ invoke__">Ok</span>(())<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="Sharing-Immutable-Data-Across-Threads">Sharing Immutable Data Across Threads</h4><p><code>spawn</code> launches independent threads. Rust has no way of knowing how long the child thread will run, so it assumes the worst: it assumes the child thread may keep running even after the parent thread has finished and all values in the parent thread are gone.</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">use</span> std::sync::Arc; <br><br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">process_files_in_parallel</span>(filenames: <span class="hljs-type">Vec</span>&lt;<span class="hljs-type">String</span>&gt;, <br>                        glossary: Arc&lt;GigabyteMap&gt;) <span class="hljs-punctuation">-&gt;</span> io::<span class="hljs-type">Result</span>&lt;()&gt; &#123; <br>    ... <br>    <span class="hljs-keyword">for</span> <span class="hljs-variable">worklist</span> <span class="hljs-keyword">in</span> worklists &#123; <br>        <span class="hljs-comment">// This call to .clone() only clones the Arc and bumps the </span><br>        <span class="hljs-comment">// reference count. It does not clone the GigabyteMap. </span><br>        <span class="hljs-keyword">let</span> <span class="hljs-variable">glossary_for_child</span> = glossary.<span class="hljs-title function_ invoke__">clone</span>(); <br>        thread_handles.<span class="hljs-title function_ invoke__">push</span>( <br>                <span class="hljs-title function_ invoke__">spawn</span>(<span class="hljs-keyword">move</span> || <span class="hljs-title function_ invoke__">process_files</span>(worklist, &amp;glossary_for_child)) <br>                ); <br>    &#125; <br>    ...<br>&#125;<br></code></pre></td></tr></table></figure><p>As long as <em><strong>any</strong></em> thread owns an <code>Arc&lt;GigabyteMap&gt;</code>, it will keep the map alive, even if the parent thread bails out early. There won’t be any data races, because data in an <code>Arc</code> is immutable.</p><h3 id="Channels">Channels</h3><p>A <em><strong>channel</strong></em> is a one-way conduit for sending values from one thread to another. In other words, it’s a thread-safe queue.</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20240210120702288.png" alt="image-20240210120702288"></p><h4 id="Thread-Safety-Send-and-Sync">Thread Safety: Send and Sync</h4><p>Rust’s full thread safety story hinges on two built-in traits, <code>std::marker::Send</code> and <code>std::marker::Sync</code>.</p><ul><li>Types that implement <code>Send</code> are safe to pass by value to another thread. They can be moved across threads.</li><li>Types that implement <code>Sync</code> are safe to pass by non-mut reference to another thread. They can be shared across threads.</li></ul><blockquote><p>By <em><strong>safe</strong></em> here, we mean the same thing we always mean: free from data races and other undefined behavior.</p></blockquote><p>A struct or enum is <code>Send</code> if its fields are <code>Send</code>, and <code>Sync</code> if its fields are <code>Sync</code>.</p><h3 id="Shared-Mutable-State">Shared Mutable State</h3><blockquote><p>In C++, as in most languages, the data and the lock are separate objects. Ideally, comments explain that every thread must acquire the mutex before touching the data.</p></blockquote><p>Unlike C++, in Rust the protected data is stored inside the Mutex. Setting up the Mutex looks like this:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">use</span> std::sync::Arc; <br><br><span class="hljs-keyword">let</span> <span class="hljs-variable">app</span> = Arc::<span class="hljs-title function_ invoke__">new</span>(FernEmpireApp &#123; <br>    ...<br>     waiting_list: Mutex::<span class="hljs-title function_ invoke__">new</span>(<span class="hljs-built_in">vec!</span>[]), <br>     ... <br> &#125;);<br></code></pre></td></tr></table></figure><p><code>Arc</code> is handy for sharing things across threads, and <code>Mutex</code> is handy for mutable data that’s shared across threads.</p><p>The only way to get at the data is to call the <code>.lock()</code> method:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">guard</span> = <span class="hljs-keyword">self</span>.waiting_list.<span class="hljs-title function_ invoke__">lock</span>().<span class="hljs-title function_ invoke__">unwrap</span>();<br></code></pre></td></tr></table></figure><h4 id="mut-and-Mutex">mut and Mutex</h4><p>In Rust, <code>&amp;mut</code> <em><strong>means exclusive access</strong></em>. Plain <code>&amp;</code> means <em><strong>shared access</strong></em>.</p><p><code>Mutex</code> does have a way: the lock. In fact, a mutex is little more than a way to do exactly this, to provide <em><strong>exclusive</strong></em> (<code>mut</code>) access to the data inside, even though many threads may have <em><strong>shared</strong></em> (<code>non-mut</code>) access to the <code>Mutex</code> itself.</p><p>If a thread panics while holding a <code>Mutex</code>, Rust marks the Mutex as <em><strong>poisoned</strong></em>. Any subsequent attempt to lock the poisoned Mutex will get an error result. But you <em><strong>can</strong></em> still lock a poisoned mutex and access the data inside, with mutual exclusion fully enforced; see the documentation for <code>PoisonError::into_inner()</code>. But you won’t do it by accident.</p><h4 id="Condition-Variables-Condvar">Condition Variables (Condvar)</h4><p>A Condvar has methods <code>.wait()</code> and <code>.notify_all()</code>; <code>.wait()</code> blocks until some other thread calls <code>.notify_all()</code>.</p><h2 id="Chapter-20-Asynchronous-Programming">Chapter 20 Asynchronous Programming</h2><p>You can use Rust <em><strong>asynchronous tasks</strong></em> to interleave many independent activities on a single thread or a pool of worker threads. Asynchronous tasks are similar to threads, but are much quicker to create, pass control amongst themselves more efficiently, and have memory overhead an order of magnitude less than that of a thread.</p><p>It is perfectly feasible to have hundreds of thousands of asynchronous tasks running simultaneously in a single program.</p><p>Before:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">use</span> std::&#123;net, thread&#125;; <br><br><span class="hljs-keyword">let</span> <span class="hljs-variable">listener</span> = net::TcpListener::<span class="hljs-title function_ invoke__">bind</span>(address)?; <br><br><span class="hljs-keyword">for</span> <span class="hljs-variable">socket_result</span> <span class="hljs-keyword">in</span> listener.<span class="hljs-title function_ invoke__">incoming</span>() &#123; <br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">socket</span> = socket_result?; <br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">groups</span> = chat_group_table.<span class="hljs-title function_ invoke__">clone</span>(); <br>    thread::<span class="hljs-title function_ invoke__">spawn</span>(|| &#123; <br>        <span class="hljs-title function_ invoke__">log_error</span>(<span class="hljs-title function_ invoke__">serve</span>(socket, groups)); <br>    &#125;); <br>&#125;<br></code></pre></td></tr></table></figure><p>After:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">use</span> async_std::&#123;net, task&#125;; <br><br><span class="hljs-keyword">let</span> <span class="hljs-variable">listener</span> = net::TcpListener::<span class="hljs-title function_ invoke__">bind</span>(address).<span class="hljs-keyword">await</span>?; <br><br><span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">new_connections</span> = listener.<span class="hljs-title function_ invoke__">incoming</span>(); <br><span class="hljs-keyword">while</span> <span class="hljs-keyword">let</span> <span class="hljs-variable">Some</span>(socket_result) = new_connections.<span class="hljs-title function_ invoke__">next</span>().<span class="hljs-keyword">await</span> &#123; <br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">socket</span> = socket_result?; <br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">groups</span> = chat_group_table.<span class="hljs-title function_ invoke__">clone</span>(); <br>    task::<span class="hljs-title function_ invoke__">spawn</span>(<span class="hljs-keyword">async</span> &#123; <br>        <span class="hljs-title function_ invoke__">log_error</span>(<span class="hljs-title function_ invoke__">serve</span>(socket, groups).<span class="hljs-keyword">await</span>); <br>    &#125;); <br>&#125;<br></code></pre></td></tr></table></figure><h3 id="From-Synchronous-to-Asynchronous">From Synchronous to Asynchronous</h3><h4 id="Futures">Futures</h4><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">trait</span> <span class="hljs-title class_">Future</span> &#123; <br>    <span class="hljs-keyword">type</span> <span class="hljs-title class_">Output</span>;<br>    <span class="hljs-comment">// For now, read `Pin&lt;&amp;mut Self&gt;` as `&amp;mut Self`. </span><br>    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">poll</span>(<span class="hljs-keyword">self</span>: Pin&lt;&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">Self</span>&gt;, cx: &amp;<span class="hljs-keyword">mut</span> Context&lt;<span class="hljs-symbol">&#x27;_</span>&gt;) <br>                    <span class="hljs-punctuation">-&gt;</span> Poll&lt;<span class="hljs-keyword">Self</span>::Output&gt;; <br>&#125; <br><br><span class="hljs-keyword">enum</span> <span class="hljs-title class_">Poll</span>&lt;T&gt; &#123; <br>    <span class="hljs-title function_ invoke__">Ready</span>(T), <br>    Pending, <br>&#125;<br></code></pre></td></tr></table></figure><p>A future’s <code>poll</code> method never waits for the operation to finish: it always returns immediately.</p><p>If and when the future is worth polling again, it promises to let us know by invoking a waker, a callback function supplied in the Context. We call this the “piñata model” of asynchronous programming: the only thing you can do with a future is whack it with a poll until a value falls out.</p><hr><h2 id="Deref">Deref</h2><p>Rust 中引用既像指针，又不是那么的像指针：</p><ul><li>一方面 rust 中具有引用类型的变量的内存布局和 C 语言中的指针几乎是一样的</li><li>而另一方面，rust 中将“创建一个变量的引用”这种动作称呼为“借用这个变量”，<strong>同时我们的确可以隔着若干层变量的引用对一个变量进行操作</strong><ul><li>Rust 的方法解析时的自动借用/自动解引用机制</li></ul></li></ul><p>Rust 中，将一个方法调用(method call)的点号左侧的值称为&quot;方法的 receiver&quot;，而 rust 规定，在进行方法调用解析时，可以对 receiver 做以下的操作，来寻找合法的方法调用：</p><p>假设receiver具有类型<code>T</code>，重复执行以下操作直到<code>T</code>不再改变：</p><p>（1）使<code>U=T</code></p><p>（2）将<code>U</code>，<code>&amp;U</code>，<code>&amp;mut U</code>加入解析列表</p><p>（3）对<code>U</code>解引用，使<code>T=*U</code></p><p>上述循环结束后，执行一次 <a href="https://link.zhihu.com/?target=https%3A//doc.rust-lang.org/reference/type-coercions.html%23unsized-coercions">unsized coercion</a>，并使得 <code>T</code> 等于 unsized coercion 的得到的结果类型再次执行一次（2）和（3），最终得到一个完整的解析列表；最后，按顺序尝试将解析列表中的类型匹配到方法上，且最终的解析结果不能有冲突</p><p>用星号 <code>*</code> 操作符解引用时，实际执行的动作有两种情况：</p><ul><li>1.直接解引用：被解引用的表达式具有引用类型，那么就直接去掉一层 indirection</li><li>2.执行 <code>*(x.deref())</code>（来自 Deref Trait）：被解引用的表达式<strong>不具有引用类型</strong></li></ul><h3 id="Deref-Trait">Deref Trait</h3><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">pub</span> <span class="hljs-keyword">trait</span> <span class="hljs-title class_">Deref</span> &#123;<br>    <span class="hljs-keyword">type</span> <span class="hljs-title class_">Target</span>: ?<span class="hljs-built_in">Sized</span>;<br>    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">deref</span>(&amp;<span class="hljs-keyword">self</span>)<span class="hljs-punctuation">-&gt;</span>&amp;<span class="hljs-keyword">Self</span>::Target; <span class="hljs-comment">//需要impl deref,返回一个类型为Target的引用</span><br>&#125;<br></code></pre></td></tr></table></figure><p>对于一个实现了Deref Trait的类型为<code>T</code>的表达式<code>x</code>来说，如果<code>Target=U</code>，那么：</p><ul><li><code>*x</code>等价于<code>*(x.deref())</code>：你从一个<code>T</code>得到一个<code>U</code> （x不是引用或者裸指针）</li><li>允许<code>&amp;T</code>类型，或者<code>&amp;mut T</code>的表达式被强转为<code>&amp;U</code>类型<ul><li>因为<code>&amp;T</code>可以被转换(coerce)到<code>&amp;U</code>，<code>T</code>类型会自动实现所有<code>U</code>类型的不可变方法</li></ul></li></ul><blockquote><p>假设x是一个引用（也就是一个指针），*x的本意是得到指针类型指向的内存位置，即是一个具体的值</p><p>x.deref()获取到的是值的引用，和*的原意不一致，所以应该是*(x.deref())</p></blockquote><p>如果类型T实现了Deref(Target=U)和DerefMut(Target=U)，那么就相当于类型T自动实现了类型U的所有方法</p><p>因为Rust的自动借用/自动解引用机制：T会被解引用（通过执行*(T.deref()）来得到U</p><h2 id="Type-Coercions">Type Coercions</h2><p><strong>Type coercions</strong> are implicit operations that change the type of a value.</p><blockquote><p>Type Coercion包含了Deref Coercion</p><p><em>Deref coercion</em> converts a reference to a type that implements the <code>Deref</code> trait into a reference to another type.</p><p>Deref coercion is a convenience Rust <strong>performs on arguments</strong> to functions and methods.</p></blockquote><h3 id="Coercion-Sites">Coercion Sites</h3><p>Type Coercions会发生在程序的以下地方</p><ul><li><p><code>let</code> statements where an explicit type is given.</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">let</span> <span class="hljs-variable">_</span>: &amp;<span class="hljs-type">i8</span> = &amp;<span class="hljs-keyword">mut</span> <span class="hljs-number">42</span>;<br></code></pre></td></tr></table></figure></li><li><p>Arguments for function and method calls</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">bar</span>(_: &amp;<span class="hljs-type">i8</span>) &#123; &#125;<br><br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() &#123;<br>    <span class="hljs-title function_ invoke__">bar</span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-number">42</span>);<br>&#125;<br></code></pre></td></tr></table></figure><blockquote><p>针对的是Function和Method的<strong>参数</strong>（不包括调用方的处理）</p></blockquote></li></ul><h3 id="Rules">Rules</h3><p>Coercion is allowed between the following types:</p><ul><li><p><code>T</code> to <code>U</code> if <code>T</code> is a <a href="https://doc.rust-lang.org/reference/subtyping.html">subtype</a> of <code>U</code> (<em>reflexive case</em>)</p></li><li><p><code>T_1</code> to <code>T_3</code> where <code>T_1</code> coerces to <code>T_2</code> and <code>T_2</code> coerces to <code>T_3</code> (<em>transitive case</em>)</p><p>Note that this is not fully supported yet.</p></li><li><p><code>&amp;mut T</code> to <code>&amp;T</code></p></li><li><p><code>*mut T</code> to <code>*const T</code></p></li><li><p><code>&amp;T</code> to <code>*const T</code></p></li><li><p><code>&amp;mut T</code> to <code>*mut T</code></p></li><li><p><code>&amp;T</code> or <code>&amp;mut T</code> to <code>&amp;U</code> if <code>T</code> implements <code>Deref&lt;Target = U&gt;</code>. For example:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">use</span> std::ops::Deref;<br><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">CharContainer</span> &#123;<br>    value: <span class="hljs-type">char</span>,<br>&#125;<br><br><span class="hljs-keyword">impl</span> <span class="hljs-title class_">Deref</span> <span class="hljs-keyword">for</span> <span class="hljs-title class_">CharContainer</span> &#123;<br>    <span class="hljs-keyword">type</span> <span class="hljs-title class_">Target</span> = <span class="hljs-type">char</span>;<br><br>    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">deref</span>&lt;<span class="hljs-symbol">&#x27;a</span>&gt;(&amp;<span class="hljs-symbol">&#x27;a</span> <span class="hljs-keyword">self</span>) <span class="hljs-punctuation">-&gt;</span> &amp;<span class="hljs-symbol">&#x27;a</span> <span class="hljs-type">char</span> &#123;<br>        &amp;<span class="hljs-keyword">self</span>.value<br>    &#125;<br>&#125;<br><br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">foo</span>(arg: &amp;<span class="hljs-type">char</span>) &#123;&#125;<br><br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() &#123;<br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">x</span> = &amp;<span class="hljs-keyword">mut</span> CharContainer &#123; value: <span class="hljs-string">&#x27;y&#x27;</span> &#125;;<br>    <span class="hljs-title function_ invoke__">foo</span>(x); <span class="hljs-comment">//&amp;mut CharContainer is coerced to &amp;char.</span><br>&#125;<br></code></pre></td></tr></table></figure></li></ul><h3 id="Differences-between-Deref-Coercion-and-Auto-dereferenced">Differences between Deref Coercion and Auto-dereferenced</h3><ul><li>发生的位置不一样<ul><li>Deref Coercion只发生在Function或者Method的参数上</li><li>Auto-dereferenced发生在Method的调用方上</li></ul></li><li>结果不一样<ul><li>Deref Coercion只会对Reference生效，并且一个reference经过Deref Coercion后仍然是一个reference（遵循特定的Rules）</li><li>Auto-dereferenced和Auto-referenced同时作用于Method的调用方，可能会产生reference，也可能会产生value</li></ul></li></ul><h2 id="Auto-referenced-Auto-dereferenced-with-Method">Auto-referenced &amp;&amp; Auto-dereferenced with Method</h2><blockquote><p>针对问题：为什么&amp;&amp;&amp;&amp;&amp;&amp;String或者&amp;String能够调用String的方法</p></blockquote><p>我们来分析一下Rust中Method到底是怎么执行的</p><p>通过method的第一个参数必须是self我们可以很清晰地察觉到method是如何转换为function的</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs rust">x.<span class="hljs-title function_ invoke__">method</span>() -<span class="hljs-punctuation">-&gt;</span> X::<span class="hljs-title function_ invoke__">method</span>(x)<br></code></pre></td></tr></table></figure><p>然后方法的第一参数分为两大类：</p><ul><li>self：自身，这样会发生所有权的转移</li><li>&amp;self：自身的引用，其中包括<ul><li>&amp;self: immutable reference</li><li>&amp;mut self: mutable reference</li></ul></li></ul><p>在实际应用的过程中，Rust 会自动 ref 和自动 deref 来匹配合适的参数</p><p>这个过程叫做 <code>Method lookup</code></p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs rust">receiver.<span class="hljs-title function_ invoke__">method</span>(...)<br><span class="hljs-comment">// into</span><br>ReceiverType::<span class="hljs-title function_ invoke__">method</span>(<span class="hljs-title function_ invoke__">ADJ</span>(receiver), ...) <span class="hljs-comment">// for an inherent method call</span><br></code></pre></td></tr></table></figure><p>Method lookup包含两个阶段：</p><ul><li>Probing<ul><li>Decide what method to call and how to adjust the receiver</li></ul></li><li>Confirmation<ul><li>“applies” this selection, updating the side-tables, unifying type variables, and otherwise doing side-effectful things.</li></ul></li></ul><p>我们只关心 Probing 是怎么进行的</p><ol><li>生成所有可能的 receiver</li><li>生成所有可能的 method</li><li>将 receiver 和 method 进行匹配</li></ol><p>首先，probing 会通过对 receiver type 不断地解引用，生成一系列的 steps,直到不能再解引用为止，比如类型 <code>Rc&lt;Box&lt;[T; 3]&gt;&gt;</code> 会生成以下 step</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs rust">Rc&lt;<span class="hljs-type">Box</span>&lt;[T; <span class="hljs-number">3</span>]&gt;&gt;<br><span class="hljs-type">Box</span>&lt;[T; <span class="hljs-number">3</span>]&gt;<br>[T; <span class="hljs-number">3</span>]<br>[T<br></code></pre></td></tr></table></figure><p>然后生成所有的method（这里忽略）</p><p>Finally, to actually pick the method, we will search down the steps, trying to match the receiver type against the candidate types.</p><p>在每一步中（假设该步的类型为U）：</p><ol><li>if there’s a method <code>bar</code> where the receiver type (the type of <code>self</code> in the method) matches <code>U</code> exactly</li><li>otherwise, add one auto-ref (take <code>&amp;</code> or <code>&amp;mut</code> of the receiver), and, if some method’s receiver matches <code>&amp;U</code></li></ol><p>Rust在进行方法解析时会发生自动借用/自动解引用</p><p>忙 Rust 中，将一个方法调用(method call)的点号左侧的值称为&quot;方法的 receiver&quot;，而 rust 规定，在进行方法调用解析时，可以对 receiver 做以下的操作，来寻找合法的方法调用：</p><p>假设receiver具有类型<code>T</code>，重复执行以下操作直到<code>T</code>不再改变：</p><p>（1）使<code>U=T</code></p><p>（2）将<code>U</code>，<code>&amp;U</code>，<code>&amp;mut U</code>加入解析列表</p><p>（3）对<code>U</code>解引用，使<code>T=*U</code></p><p>上述循环结束后，执行一次<a href="https://link.zhihu.com/?target=https%3A//doc.rust-lang.org/reference/type-coercions.html%23unsized-coercions">unsized coercion</a>，并使得<code>T</code>等于unsized coercion的得到的结果类型再次执行一次（2）和（3），最终得到一个完整的解析列表；最后，按顺序尝试将解析列表中的类型匹配到方法上，且最终的解析结果不能有冲突。</p><p>简单来说就是，每一步先分别试着加引用，以及加可变引用；如果不行，就对原来的类型解引用，反复尝试，直到解析成功。</p><h3 id="Example">Example</h3><p>Suppose we have a call <code>foo.refm()</code>, if <code>foo</code> has type:</p><ul><li><code>X</code>, then we start with <code>U = X</code>, <code>refm</code> has receiver type <code>&amp;...</code>, so step 1 doesn’t match, taking an auto-ref gives us <code>&amp;X</code>, and this does match (with <code>Self = X</code>), so the call is <code>RefM::refm(&amp;foo)</code></li><li><code>&amp;X</code>, starts with <code>U = &amp;X</code>, which matches <code>&amp;self</code> in the first step (with <code>Self = X</code>), and so the call is <code>RefM::refm(foo)</code></li><li><code>&amp;&amp;&amp;&amp;&amp;X</code>, this doesn’t match either step (the trait isn’t implemented for <code>&amp;&amp;&amp;&amp;X</code> or <code>&amp;&amp;&amp;&amp;&amp;X</code>), so we dereference once to get <code>U = &amp;&amp;&amp;&amp;X</code>, which matches 1 (with <code>Self = &amp;&amp;&amp;X</code>) and the call is <code>RefM::refm(*foo)</code></li><li><code>Z</code>, doesn’t match either step so it is dereferenced once, to get <code>Y</code>, which also doesn’t match, so it’s dereferenced again, to get <code>X</code>, which doesn’t match 1, but does match after auto-ref, so the call is <code>RefM::refm(&amp;**foo)</code>.</li><li><code>&amp;&amp;A</code>, the 1. doesn’t match and neither does 2. since the trait is not implemented for <code>&amp;A</code> (for 1) or <code>&amp;&amp;A</code> (for 2), so it is dereferenced to <code>&amp;A</code>, which matches 1., with <code>Self = A</code></li></ul><p>Suppose we have <code>foo.m()</code>, and that <code>A</code> isn’t <code>Copy</code>, if <code>foo</code> has type:</p><ul><li><code>A</code>, then <code>U = A</code> matches <code>self</code> directly so the call is <code>M::m(foo)</code> with <code>Self = A</code></li><li><code>&amp;A</code>, then 1. doesn’t match, and neither does 2. (neither <code>&amp;A</code> nor <code>&amp;&amp;A</code> implement the trait), so it is dereferenced to <code>A</code>, which does match, but <code>M::m(*foo)</code> requires taking <code>A</code> by value and hence moving out of <code>foo</code>, hence the error.</li><li><code>&amp;&amp;A</code>, 1. doesn’t match, but auto-ref gives <code>&amp;&amp;&amp;A</code>, which does match, so the call is <code>M::m(&amp;foo)</code> with <code>Self = &amp;&amp;&amp;A</code>.</li></ul><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">X</span> &#123; val: <span class="hljs-type">i32</span> &#125;<br><span class="hljs-keyword">impl</span> <span class="hljs-title class_">std</span>::ops::Deref <span class="hljs-keyword">for</span> <span class="hljs-title class_">X</span> &#123;<br>    <span class="hljs-keyword">type</span> <span class="hljs-title class_">Target</span> = <span class="hljs-type">i32</span>;<br>    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">deref</span>(&amp;<span class="hljs-keyword">self</span>) <span class="hljs-punctuation">-&gt;</span> &amp;<span class="hljs-type">i32</span> &#123; &amp;<span class="hljs-keyword">self</span>.val &#125;<br>&#125;<br><br><span class="hljs-keyword">trait</span> <span class="hljs-title class_">M</span> &#123; <span class="hljs-keyword">fn</span> <span class="hljs-title function_">m</span>(<span class="hljs-keyword">self</span>); &#125;<br><span class="hljs-keyword">impl</span> <span class="hljs-title class_">M</span> <span class="hljs-keyword">for</span> <span class="hljs-title class_">i32</span>   &#123; <span class="hljs-keyword">fn</span> <span class="hljs-title function_">m</span>(<span class="hljs-keyword">self</span>) &#123; <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;i32::m()&quot;</span>);  &#125; &#125;<br><span class="hljs-keyword">impl</span> <span class="hljs-title class_">M</span> <span class="hljs-keyword">for</span> <span class="hljs-title class_">X</span>     &#123; <span class="hljs-keyword">fn</span> <span class="hljs-title function_">m</span>(<span class="hljs-keyword">self</span>) &#123; <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;X::m()&quot;</span>);    &#125; &#125;<br><span class="hljs-keyword">impl</span> <span class="hljs-title class_">M</span> <span class="hljs-keyword">for</span> &amp;X    &#123; <span class="hljs-keyword">fn</span> <span class="hljs-title function_">m</span>(<span class="hljs-keyword">self</span>) &#123; <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;&amp;X::m()&quot;</span>);   &#125; &#125;<br><span class="hljs-keyword">impl</span> <span class="hljs-title class_">M</span> <span class="hljs-keyword">for</span> &amp;&amp;X   &#123; <span class="hljs-keyword">fn</span> <span class="hljs-title function_">m</span>(<span class="hljs-keyword">self</span>) &#123; <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;&amp;&amp;X::m()&quot;</span>);  &#125; &#125;<br><span class="hljs-keyword">impl</span> <span class="hljs-title class_">M</span> <span class="hljs-keyword">for</span> &amp;&amp;&amp;X  &#123; <span class="hljs-keyword">fn</span> <span class="hljs-title function_">m</span>(<span class="hljs-keyword">self</span>) &#123; <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;&amp;&amp;&amp;X::m()&quot;</span>); &#125; &#125;<br><br><span class="hljs-keyword">trait</span> <span class="hljs-title class_">RefM</span> &#123; <span class="hljs-keyword">fn</span> <span class="hljs-title function_">refm</span>(&amp;<span class="hljs-keyword">self</span>); &#125;<br><span class="hljs-keyword">impl</span> <span class="hljs-title class_">RefM</span> <span class="hljs-keyword">for</span> <span class="hljs-title class_">i32</span>  &#123; <span class="hljs-keyword">fn</span> <span class="hljs-title function_">refm</span>(&amp;<span class="hljs-keyword">self</span>) &#123; <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;i32::refm()&quot;</span>);  &#125; &#125;<br><span class="hljs-keyword">impl</span> <span class="hljs-title class_">RefM</span> <span class="hljs-keyword">for</span> <span class="hljs-title class_">X</span>    &#123; <span class="hljs-keyword">fn</span> <span class="hljs-title function_">refm</span>(&amp;<span class="hljs-keyword">self</span>) &#123; <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;X::refm()&quot;</span>);    &#125; &#125;<br><span class="hljs-keyword">impl</span> <span class="hljs-title class_">RefM</span> <span class="hljs-keyword">for</span> &amp;X   &#123; <span class="hljs-keyword">fn</span> <span class="hljs-title function_">refm</span>(&amp;<span class="hljs-keyword">self</span>) &#123; <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;&amp;X::refm()&quot;</span>);   &#125; &#125;<br><span class="hljs-keyword">impl</span> <span class="hljs-title class_">RefM</span> <span class="hljs-keyword">for</span> &amp;&amp;X  &#123; <span class="hljs-keyword">fn</span> <span class="hljs-title function_">refm</span>(&amp;<span class="hljs-keyword">self</span>) &#123; <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;&amp;&amp;X::refm()&quot;</span>);  &#125; &#125;<br><span class="hljs-keyword">impl</span> <span class="hljs-title class_">RefM</span> <span class="hljs-keyword">for</span> &amp;&amp;&amp;X &#123; <span class="hljs-keyword">fn</span> <span class="hljs-title function_">refm</span>(&amp;<span class="hljs-keyword">self</span>) &#123; <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;&amp;&amp;&amp;X::refm()&quot;</span>); &#125; &#125;<br><br><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">Y</span> &#123; val: <span class="hljs-type">i32</span> &#125;<br><span class="hljs-keyword">impl</span> <span class="hljs-title class_">std</span>::ops::Deref <span class="hljs-keyword">for</span> <span class="hljs-title class_">Y</span> &#123;<br>    <span class="hljs-keyword">type</span> <span class="hljs-title class_">Target</span> = <span class="hljs-type">i32</span>;<br>    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">deref</span>(&amp;<span class="hljs-keyword">self</span>) <span class="hljs-punctuation">-&gt;</span> &amp;<span class="hljs-type">i32</span> &#123; &amp;<span class="hljs-keyword">self</span>.val &#125;<br>&#125;<br><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">Z</span> &#123; val: Y &#125;<br><span class="hljs-keyword">impl</span> <span class="hljs-title class_">std</span>::ops::Deref <span class="hljs-keyword">for</span> <span class="hljs-title class_">Z</span> &#123;<br>    <span class="hljs-keyword">type</span> <span class="hljs-title class_">Target</span> = Y;<br>    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">deref</span>(&amp;<span class="hljs-keyword">self</span>) <span class="hljs-punctuation">-&gt;</span> &amp;Y &#123; &amp;<span class="hljs-keyword">self</span>.val &#125;<br>&#125;<br><br><br><span class="hljs-meta">#[derive(Clone, Copy)]</span><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">A</span>;<br><br><span class="hljs-keyword">impl</span> <span class="hljs-title class_">M</span> <span class="hljs-keyword">for</span>    <span class="hljs-title class_">A</span> &#123; <span class="hljs-keyword">fn</span> <span class="hljs-title function_">m</span>(<span class="hljs-keyword">self</span>) &#123; <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;A::m()&quot;</span>);    &#125; &#125;<br><span class="hljs-keyword">impl</span> <span class="hljs-title class_">M</span> <span class="hljs-keyword">for</span> &amp;&amp;&amp;A &#123; <span class="hljs-keyword">fn</span> <span class="hljs-title function_">m</span>(<span class="hljs-keyword">self</span>) &#123; <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;&amp;&amp;&amp;A::m()&quot;</span>); &#125; &#125;<br><br><span class="hljs-keyword">impl</span> <span class="hljs-title class_">RefM</span> <span class="hljs-keyword">for</span>    <span class="hljs-title class_">A</span> &#123; <span class="hljs-keyword">fn</span> <span class="hljs-title function_">refm</span>(&amp;<span class="hljs-keyword">self</span>) &#123; <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;A::refm()&quot;</span>);    &#125; &#125;<br><span class="hljs-keyword">impl</span> <span class="hljs-title class_">RefM</span> <span class="hljs-keyword">for</span> &amp;&amp;&amp;A &#123; <span class="hljs-keyword">fn</span> <span class="hljs-title function_">refm</span>(&amp;<span class="hljs-keyword">self</span>) &#123; <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;&amp;&amp;&amp;A::refm()&quot;</span>); &#125; &#125;<br><br><br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() &#123;<br>    <span class="hljs-comment">// I&#x27;ll use @ to denote left side of the dot operator</span><br>    (*X&#123;val:<span class="hljs-number">42</span>&#125;).<span class="hljs-title function_ invoke__">m</span>();        <span class="hljs-comment">// i32::m()    , Self == @</span><br>    X&#123;val:<span class="hljs-number">42</span>&#125;.<span class="hljs-title function_ invoke__">m</span>();           <span class="hljs-comment">// X::m()      , Self == @</span><br>    (&amp;X&#123;val:<span class="hljs-number">42</span>&#125;).<span class="hljs-title function_ invoke__">m</span>();        <span class="hljs-comment">// &amp;X::m()     , Self == @</span><br>    (&amp;&amp;X&#123;val:<span class="hljs-number">42</span>&#125;).<span class="hljs-title function_ invoke__">m</span>();       <span class="hljs-comment">// &amp;&amp;X::m()    , Self == @</span><br>    (&amp;&amp;&amp;X&#123;val:<span class="hljs-number">42</span>&#125;).<span class="hljs-title function_ invoke__">m</span>();      <span class="hljs-comment">// &amp;&amp;&amp;X:m()    , Self == @</span><br>    (&amp;&amp;&amp;&amp;X&#123;val:<span class="hljs-number">42</span>&#125;).<span class="hljs-title function_ invoke__">m</span>();     <span class="hljs-comment">// &amp;&amp;&amp;X::m()   , Self == *@</span><br>    (&amp;&amp;&amp;&amp;&amp;X&#123;val:<span class="hljs-number">42</span>&#125;).<span class="hljs-title function_ invoke__">m</span>();    <span class="hljs-comment">// &amp;&amp;&amp;X::m()   , Self == **@</span><br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;-------------------------&quot;</span>);<br><br>    (*X&#123;val:<span class="hljs-number">42</span>&#125;).<span class="hljs-title function_ invoke__">refm</span>();     <span class="hljs-comment">// i32::refm() , Self == @</span><br>    X&#123;val:<span class="hljs-number">42</span>&#125;.<span class="hljs-title function_ invoke__">refm</span>();        <span class="hljs-comment">// X::refm()   , Self == &amp;@</span><br>    (&amp;X&#123;val:<span class="hljs-number">42</span>&#125;).<span class="hljs-title function_ invoke__">refm</span>();     <span class="hljs-comment">// X::refm()   , Self == @</span><br>    (&amp;&amp;X&#123;val:<span class="hljs-number">42</span>&#125;).<span class="hljs-title function_ invoke__">refm</span>();    <span class="hljs-comment">// &amp;X::refm()  , Self == @</span><br>    (&amp;&amp;&amp;X&#123;val:<span class="hljs-number">42</span>&#125;).<span class="hljs-title function_ invoke__">refm</span>();   <span class="hljs-comment">// &amp;&amp;X::refm() , Self == @</span><br>    (&amp;&amp;&amp;&amp;X&#123;val:<span class="hljs-number">42</span>&#125;).<span class="hljs-title function_ invoke__">refm</span>();  <span class="hljs-comment">// &amp;&amp;&amp;X::refm(), Self == @</span><br>    (&amp;&amp;&amp;&amp;&amp;X&#123;val:<span class="hljs-number">42</span>&#125;).<span class="hljs-title function_ invoke__">refm</span>(); <span class="hljs-comment">// &amp;&amp;&amp;X::refm(), Self == *@</span><br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;-------------------------&quot;</span>);<br><br>    Y&#123;val:<span class="hljs-number">42</span>&#125;.<span class="hljs-title function_ invoke__">refm</span>();        <span class="hljs-comment">// i32::refm() , Self == *@</span><br>    Z&#123;val:Y&#123;val:<span class="hljs-number">42</span>&#125;&#125;.<span class="hljs-title function_ invoke__">refm</span>(); <span class="hljs-comment">// i32::refm() , Self == **@</span><br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;-------------------------&quot;</span>);<br><br>    A.<span class="hljs-title function_ invoke__">m</span>();                   <span class="hljs-comment">// A::m()      , Self == @</span><br>    <span class="hljs-comment">// without the Copy trait, (&amp;A).m() would be a compilation error:</span><br>    <span class="hljs-comment">// cannot move out of borrowed content</span><br>    (&amp;A).<span class="hljs-title function_ invoke__">m</span>();                <span class="hljs-comment">// A::m()      , Self == *@</span><br>    (&amp;&amp;A).<span class="hljs-title function_ invoke__">m</span>();               <span class="hljs-comment">// &amp;&amp;&amp;A::m()   , Self == &amp;@</span><br>    (&amp;&amp;&amp;A).<span class="hljs-title function_ invoke__">m</span>();              <span class="hljs-comment">// &amp;&amp;&amp;A::m()   , Self == @</span><br>    A.<span class="hljs-title function_ invoke__">refm</span>();                <span class="hljs-comment">// A::refm()   , Self == @</span><br>    (&amp;A).<span class="hljs-title function_ invoke__">refm</span>();             <span class="hljs-comment">// A::refm()   , Self == *@</span><br>    (&amp;&amp;A).<span class="hljs-title function_ invoke__">refm</span>();            <span class="hljs-comment">// A::refm()   , Self == **@</span><br>    (&amp;&amp;&amp;A).<span class="hljs-title function_ invoke__">refm</span>();           <span class="hljs-comment">// &amp;&amp;&amp;A::refm(), Self == @</span><br>&#125;<br></code></pre></td></tr></table></figure><h3 id="Summary">Summary</h3><h4 id="Method">Method</h4><p>Method是这样查找的</p><ul><li>如果如果方法签名类似于T::method(self)<ul><li>方法左边就是T</li></ul></li><li>如果方法签名类似于T::method(&amp;self)<ul><li>方法左边就是&amp;T</li></ul></li></ul><p>对于类型T，先让U=T</p><p>执行以下步骤</p><ul><li>查看U是否match</li><li>如果不match，查看&amp;U是否match</li></ul><p>U=*U（解引用一次）</p><p>再执行以上步骤</p><h3 id="Reference">Reference</h3><p><a href="https://stackoverflow.com/questions/28519997/what-are-rusts-exact-auto-dereferencing-rules">stackoverflow</a></p><p><strong>source code</strong></p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-meta">#[derive(Clone,Debug)]</span><br><span class="hljs-keyword">pub</span> <span class="hljs-keyword">enum</span> <span class="hljs-title class_">PickAdjustment</span> &#123;<br>    <span class="hljs-comment">// Indicates that the source expression should be autoderef&#x27;d N times</span><br>    <span class="hljs-comment">//</span><br>    <span class="hljs-comment">// A = expr | *expr | **expr</span><br>    <span class="hljs-title function_ invoke__">AutoDeref</span>(uint),<br><br>    <span class="hljs-comment">// Indicates that the source expression should be autoderef&#x27;d N</span><br>    <span class="hljs-comment">// times and then &quot;unsized&quot;. This should probably eventually go</span><br>    <span class="hljs-comment">// away in favor of just coercing method receivers.</span><br>    <span class="hljs-comment">//</span><br>    <span class="hljs-comment">// A = unsize(expr | *expr | **expr)</span><br>    <span class="hljs-title function_ invoke__">AutoUnsizeLength</span>(<span class="hljs-comment">/* number of autoderefs */</span> uint, <span class="hljs-comment">/* length*/</span> uint),<br><br>    <span class="hljs-comment">// Indicates that an autoref is applied after some number of other adjustments</span><br>    <span class="hljs-comment">//</span><br>    <span class="hljs-comment">// A = &amp;A | &amp;mut A</span><br>    <span class="hljs-title function_ invoke__">AutoRef</span>(ast::Mutability, <span class="hljs-type">Box</span>&lt;PickAdjustment&gt;),<br>&#125;<br></code></pre></td></tr></table></figure><blockquote><p>Auto deref is part of coercion, which includes auto-deref, auto-unsize, auto-ref, etc.</p><p>See <a href="https://github.com/rust-lang/rust/blob/b6d91a2bdac45cd919497a24207fab843124d4ba/src/librustc_typeck/check/method/probe.rs#L92">here</a></p></blockquote><h2 id="Ownership">Ownership</h2><p>一个变量如果拥有了某个值（不是引用），就代表该变量是这个值的 owner</p><p>If a variable wants to a value’s ownership:</p><ul><li>If the type of the value implements Copy Trait<ul><li>A new value is copied from the old one, and the variable has the ownership</li></ul></li><li>If not<ul><li>Just take over the ownership and make the old varialbe invalid</li></ul></li></ul><blockquote><p>一个强盗索要你身上的一个东西，你要么拿个一模一样的给他（实现了Copy Trait），要么就直接把东西给他（move out）</p></blockquote><p>Rust有以下两种处理方式</p><ul><li>如果实现了Copy Trait，就在栈上复制出一份相同的新值，给新变量新值的ownership<ul><li>该动作称为<code>Copy</code></li></ul></li><li>如果没有实现Copy Trait，把值的所有权交给新的变量，同时废除旧变量的ownership<ul><li>该动作称为<code>Move Out</code></li></ul></li></ul><p>有两种情况新变量一个现有值的ownership：</p><ul><li>By assignment (<strong>Variable Binding</strong>)</li><li>By passing data through a function barrier<ul><li>either as an argument or a return value</li></ul></li></ul><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">test_copy</span>(x:&amp;<span class="hljs-keyword">mut</span> <span class="hljs-type">i32</span>)&#123;<br>    <span class="hljs-comment">// y wants the ownership</span><br>    <span class="hljs-comment">// i32 implements the Copy Trait</span><br>    <span class="hljs-comment">// so make a copy</span><br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">y</span> = *x;<br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;&#123;&#125;&quot;</span>,y)<br>&#125;<br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">test_move</span>(x:&amp;<span class="hljs-keyword">mut</span> <span class="hljs-type">Option</span>&lt;<span class="hljs-type">String</span>&gt;)&#123;<br>    <span class="hljs-comment">// y wants the ownership</span><br>    <span class="hljs-comment">// Option&lt;String&gt; doesn&#x27;t implement the Copy Trait</span><br>    <span class="hljs-comment">// so y will take over the ownership</span><br>    <span class="hljs-comment">// because x is a reference, it is not allowed</span><br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">y</span> = *x;<br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;&#123;:?&#125;&quot;</span>,y)<br><br>&#125;<br><br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>()&#123;<br>    <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">a</span> = <span class="hljs-number">5</span>;<br>    <span class="hljs-title function_ invoke__">test_copy</span>(&amp;<span class="hljs-keyword">mut</span> a);<br>    <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">b</span> = <span class="hljs-title function_ invoke__">Some</span>(<span class="hljs-type">String</span>::<span class="hljs-title function_ invoke__">from</span>(<span class="hljs-string">&quot;HELLO&quot;</span>));<br>    <span class="hljs-title function_ invoke__">test_move</span>(&amp;<span class="hljs-keyword">mut</span> b);<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Lifetime">Lifetime</h2><p>The subject of the reference must live longer than the reference itself to keep the reference valid.</p><p>The borrow checker needs to know <strong>every</strong> reference’s lifetime.</p><ul><li>函数里的 lifetime specifier 相当于在显式地告诉 Borrow Checker 这个函数返回的引用的 lifetime 不应该比传入的两个引用中的任意一个长</li><li>结构体里面的 lifetime specifier 相当于在显式地告诉 Borrow Checker 这个结构体的 lifetime 不应该比结构体内部任意一个 reference 长</li></ul><p>只有你显式地告诉了 Borrow Checker 后，borrow checker 才能继续保证所有的 reference 都是有效的，不会出现悬垂引用的情况</p><h2 id="Option-T-take-Option-T-unwrap"><code>Option&lt;T&gt;.take()</code> &amp;&amp; <code>Option&lt;T&gt;.unwrap()</code></h2><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">test_mut</span>(a:&amp;<span class="hljs-keyword">mut</span> <span class="hljs-type">Option</span>&lt;<span class="hljs-type">String</span>&gt;)&#123;<br>    <span class="hljs-comment">// when you are using unwrap(), you are expecting to unwrap the Option entity</span><br>    <span class="hljs-comment">// and diliver the inner content to someone</span><br>    <span class="hljs-comment">// So you have to take over the ownership and you don&#x27;t want to unwrap again to </span><br>    <span class="hljs-comment">// diliver the content to someone else, which violates the rule.</span><br>    <span class="hljs-comment">// let y = a.unwrap();</span><br>    <span class="hljs-comment">// Let&#x27;s exam the reason why it gives the Error</span><br>    <span class="hljs-comment">// &quot;cannot move out of `*a` which is behind a mutable reference&quot;</span><br>    <span class="hljs-comment">// a.unwrap() --&gt; Option::unwrap(*a)</span><br>    <span class="hljs-comment">// unwarp() wants the ownership</span><br>    <span class="hljs-comment">// the type (*a) Option&lt;String&gt; does not implement the &quot;Copy&quot; trait</span><br>    <span class="hljs-comment">// So it will take over the ownership</span><br>    <span class="hljs-comment">//But a:&amp;mut Option&lt;String&gt; is an reference, which does not have ownership</span><br>    <span class="hljs-comment">// So it gives the Error</span><br><br>    <span class="hljs-comment">// take() does not require the ownership, because it just changes the inner data,</span><br>    <span class="hljs-comment">// which is acceptable for a mut reference</span><br>    <span class="hljs-comment">// it changes the inner data to None and GIVE the origin Option&lt;String&gt; to someone</span><br>    <span class="hljs-comment">// GIVE means the receiver will have the ownership of the Option&lt;String&gt;</span><br>    <span class="hljs-comment">// take() is executing a replace operation at Enum level</span><br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">_y</span> = a.<span class="hljs-title function_ invoke__">take</span>();<br>&#125;<br><br><br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() &#123;<br>    <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">x</span>  = <span class="hljs-title function_ invoke__">Some</span>(<span class="hljs-type">String</span>::<span class="hljs-title function_ invoke__">from</span>(<span class="hljs-string">&quot;HELLO&quot;</span>));<br>    <span class="hljs-title function_ invoke__">test_mut</span>(&amp;<span class="hljs-keyword">mut</span> x);<br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;&#123;:?&#125;&quot;</span>,x);<br>    <span class="hljs-comment">// let y = x.unwrap();</span><br>    <span class="hljs-comment">// println!(&quot;&#123;y&#125;&quot;);</span><br><br>&#125;<br></code></pre></td></tr></table></figure><p>在一个结构体里面，结构体总是拥有它属下的值的所有权，在使用过程中，如果我们想要夺取某个值的所有权，可以预先把这个值用Option包裹一下，然后在需要所有权的地方调用take()方法</p><h2 id="Smart-Pointers">Smart Pointers</h2><h3 id="Box-T"><code>Box&lt;T&gt;</code></h3><p>Two main use cases for box</p><ul><li><p>When we have a variable with a trait type that can’t be computed at compile time</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">trait</span> <span class="hljs-title class_">Vehicle</span> &#123;<br>    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">drive</span>(&amp;<span class="hljs-keyword">self</span>);<br>&#125;<br><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">Truck</span>;<br><br><span class="hljs-keyword">impl</span> <span class="hljs-title class_">Vehicle</span> <span class="hljs-keyword">for</span> <span class="hljs-title class_">Truck</span>&#123;<br>    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">drive</span>(&amp;<span class="hljs-keyword">self</span>) &#123;<br>        <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;Truck is driving&quot;</span>)<br>    &#125;<br>&#125;<br><br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>()&#123;<br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">t</span>: <span class="hljs-type">Box</span>&lt;<span class="hljs-keyword">dyn</span> Vehicle&gt;;<br>    t= <span class="hljs-type">Box</span>::<span class="hljs-title function_ invoke__">new</span>(Truck);<br>    t.<span class="hljs-title function_ invoke__">drive</span>();<br>&#125;<br></code></pre></td></tr></table></figure></li><li><p>Recursive data types</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">Truck</span>&#123;<br>    next_truck:<span class="hljs-type">Option</span>&lt;<span class="hljs-type">Box</span>&lt;Truck&gt;&gt;<br>&#125;<br></code></pre></td></tr></table></figure></li></ul><h3 id="Rc-T"><code>Rc&lt;T&gt;</code></h3><p>In  a situation where you want to have <strong>multiple reference</strong> of some memory but you’re not sure about the order in which those references are going to go out of scope and you want that memory wo stay around until the last reference goes out of scope.</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-meta">#[derive(Debug)]</span><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">Truck</span> &#123;<br>    capacity: <span class="hljs-type">i32</span>,<br>&#125;<br><br><span class="hljs-keyword">use</span> std::rc::Rc;<br><br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() &#123;<br>    <span class="hljs-keyword">let</span> (truck_a, truck_b, truck_c) = (<br>        Rc::<span class="hljs-title function_ invoke__">new</span>(Truck &#123; capacity: <span class="hljs-number">1</span> &#125;),<br>        Rc::<span class="hljs-title function_ invoke__">new</span>(Truck &#123; capacity: <span class="hljs-number">2</span> &#125;),<br>        Rc::<span class="hljs-title function_ invoke__">new</span>(Truck &#123; capacity: <span class="hljs-number">3</span> &#125;),<br>    );<br><br>    <span class="hljs-comment">// Could get around this by using regular borrows</span><br>    <span class="hljs-comment">// assuming you only need a read-only reference to this</span><br>    <span class="hljs-comment">// Problem is that the main function has to maintain the ownership of truck_b</span><br>    <span class="hljs-comment">// track_b would get deallocated when the main function is done</span><br>    <span class="hljs-comment">// even if we stop needing truck_b long before that</span><br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">facility_one</span> = <span class="hljs-built_in">vec!</span>[Rc::<span class="hljs-title function_ invoke__">clone</span>(&amp;truck_a), Rc::<span class="hljs-title function_ invoke__">clone</span>(&amp;truck_b)];<br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">facility_two</span> = <span class="hljs-built_in">vec!</span>[Rc::<span class="hljs-title function_ invoke__">clone</span>(&amp;truck_b), Rc::<span class="hljs-title function_ invoke__">clone</span>(&amp;truck_c)];<br><br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;One &#123;:?&#125;&quot;</span>, facility_one);<br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;Two &#123;:?&#125;&quot;</span>, facility_two);<br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;Truck_b strong count &#123;&#125;&quot;</span>,Rc::<span class="hljs-title function_ invoke__">strong_count</span>(&amp;truck_b));<br>    std::mem::<span class="hljs-title function_ invoke__">drop</span>(facility_two);<br><br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;One after drop &#123;:?&#125;&quot;</span>, facility_one);<br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;Truck_b strong count &#123;&#125;&quot;</span>,Rc::<span class="hljs-title function_ invoke__">strong_count</span>(&amp;truck_b));<br><br>&#125;<br></code></pre></td></tr></table></figure><h2 id="ref">ref</h2><p>Bind by reference during pattern matching.</p><p><code>ref</code> annotates pattern bindings to make them borrow rather than move. It is <strong>not</strong> a part of the pattern as far as matching is concerned: it does not affect <em>whether</em> a value is matched, only <em>how</em> it is matched.</p><p>By default, <a href="vscode-file://vscode-app/usr/share/code/resources/app/out/vs/code/electron-sandbox/workbench/workbench.html"><code>match</code></a> statements consume all they can, which can sometimes be a problem, when you don’t really need the value to be moved and owned:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() &#123;<br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">maybe_name</span> = <span class="hljs-title function_ invoke__">Some</span>(<span class="hljs-type">String</span>::<span class="hljs-title function_ invoke__">from</span>(<span class="hljs-string">&quot;Alice&quot;</span>));<br>    <span class="hljs-comment">// The variable &#x27;maybe_name&#x27; is consumed here ...</span><br>    <span class="hljs-keyword">match</span> maybe_name &#123;<br>        <span class="hljs-title function_ invoke__">Some</span>(n) =&gt; <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;Hello, &#123;n&#125;&quot;</span>),<br>        _ =&gt; <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;Hello, world&quot;</span>),<br>    &#125;<br>    <span class="hljs-comment">// ... and is now unavailable.</span><br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;Hello again, &#123;&#125;&quot;</span>, maybe_name.<span class="hljs-title function_ invoke__">unwrap_or</span>(<span class="hljs-string">&quot;world&quot;</span>.<span class="hljs-title function_ invoke__">into</span>()));<br><br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">maybe_name</span> = <span class="hljs-title function_ invoke__">Some</span>(<span class="hljs-type">String</span>::<span class="hljs-title function_ invoke__">from</span>(<span class="hljs-string">&quot;Alice&quot;</span>));<br>    <span class="hljs-comment">// Using `ref`, the value is borrowed, not moved ...</span><br>    <span class="hljs-keyword">match</span> maybe_name &#123;<br>        <span class="hljs-title function_ invoke__">Some</span>(<span class="hljs-keyword">ref</span> n) =&gt; <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;Hello, &#123;n&#125;&quot;</span>),<br>        _ =&gt; <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;Hello, world&quot;</span>),<br>    &#125;<br>    <span class="hljs-comment">// ... so it&#x27;s available here!</span><br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;Hello again, &#123;&#125;&quot;</span>, maybe_name.<span class="hljs-title function_ invoke__">unwrap_or</span>(<span class="hljs-string">&quot;world&quot;</span>.<span class="hljs-title function_ invoke__">into</span>()));<br>&#125;<br></code></pre></td></tr></table></figure><blockquote><p>在tuple的结构中也常见</p></blockquote><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() &#123;<br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">tuple</span> = (<span class="hljs-type">String</span>::<span class="hljs-title function_ invoke__">from</span>(<span class="hljs-string">&quot;1&quot;</span>), <span class="hljs-type">String</span>::<span class="hljs-title function_ invoke__">from</span>(<span class="hljs-string">&quot;2&quot;</span>));<br>    <span class="hljs-comment">// variable a,b is moved from tuple</span><br>    <span class="hljs-keyword">let</span> (a, b) = tuple;<br><br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">tuple2</span> = (<span class="hljs-type">String</span>::<span class="hljs-title function_ invoke__">from</span>(<span class="hljs-string">&quot;1&quot;</span>), <span class="hljs-type">String</span>::<span class="hljs-title function_ invoke__">from</span>(<span class="hljs-string">&quot;2&quot;</span>));<br><br>    <span class="hljs-comment">// variable c,d borrow from tuple2</span><br>    <span class="hljs-keyword">let</span> (<span class="hljs-keyword">ref</span> c,<span class="hljs-keyword">ref</span> d)= tuple2;<br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;&#123;&#125; &#123;&#125;&quot;</span>, c, d);<br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;&#123;:?&#125;&quot;</span>,tuple2)<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Copy-Clone">Copy &amp;&amp; Clone</h2><h3 id="Clone-Trait">Clone Trait</h3><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">pub</span> <span class="hljs-keyword">trait</span> <span class="hljs-title class_">Clone</span>: <span class="hljs-built_in">Sized</span> &#123;<br>    <span class="hljs-comment">/// Returns a copy of the value.</span><br>    <span class="hljs-comment">///</span><br>    <span class="hljs-comment">/// # Examples</span><br>    <span class="hljs-comment">///</span><br>    <span class="hljs-comment">/// ```</span><br>    <span class="hljs-comment">/// # #![allow(noop_method_call)]</span><br>    <span class="hljs-comment">/// let hello = &quot;Hello&quot;; // &amp;str implements Clone</span><br>    <span class="hljs-comment">///</span><br>    <span class="hljs-comment">/// assert_eq!(&quot;Hello&quot;, hello.clone());</span><br>    <span class="hljs-comment">/// ```</span><br>    <span class="hljs-meta">#[stable(feature = <span class="hljs-string">&quot;rust1&quot;</span>, since = <span class="hljs-string">&quot;1.0.0&quot;</span>)]</span><br>    <span class="hljs-meta">#[must_use = <span class="hljs-string">&quot;cloning is often expensive and is not expected to have side effects&quot;</span>]</span><br>    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">clone</span>(&amp;<span class="hljs-keyword">self</span>) <span class="hljs-punctuation">-&gt;</span> <span class="hljs-keyword">Self</span>;<br><br>    <span class="hljs-comment">/// Performs copy-assignment from `source`.</span><br>    <span class="hljs-comment">///</span><br>    <span class="hljs-comment">/// `a.clone_from(&amp;b)` is equivalent to `a = b.clone()` in functionality,</span><br>    <span class="hljs-comment">/// but can be overridden to reuse the resources of `a` to avoid unnecessary</span><br>    <span class="hljs-comment">/// allocations.</span><br>    <span class="hljs-meta">#[inline]</span><br>    <span class="hljs-meta">#[stable(feature = <span class="hljs-string">&quot;rust1&quot;</span>, since = <span class="hljs-string">&quot;1.0.0&quot;</span>)]</span><br>    <span class="hljs-keyword">fn</span> <span class="hljs-title function_">clone_from</span>(&amp;<span class="hljs-keyword">mut</span> <span class="hljs-keyword">self</span>, source: &amp;<span class="hljs-keyword">Self</span>)<br>    <span class="hljs-keyword">where</span><br>        <span class="hljs-keyword">Self</span>: ~<span class="hljs-keyword">const</span> Destruct,<br>    &#123;<br>        *<span class="hljs-keyword">self</span> = source.<span class="hljs-title function_ invoke__">clone</span>()<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>Clone 是深度拷贝，栈内存和堆内存一起拷贝</p><p><strong>对于实现了 Copy 的类型，它的 clone 方法应该跟 Copy 语义相容，等同于按位拷贝</strong></p><blockquote><p>因为copy trait会依赖与clone trait</p></blockquote><h3 id="Copy-Trait">Copy Trait</h3><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">pub</span> <span class="hljs-keyword">trait</span> <span class="hljs-title class_">Copy</span>: <span class="hljs-built_in">Clone</span> &#123;<br>    <span class="hljs-comment">// Empty.</span><br>&#125;<br></code></pre></td></tr></table></figure><p>从这里可以看出，<code>Copy</code> 和 <code>Clone</code> 实际的操作是一样的</p><p><strong>但是 <code>Clone</code> 是程序员手动显式调用，<code>Copy</code> 是编译器隐式调用</strong></p><p>对于一个类型到底是应不应该实现<code>Copy Trait</code>，这是由程序员显式决定的</p><p>而考虑的因素就是性能</p><ul><li>如果这个类型具有确定的大小并且很小，就可以实现copy trait，所有数据都存在栈上，并且复制速度快</li><li>如果这个类型没有确定的大小，就只能存放在堆上，堆上的数据操作很慢，这时就不应该实现copy trait,如果实现了的话，每次赋值或者传递都会引起堆上的数据复制，很慢</li><li>如果这个类型有确定的大小并且很大，程序员也应该考虑不实现copy trait，因为即使能存放在栈上，但是复制所有数据仍然是很耗时的，完全复制也会很影响性能</li></ul><h4 id="实现条件">实现条件</h4><p>常见的数字类型、bool类型、共享借用指针&amp;，都是具有 Copy 属性的类型。而 Box、Vec、可写借用指针&amp;mut 等类型都是不具备 Copy 属性的类型。</p><p>对于数组类型，如果它内部的元素类型是 Copy，那么这个数组也是 Copy 类型。</p><p>对于 tuple 类型，如果它的每一个元素都是 Copy 类型，那么这个 tuple 会自动实现 Copy trait。</p><p>对于 struct 和 enum 类型，不会自动实现 Copy trait。而且只有当 struct 和 enum 内部每个元素都是 Copy 类型的时候，编译器才允许我们针对此类型实现 Copy trait</p><h3 id="Summary-2">Summary</h3><ul><li><p>在堆的数据上一定不会是 Copy 语义的。</p></li><li><p>栈上的数据可能是 Copy 的，也可能是 非 Copy 的。</p></li><li><p>Copy trait 和 Drop trait 是互斥的。非 Copy 语义的数据就会被 Drop 掉。</p></li></ul><h2 id="Unsafe">Unsafe</h2><p>Segmentation faults are generated when the CPU and OS detect that your program is attempting to access memory regions that they aren’t entitled to.</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">fn</span> <span class="hljs-title function_">noop</span>()<span class="hljs-punctuation">-&gt;</span>*<span class="hljs-keyword">const</span> <span class="hljs-type">i32</span>&#123;<br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">noop_local</span> = <span class="hljs-number">12345</span>;<br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;noop_local: &#123;&#125; address:&#123;:p&#125;&quot;</span>, noop_local,&amp;noop_local);<br>    &amp;noop_local <span class="hljs-keyword">as</span> *<span class="hljs-keyword">const</span> <span class="hljs-type">i32</span><br>&#125;<br><br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>()&#123;<br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">fn_int</span> = <span class="hljs-title function_ invoke__">noop</span>();<br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;fn_int: &#123;:p&#125;&quot;</span>, fn_int);<br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;fn_int: &#123;&#125;&quot;</span>, <span class="hljs-keyword">unsafe</span>&#123;*fn_int&#125;);<br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">danger_addr</span> = <span class="hljs-number">0x1</span> <span class="hljs-keyword">as</span> *<span class="hljs-keyword">const</span> <span class="hljs-type">u8</span>;<br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">content</span> = <span class="hljs-keyword">unsafe</span>&#123;*danger_addr&#125;;<br>    <span class="hljs-built_in">println!</span>(<span class="hljs-string">&quot;content: &#123;&#125;&quot;</span>, content);<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="std-io-Read-by-ref">std::io::Read::by_ref()</h2><p>首先，我们要知道 <code>std::io::Read::</code> 是会消耗它的调用方的</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">use</span> std::io;<br><span class="hljs-keyword">use</span> std::io::prelude::*;<br><span class="hljs-keyword">use</span> std::fs::File;<br><br><span class="hljs-keyword">fn</span> <span class="hljs-title function_">main</span>() <span class="hljs-punctuation">-&gt;</span> io::<span class="hljs-type">Result</span>&lt;()&gt; &#123;<br>    <span class="hljs-keyword">let</span> <span class="hljs-variable">f</span> = File::<span class="hljs-title function_ invoke__">open</span>(<span class="hljs-string">&quot;foo.txt&quot;</span>)?;<br>    <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">buffer</span> = [<span class="hljs-number">0</span>; <span class="hljs-number">5</span>];<br><br>    <span class="hljs-comment">// read at most five bytes</span><br>    <span class="hljs-comment">// take() consumes f</span><br>    <span class="hljs-keyword">let</span> <span class="hljs-keyword">mut </span><span class="hljs-variable">handle</span> = f.<span class="hljs-title function_ invoke__">take</span>(<span class="hljs-number">5</span>);<br>    <span class="hljs-comment">// Error: f no longer exists  </span><br>    <span class="hljs-comment">// f.read(&amp;mut buffer)?;</span><br><br>    handle.<span class="hljs-title function_ invoke__">read</span>(&amp;<span class="hljs-keyword">mut</span> buffer)?;<br>    <span class="hljs-title function_ invoke__">Ok</span>(())<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Programming</category>
      
      <category>Rust</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Paper Note: Towards Transaction as a Service</title>
    <link href="/2024/01/22/Papers/Distributed%20Transactions/towards-transaction-as-a-service/"/>
    <url>/2024/01/22/Papers/Distributed%20Transactions/towards-transaction-as-a-service/</url>
    
    <content type="html"><![CDATA[<h2 id="Background">Background</h2><p>Database systems have evolved to be with a cloud-native architecture,i.e., disaggregation of compute and storage architecture, which decouples the storage from the compute nodes, then connects the compute nodes to shared storage through a high-speed network.</p><blockquote><p>The principle of cloud-native architecture is decoupling. (decoupled functions to make good use of disaggregated resources)</p></blockquote><p>Most existing cloud-native databases couple TP either with storage layer or with execution layer.</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20240122102851365.png" alt="image-20240122102851365"></p><ul><li><strong>Coupling TP with Storage Layer</strong></li></ul><blockquote><p>TiDB adopts a distributed transactional key-value store TiKV as the storage layer.</p></blockquote><p>Coupling TP with storage has two limitations:</p><ul><li><p>Storage servers are usually configured with high-volume SSDs/disks but relatively low compute resources, while TP requires high parallelism.</p><ul><li>This causes a contradiction and will impact cost efficiency, violating the purpose of cloud-native design.</li></ul></li><li><p>The storage is not commonly elastically scaled, while the TP should be elastically scaled according to varying loads.</p></li><li><p><strong>Coupling TP with Execution Layer.</strong></p></li></ul><blockquote><p>Amazon Aurora leverages MySQL or PostgreSQL as the SQL execution instance, which handles TP in the execution layer.</p></blockquote><ul><li>Bundling TP and the execution layer together would incur redevelopment costs for resolving transaction conflicts.</li></ul><p>根据上文的分析，论文提出了：</p><blockquote><p>It is desirable to decouple TP from the database architecture and make it work as an independent transaction service that allows different execution engines with various data models to connect.</p></blockquote><p>As shown in Figure 1c, the execution layer executes the transaction queries and generates the readset and writeset which are posted to the TaaS layer.</p><h3 id="The-three-tier-layer-design">The three-tier layer design</h3><p>The three-tier layer design brings some advantages:</p><ul><li>By connecting existing NoSQL databases to TaaS, <em><strong>the NoSQL databases can be empowered with ACID TP capability</strong></em>.</li><li>By connecting multiple existing standalone TP engine instances to TaaS, <em><strong>a multimaster distributed TP can be realized to improve the TP’s horizontal scalability</strong></em>.</li><li>By connecting multiple execution engines with different data models to TaaS, <em><strong>multi-model transactions are supported</strong></em>.</li><li>The TaaS layer can be optimized and upgraded independently for high performance.</li></ul><h2 id="TaaS-Architecture">TaaS Architecture</h2><p>An execution-transaction-storage three-layer database architecture can be constructed:</p><ul><li><strong>The execution layer</strong> consists of multiple stateless execution engine instances.<ul><li>Each of which accepts users’ transaction requests in the format of SQL or other query languages.</li></ul></li><li><strong>The transaction layer</strong> consists of multiple TaaS nodes.<ul><li>Each of which accepts multiple concurrent updates from different execution engines and performing concurrency conflict resolution.</li></ul></li><li><strong>The storage layer</strong> stores sharding data tables and metadata.</li></ul><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20240122104831715.png" alt="image-20240122104831715"></p><ul><li><strong>Execution Layer (From Txn to Writeset)</strong></li></ul><blockquote><p>The design of the execution layer is similar to TiDB Server.</p></blockquote><p>The transaction request will be parsed into a physical execution plan, then the executor <em><strong>optimistically</strong></em> executes the plan and outputs the readset and writeset of each transaction.</p><p>Once the user commits the transaction, the cached readset and writeset are posted to the TaaS layer.</p><ul><li><strong>Transaction Layer (From Writesets to Log)</strong></li></ul><p>Any TaaS node can accept readsets and writesets from the execution layer, which forms <em><strong>a multi-master architecture</strong></em>.</p><p>Since only the read and write operations are transferred to the TaaS layer, <strong>the concurrency control problem of transaction processing becomes a read-write or write-write conflict resolution problem.</strong></p><p>The conflict resolution results that indicate the transaction commit or abort are logged.</p><ul><li><p>The transaction commit or abort notifications are <em><strong>synchronously</strong></em> returned to the execution layer and users for low latency.</p></li><li><p>The logs are <em><strong>asynchronously</strong></em> pushed to the storage layer.</p></li><li><p><strong>Storage Layer (From Log to Data)</strong></p></li></ul><p><strong>A storage adaptor needs to be implemented by developers</strong> to specify how to update data stores based on the received logs.</p><h2 id="Conflict-Handling-in-Transaction-Layer">Conflict Handling in Transaction Layer</h2><blockquote><p>The core of concurrency control (CC) is conflict handling.<br>“就是为了这点醋，我才包的这顿饺子。”</p></blockquote><p>The conflict handling algorithm used in TaaS should satisfy a set of specific requirements:</p><ul><li>First, the conflict handling should follow multi-master architecture.<ul><li>The readsets/writesets are naturally sent from different execution engine instances, only allowing single-write would incur a single node bottleneck.</li><li>transaction service should be independently scaled, any node can be shutdown or a new node can join at any time.</li></ul></li><li>Second, the conflict handling algorithm should be <em><strong>optimistic</strong></em>.<ul><li>Due to the lazy update of the data in the storage layer, the execution layer could read stale data, and a transaction is optimistically executed in the execution layer.</li></ul></li><li>Third, to improve the efficiency of conflict handling, the writes of transactions are usually batched and exchanged with other TaaS nodes in batches.</li></ul><p><strong>We leverage the epoch-based multi-master OCC as the default conflict handling algorithm：</strong></p><ul><li>The readsets and writesets cached by each TaaS node are exchanged with every other TaaS node at the end of epoch.</li><li>Each TaaS node merges these writesets in terms of a deterministic rule (e.g., first-writer-win).</li></ul><p>There are some implementation details:</p><ul><li><strong>Isolation</strong><ul><li>The epoch-based conflict resolution mechanism can provide multiple isolation levels.</li></ul></li><li><strong>Read Consistency</strong><ul><li>Since the logs in the TaaS layer are asynchronously pushed to the storage layer, the execution layer might read the stale data.</li><li>We address this problem by associating a version number of the storage data and checking whether the read data is the most recent one according to the latest commit version in the TaaS layer. If not, it means that the read data is stale, and the transaction will be aborted.</li></ul></li><li><strong>Durability</strong><ul><li>During the exchange of writesets, the Raft consensus protocol is used to ensure the writesets are received by most of the peer nodes.</li></ul></li><li><strong>Fault Recovery</strong><ul><li>The execution layer is stateless.</li><li>The storage layer usually leverages cloud storage.</li><li>A TaaS node in the transaction layer could fail. Since the Raft consensus is used to ensure the successful transferring of writesets, the updates will not be lost.</li></ul></li></ul><h2 id="Advantages-and-Case-studies">Advantages and Case studies</h2><h3 id="Empowering-NoSQL-DBs-with-TP-Capability">Empowering NoSQL DBs with TP Capability</h3><p><em><strong>By connecting existing NoSQL databases to TaaS, they can be empowered with TP capability.</strong></em></p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20240122111742188.png" alt="image-20240122111742188"></p><p>By connecting to TaaS, these NoSQL databases show higher operation throughput and lower latency due to concurrent execution supported by TaaS.</p><h3 id="Making-Standalone-TP-Engine-Distributed">Making Standalone TP Engine Distributed</h3><p><em><strong>By connecting multiple standalone TP engine instances to TaaS, we can achieve distributed TP easily.</strong></em></p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20240122111817112.png" alt="image-20240122111817112"></p><ul><li>OpenGauss is slightly modified to post the readset and writeset to the TaaS layer.</li><li>Each TaaS node tags the writeset with a local timestamp and performs a readset validation to check whether a certain isolation requirement is violated (read-write conflict).</li><li>Suppose a transaction passes the readset validation, the writeset of this transaction is exchanged with other TaaS nodes at the end of each epoch. Then a writeset merge operation is performed to check the write-write conflicts.</li></ul><h3 id="Supporting-Multi-Model-Transactions">Supporting Multi-Model Transactions</h3><p>By connecting multiple execution engines with different data models to TaaS, we can create a unified query proxy to <em><strong>decompose a multi-model transaction into multiple sub-transactions (each corresponding to a data model) and distribute these subtransactions to different execution engines</strong></em>.</p><p>Furthermore, the TaaS layer can be thought of as a data consistency ensurance layer. The data consistency problems across separate data stores are resolved by TaaS.</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20240122112408512.png" alt="image-20240122112408512"></p><p>It is noticeable that the readsets/writesets of the sub-transactions that belong to the same multi-model transaction should be routed to the same TaaS node, which is essential for guaranteeing atomicity, i.e., the TaaS node should know the commit or abort information of each sub-transaction.</p><h2 id="Challenges-and-Opportunities">Challenges and Opportunities</h2><p><em><strong>The key benefit that attracts users using TaaS is the powers and functions that the TP service itself can provide.</strong></em></p><ul><li><strong>NVM-Native TaaS.</strong><ul><li>Non-volatile memory (NVM) with near DRAM speed, lower power consumption, large memory capacity, and nonvolatility in light of power failure, promises signifcant performance potential for TP.</li></ul></li><li><strong>Rich Isolation and Consistency Choices.</strong><ul><li>The consistency of transactions among TaaS nodes and the consistency across the TaaS layer and storage layer should also be further studied.</li></ul></li><li><strong>Cross-Region TP and Global Data Consistency Layer.</strong><ul><li>If TaaS supports cross-region TP, any node in any continent can connect to TaaS to solve the data consistency problem across regional servers.</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>Distributed</category>
      
      <category>Transactions</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PaperNote</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>A Piece Of: Go Tests</title>
    <link href="/2024/01/21/Pieces/a-piece-of-go-test/"/>
    <url>/2024/01/21/Pieces/a-piece-of-go-test/</url>
    
    <content type="html"><![CDATA[<p>最近在写毕设项目时，总是发现有些单元测试在 VSCode 的 Testing Panel 连续运行测试时无法通过，但是单独运行时能正常通过，困扰了我好长一段时间。</p><p>有一次我发现了一个盲点：</p><p>在我写的框架中，有一个 <code>config.go</code> 文件：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">var</span> Config = config&#123;<br>    LeaseTime:       <span class="hljs-number">1000</span> * time.Millisecond,<br>    MaxRecordLength: <span class="hljs-number">2</span>,<br>    IdGenerator:     NewIncrementalGenerator(),<br>    Serializer:      serializer.NewJSONSerializer(),<br>    LogLevel:        zapcore.InfoLevel,<br>&#125;<br></code></pre></td></tr></table></figure><p>当我从 Testing Panel 连续运行测试时，不同的测试都会复用 <code>IdGenerator</code>。</p><p>从网上查了资料后，才知道：</p><blockquote><p>The behavior you’re seeing is expected because Config is a global variable and it’s shared across the entire package. This means that state, such as the current ID from your NewIncrementalGenerator (), is preserved and reused across all your tests running within the same package.</p><p><em><strong>Go runs test functions (those starting with Test) in parallel by default, but within a single test package, they all share the same memory space. Therefore, global variables will persist their state across individual tests within that package.</strong></em></p></blockquote><p>我一直以为像 config 这种全局变量，每个测试都有一个自己对应的，所以在一些特殊的单元测试中修改了某些参数后，没有及时修改回来，导致后面的测试使用了错误的参数，进而无法通过。</p>]]></content>
    
    
    <categories>
      
      <category>Pieces</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Golang</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Paper Note: Scalable Distributed Transactions across Heterogeneous Stores</title>
    <link href="/2023/12/09/Papers/Distributed%20Transactions/scalable-distributed-transactions-across-heterogeneous-stores/"/>
    <url>/2023/12/09/Papers/Distributed%20Transactions/scalable-distributed-transactions-across-heterogeneous-stores/</url>
    
    <content type="html"><![CDATA[<h2 id="FAQ">FAQ</h2><h4 id="What-is-the-difference-between-rolling-backward-and-rolling-forward-in-database-transactions"><em>What is the difference between rolling backward and rolling forward in database transactions?</em></h4><p>“Rolling backward” and “rolling forward” in the context of database transactions refer to two distinct phases of the recovery process that helps maintain the integrity and consistency of the database after a system crash or failure. These concepts are tied to the idea of transaction logs that record the changes made to the database. Below are the key differences between rolling backward and rolling forward:</p><p><strong>Rolling Backward (Rollback)</strong>:</p><ul><li>Rollback is the process of undoing changes that were made by transactions that had not yet been committed at the time of a crash or system failure.</li><li>This is necessary because those transactions were incomplete and could leave the database in an inconsistent state if their changes were applied.</li><li>The database system uses the transaction log to identify changes made by these in-progress transactions and reverse them, ensuring that the database contains only the results of completed (committed) transactions.</li><li><strong>Rolling back is a way to enforce the “Atomicity” part of the ACID properties of transactions, meaning that a transaction must be fully completed or not take effect at all.</strong></li></ul><p><strong>Rolling Forward (Redo)</strong>:</p><ul><li><strong>Rolling forward is the process of reapplying committed transactions that may not have been fully written to the data files before a crash or system failure occurred.</strong></li><li>This ensures that all the changes from transactions that were committed before the crash are reflected in the database upon recovery, even if those changes were not fully persisted to disk.</li><li>Using the transaction log, the system identifies transactions that were successfully committed but whose effects may not be present in the data files, and then reapplies those changes.</li><li><strong>Rolling forward is part of maintaining the “Durability” characteristic of the ACID properties, ensuring that once a transaction is committed, it remains so even in the event of a system failure.</strong></li></ul><p>In summary, rolling backward is about undoing the effects of transactions that hadn’t been fully completed to preserve database integrity, while rolling forward is about ensuring that the effects of committed transactions are permanent and fully reflected in the database despite any failures.</p><h4 id="What-will-happen-if-the-local-clock-is-drifting"><em>What will happen if the local clock is drifting?</em></h4><ul><li>If a client lags too much, the transaction read will fail every time due to missing to find a corresponding one.</li><li>If a client goes too fast, other clients will not see its data because <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mrow><mi>c</mi><mi>o</mi><mi>m</mi><mi>m</mi><mi>i</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_{commit}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">co</span><span class="mord mathnormal mtight">mmi</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> is behind others’s <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mrow><mi>s</mi><mi>t</mi><mi>a</mi><mi>r</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_{start}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li></ul><h2 id="Introduction">Introduction</h2><p>Background:</p><ul><li>Many cloud-based distributed data store often provide no transactions or only transactions that access a single record.</li></ul><blockquote><p>Most applications built using key value stores work well because of the relative simplicity of the programming interface to the data store. Many of these applications use write-once-read-many (WORM) data access to the key value store and function well under the eventual consistency setting.</p></blockquote><p>Three ways to solve this:</p><ul><li>One way is to implement transaction support in the data store itself.<ul><li>This is complicated and is difficult to implement without compromising scalability and availability.</li></ul></li><li>Another approach is to use middleware to coordinate transactional access to the data store.<ul><li>The middleware approach works well when the application is hosted in the cloud and there is a known and controlled set of data stores used by the application.</li><li>However, these systems require to be setup and maintained separately.</li></ul></li><li>Another way of implementing multi-key transaction support for distributed key-value stores is to incorporate the transaction coordinator into the client.<ul><li>There is no need to install or maintain additional infrastructure.</li><li><strong>This paper solve the problem in this way.</strong></li></ul></li></ul><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231204152941482.png" alt=""></p><h2 id="Structure">Structure</h2><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231209192758050.png" alt="image-20231209192758050"></p><p><em><strong>A client coordinated transaction protocol to enable efficient multi-item transactions across heterogeneous key-value store.</strong></em></p><h2 id="Implementation">Implementation</h2><h3 id="Prerequisite">Prerequisite</h3><p>The design requires that each data store provide the following capabilities:</p><ul><li>The option when reading for single-item strong consistency.</li><li>Atomic conditional update and delete on single items, similar to Test-and-Set.</li><li>Ability to include user-defined meta-data along with the content of a data item.</li></ul><h3 id="Transcation-Process">Transcation Process</h3><p>Transaction Read:</p><ul><li>if record is already in cache, use the cache</li><li>in COMMITED:<ul><li>if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mrow><mi>v</mi><mi>a</mi><mi>l</mi><mi>i</mi><mi>d</mi></mrow></msub><mo>&lt;</mo><msub><mi>T</mi><mrow><mi>s</mi><mi>t</mi><mi>a</mi><mi>r</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_{valid} &lt; T_{start}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>: OK</li><li>else go to previous one</li><li>abort if can not find a corresponding one</li></ul></li><li>in PREPARED:<ul><li>if TSR(Transaction Status Record) exists: the record is considered COMMITED</li><li>eles if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mrow><mi>l</mi><mi>e</mi><mi>a</mi><mi>s</mi><msub><mi>e</mi><mi>t</mi></msub><mi>i</mi><mi>m</mi><mi>e</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_{lease_time}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9334em;vertical-align:-0.2501em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">s</span><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2963em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mord mathnormal mtight">im</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span></span></span></span> has expired: roll forward and considered COMMITTED</li><li>else if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mrow><mi>l</mi><mi>e</mi><mi>a</mi><mi>s</mi><msub><mi>e</mi><mi>t</mi></msub><mi>i</mi><mi>m</mi><mi>e</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_{lease_time}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9334em;vertical-align:-0.2501em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">s</span><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2963em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mord mathnormal mtight">im</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span></span></span></span> has NOT expired without TSR: read fails, transaction aborts</li></ul></li></ul><p>Transaction Write: Write to the cache</p><p>Transaction Commit: in two phase</p><ol><li>Prepare:<ul><li>mark the record with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>c</mi></msub><mi>o</mi><mi>m</mi><mi>m</mi><mi>i</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">T_commit</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathnormal">o</span><span class="mord mathnormal">mmi</span><span class="mord mathnormal">t</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>x</mi><mi>I</mi><mi>D</mi></mrow><annotation encoding="application/x-tex">TxID</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal">x</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>s</mi><mi>S</mi><mi>t</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">TsState</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal">s</span><span class="mord mathnormal">St</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span></span></span></span></li><li>conditional write(test-and-swap by using version tag) in a global order determined through a consistent hash of the record identifiers</li></ul></li><li>Commit:<ul><li>write TSR into database(signals this transaction is succeeded,if something accidentally fails, it must be rolling forward)</li><li>call <code>dataStore.commit()</code>, which just turn record’s <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>s</mi><mi>S</mi><mi>t</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">TsState</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal">s</span><span class="mord mathnormal">St</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span></span></span></span> into COMMITTED</li><li>delete TSR</li></ul></li></ol><p>Transaction Abort:</p><ul><li>if the transaction have not stepped into commit stage: simply clear the cache</li><li>if the transaction is in Prepare phase(for example, one of the conditional writes fails): undo previous operations by altering the record with the old one existing in the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mi>r</mi><mi>e</mi><mi>v</mi></mrow><annotation encoding="application/x-tex">Prev</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal">re</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span> field</li></ul><p>Transaction Recover: perform lazily</p><p>When a new transcation reads a records which seems broken, it tries to perform recovery:</p><ul><li>if the record is in PREPARED:<ul><li>with TSR: roll forward</li><li>without TSR and the lease time has expired: roll backward</li></ul></li></ul><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231209193354773.png" alt="image-20231209193354773"></p><h2 id="Conclusions">Conclusions</h2><h3 id="Limits">Limits</h3><ul><li>Actually need a centrialized timestamp to avoid clock drifting while the paper claims it does not.</li><li>Not suitable for LLTs.</li><li>KV Stores only.</li></ul><h3 id="Highlights">Highlights</h3><blockquote><p>For me, haha</p></blockquote><ul><li>Use cache to store the intermediate state.</li><li>Use a consistent hash to avoid deadlock.</li><li>A client protocol.</li></ul>]]></content>
    
    
    <categories>
      
      <category>Distributed</category>
      
      <category>Transactions</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PaperNote</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Paper Note: GRIT: Consistent Distributed Transactions across Polyglot Microservices with Multiple Databases</title>
    <link href="/2023/12/08/Papers/Distributed%20Transactions/grit/"/>
    <url>/2023/12/08/Papers/Distributed%20Transactions/grit/</url>
    
    <content type="html"><![CDATA[<h2 id="FAQ">FAQ</h2><h3 id="What-is-a-deterministic-database"><em>What is a deterministic database?</em></h3><p><strong>A deterministic database is a system where the outcomes of any database operations are guaranteed to be the same every time they are executed, provided that the operations are started from the same database state.</strong><br>This concept implies a level of reliability and predictability in the behavior of the database system.</p><p>Deterministic behavior is essential in many contexts, especially in distributed databases, where operations might need to be coordinated across multiple nodes, or in any system where replication, fault tolerance, and consistency are important. If a database operation is deterministic, it means the following:</p><ul><li><strong>Consistency</strong>: The same operation will always result in the same state change and the same output when applied to the same initial state.</li><li><strong>Repeatability</strong>: If an operation is performed multiple times with the same input, it will produce the same result each time.</li><li><strong>Concurrency Control</strong>: Determinism can simplify concurrency control, as the outcome of transaction execution is predictable. This reduces the likelihood of conflicts between transactions and can help ensure serializability.</li><li><strong>Fault Tolerance</strong>: In systems that require fault tolerance, such as distributed databases, deterministic operations can make it easier to replicate data across multiple nodes. If a node fails, another node can recreate the exact sequence of operations to reach the current state, ensuring data integrity.</li></ul><p>Determinism in database systems is usually achieved by using strictly defined schemas, stored procedures, constraints, triggers, and transaction isolation levels that enforce the ACID properties (Atomicity, Consistency, Isolation, Durability) of database transactions.</p><h3 id="Can-you-give-some-examples-of-deterministic-database-systems"><em>Can you give some examples of deterministic database systems?</em></h3><p>Deterministic database systems are typically not advertised with “deterministic” as a defining feature, as most traditional relational database management systems (RDBMS) aim for consistency and determinism in their operation. A few databases (including NewSQL databases) and distributed systems, however, emphasize determinism as a core component of their design to ensure data consistency and fault tolerance, especially in a distributed environment.</p><h2 id="Introduction">Introduction</h2><h3 id="Background">Background</h3><ul><li>How to support consistent distributed transactions in scale-out databases is a well-known challenge, and is even more challenging in a microservice architecture.</li><li>2PC does not work well in large-scale high-throughput systems. The reason is that locks are held during the entire 2PC process that significantly increase the transaction conflicts and latency.</li></ul><p>GRIT leverages some deterministic ideas, such as ordering transactions in Paxos-based logs before execution.</p><h2 id="Structure">Structure</h2><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231209201808172.png" alt="image-20231209201808172"></p><p>Components:</p><ul><li>GTM: Global Transaction Manager</li><li>GTL: Global Transaction Log</li><li>DBTM: Database Transaction Manager</li><li>DBTL: Database Transaction Commit Log</li><li>Log Player: Push commit log entries to database</li><li>DB Shard Server</li><li>DB Service: caches read/write set, send them to DBTM</li></ul><h2 id="Implementation">Implementation</h2><blockquote><p>“We do not expand this flow here.”</p><p>The GRIT system is in production in eBay, so I guess some of the implementations might involve the company’s insterests, many detais are missing.</p></blockquote><h3 id="Transaction">Transaction</h3><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231209202308522.png" alt="image-20231209202308522"></p><p>Three Phases:</p><ul><li>Optimistic Execution Phase:<ul><li>Do business logic, while DB Service captures read/write sets (with version info)</li></ul></li><li>Logical Commit Phase:<ul><li>At a DB Level:<ul><li>Conflict Resolution</li><li>If the transaction involves more than one database, commit decision should be made globally</li></ul></li><li>At Global Level: Make the global commit decision</li></ul></li><li>Physical materialization Phase:<ul><li>Log player will steam log entries sequentially to target database, and transaction writes are deterministically executed following the transaction order in the DB level transactions logs (DBTLs).</li><li>This process is done asynchronously.</li></ul></li></ul><h4 id="Details">Details</h4><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231209202830615.png" alt="image-20231209202830615"></p><p>Details:</p><ul><li>Use snapshot to solve wr-conflicts.</li><li>Use version info to solve ww-conflicts.</li><li>Use DBTM’s conflict resolution to solve rw-conflicts.</li><li>The log player <strong>asynchronously</strong> sends DBTL entries to backend storage servers.</li><li>Avoid pessimistic locking during both execution and commit process and avoid waiting for physical commit.</li></ul><p>Conflict resolution:</p><p><em><strong>The goal of conflict checking is to see if there is any other transaction that has changed an entry since the transaction read it.</strong></em></p><p>So basically it iterates the write set to see any of them has been changed.</p><p>Conflict checking at a DBTM is sufficient with the cache of w-sets from all the recently committed transactions, as long as all the updates go through the same DBTM for the covered scope of the database.</p><h2 id="Conclusions">Conclusions</h2><h3 id="Highlights">Highlights</h3><ul><li>A mechanism similar to 2PC but apply at logical commit phase, which avoids longer duration.</li><li>The key for the scalability and performance is the techniques to avoid coordination during execution phase as well as transaction materialization (physical commit) that are of relatively longer duration.</li><li><em><strong>Take advantage of deterministic database engines.</strong></em></li></ul>]]></content>
    
    
    <categories>
      
      <category>Distributed</category>
      
      <category>Transactions</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PaperNote</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Paper Note: How to Read a Paper</title>
    <link href="/2023/12/05/Papers/how-to-read-a-paper/"/>
    <url>/2023/12/05/Papers/how-to-read-a-paper/</url>
    
    <content type="html"><![CDATA[<h2 id="The-Three-Pass-Approach">The Three-Pass Approach</h2><p>Each pass accomplishes specific goals and builds upon the previous pass:</p><ul><li>The first pass gives you a general idea about the paper.</li><li>The second pass lets you grasp the paper’s content, but not its details.</li><li>The third pass helps you understand the paper in depth.</li></ul><h3 id="The-First-Pass">The First Pass</h3><blockquote><p>A quick scan to get a bird’s-eye view of the paper.</p></blockquote><p>This pass should take about <em><strong>five to ten minutes</strong></em> and consists of the following steps:</p><ul><li>Carefully read the title, abstract, and introduction.</li><li>Read the section and sub-section headings.</li><li>Read the conclusions.</li><li>Glance over the references, mentally ticking off the ones you’ve already read.</li></ul><p>At the end of the first pass, you should be able to answer the <em>five</em> Cs:</p><ul><li><em><strong>Category</strong></em>: What type of paper is this? A measurement paper? An analysis of an existing system? A description of a research prototype?</li><li><em><strong>Context</strong></em>: Which other papers is it related to? Which theoretical bases were used to analyze the problem?</li><li><em><strong>Correctness</strong></em>: Do the assumptions appear to be valid?</li><li><em><strong>Contributions</strong></em>: What are the paper’s main contributions?</li><li><em><strong>Clarity</strong></em>: Is the paper well written?</li></ul><p>The first pass is adequate for papers that aren’t in your research area, but may someday prove relevant.</p><h2 id="The-Second-Pass">The Second Pass</h2><p>The second pass should take up to <em><strong>an hour</strong></em>.</p><p>Read the paper with greater care, but <strong>ignore details such as proofs</strong>:</p><ul><li>Look carefully at the figures, diagrams and other illustrations in the paper.</li><li>Remember to mark relevant unread references for further reading.</li></ul><p>This level of detail is appropriate for a paper in which you are interested, but does not lie in your research speciality.</p><blockquote><p>Sometimes you won’t understand a paper even at the end of the second pass. This may be because the subject matter is new to you, with unfamiliar terminology and acronyms.</p></blockquote><h2 id="The-Third-Pass">The Third Pass</h2><p>The key to the third pass is to attempt to <em><strong>virtually re-implement</strong></em> the paper: that is, making the same assumptions as the authors, re-create the work.</p><p>By comparing this re-creation with the actual paper, you can easily identify not only a paper’s innovations, but also its hidden failings and assumptions.</p><p><strong>This pass requires great attention to detail.</strong> You should identify and challenge every assumption in every statement. Moreover, you should think about how you yourself would present a particular idea.</p><p>This pass can take about <em><strong>four or five hours for beginners</strong></em>, and about an hour for an experienced reader</p><p>At the end of this pass, you should be able to reconstruct the entire structure of the paper from memory, as well as be able to identify its strong and weak points.</p>]]></content>
    
    
    <categories>
      
      <category>Research</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PaperNote</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Talk about Postgres Visibility Check Rules</title>
    <link href="/2023/12/04/Talks/talk-about-postgres-visibility-check-rules/"/>
    <url>/2023/12/04/Talks/talk-about-postgres-visibility-check-rules/</url>
    
    <content type="html"><![CDATA[<h2 id="Background">Background</h2><p>最近在看分布式事务相关的论文，很多论文设计的系统中都实现的是快照隔离这一层次的机制，其中 Epoxy 最为典型，直接把 Postgres 的快照隔离机制在中间层重新实现了一遍。</p><p>之前看关于 Postgres 快照隔离机制的文章，找到了这个：<a href="https://www.interdb.jp/pg/pgsql05.html">PostgreSQL并发控制</a>，讲得非常好，逻辑非常清晰，理论和实际例子相结合。</p><p>这篇文章中关于 Visibility Check Rules 的部分讲的非常详细，但是没啥规律，可归纳性不强，我时不时就会回来看看这一段，但每次看的时候好像都要从头再重新理解一遍，于是最近我整理了一下这十条规则，力求达到清晰有序。</p><h2 id="Rules">Rules</h2><p>我先把原文中提到的十条规则列出来，方便下文做参考。</p><p>可以把这些规则简单地按照 <code>t_xmin</code> 的状态分为三部分：</p><p>Status of <code>t_xmin</code> is ABORTED:</p><ul><li>Rule 1: <code>If Status (t_xmin) = ABORTED ⇒ Invisible</code></li></ul><p>Status of <code>t_xmin</code> is IN_PROGRESS:</p><ul><li>Rule 2: <code>If Status (t_xmin) = IN_PROGRESS ∧ t_xmin = current_txid ∧ t_xmax = INVAILD ⇒ Visible</code></li><li>Rule 3: <code>If Status (t_xmin) = IN_PROGRESS ∧ t_xmin = current_txid ∧ t_xmax ≠ INVAILD ⇒ Invisible</code></li><li>Rule 4: <code>If Status (t_xmin) = IN_PROGRESS ∧ t_xmin ≠ current_txid ⇒ Invisible</code></li></ul><p>Status of <code>t_xmin</code> is COMMITTED:</p><ul><li>Rule 5: <code>If Status (t_xmin) = COMMITTED ∧ Snapshot (t_xmin) = active ⇒ Invisible</code></li><li>Rule 6: <code>If Status (t_xmin) = COMMITTED ∧ (t_xmax = INVALID ∨ Status (t_xmax) = ABORTED) ⇒ Visible</code></li><li>Rule 7: <code>If Status (t_xmin) = COMMITTED ∧ Status (t_xmax) = IN_PROGRESS ∧ t_xmax = current_txid ⇒ Invisible</code></li><li>Rule 8: <code>If Status (t_xmin) = COMMITTED ∧ Status (t_xmax) = IN_PROGRESS ∧ t_xmax ≠ current_txid ⇒ Visible</code></li><li>Rule 9: <code>If Status (t_xmin) = COMMITTED ∧ Status (t_xmax) = COMMITTED ∧ Snapshot (t_xmax) = active ⇒ Visible</code></li><li>Rule 10: <code>If Status (t_xmin) = COMMITTED ∧ Status (t_xmax) = COMMITTED ∧ Snapshot (t_xmax) ≠ active ⇒ Invisible</code></li></ul><h2 id="整理分析">整理分析</h2><p>其实我们可以分情景来讨论。</p><h3 id="未修改情况下的可见性">未修改情况下的可见性</h3><ul><li><code>pre_txid</code> 指的是上一个修改了该 record 的事务 id。</li><li><code>some_txid</code> 指的是某个事务的 id。</li></ul><table><thead><tr><th>Record</th><th>t_xmin</th><th>t_xmax</th><th>Visibility</th><th>Comment</th></tr></thead><tbody><tr><td>Record 7</td><td>some_txid</td><td>invalid</td><td>invisible</td><td>某个修改过此记录的事务已经中止（ABORTED）</td></tr><tr><td>Record 8</td><td>pre_txid</td><td>invalid</td><td><em><strong>visible</strong></em></td><td>此记录还未被其他事务修改过</td></tr></tbody></table><ul><li>Rule 1 对应 Record 7 的情况。</li><li>Rule 6 对应 Record 8 的情况。</li></ul><h3 id="事务自行修改的可见性">事务自行修改的可见性</h3><ul><li><code>cur_txid</code> 指的是目前正在进行中的事务 id。</li><li><code>pre_txid</code> 指的是上一个修改了该 record 的事务 id。</li><li><code>very_old_txid</code> 可以代表上上个修改了该 record 的事务 id。</li></ul><p>注意，下表中的 Record 都指的是同一条数据，这些数据的元数据不同。</p><table><thead><tr><th>Record</th><th>t_xmin</th><th>t_xmax</th><th>Visibility</th><th>Comment</th></tr></thead><tbody><tr><td>Record 1</td><td>very_old_txid</td><td>pre_txid</td><td>invisible</td><td>非常老的记录，等待被垃圾回收</td></tr><tr><td>Record 2</td><td>pre_txid</td><td>cur_txid</td><td>invisible</td><td>本事务开始之前的记录(t_xmax 已经被修改)</td></tr><tr><td>Record 3</td><td>cur_txid</td><td>cur_txid</td><td>invisible</td><td>本事务第一次修改</td></tr><tr><td>Record 4</td><td>cur_txid</td><td>invalid</td><td><em><strong>visible</strong></em></td><td>本事务第二次修改</td></tr></tbody></table><p>很明显，这种情况下，我们只能看到最新的一条修改记录：</p><ul><li>Rule 10 对应 Record 1 的情况</li><li>Rule 7 对应 Record 2 的情况</li><li>Rule 3 对应 Record 3 的情况</li><li>Rule 2 对应 Record 4 的情况</li></ul><h3 id="并发事务修改的可见性">并发事务修改的可见性</h3><p>这里也要细分两种情况：</p><ul><li>在本事务读某个数据时，对应的并发事务已经修改了该数据但还未提交。</li><li>在本事务读某个数据时，对应的并发事务已经修改了该数据并且已经提交。</li></ul><p>这两种情况在 Record 中的表现形式是一样的，我们的结论是：<strong>无论并发事务是否已经提交，我们都只能看到修改之前的旧数据。</strong></p><ul><li><code>pre_txid</code> 指的是上一个修改了该 record 的事务 id。</li><li><code>concur_txid</code> 指的是并发事务的 id。</li></ul><table><thead><tr><th>Record</th><th>t_xmin</th><th>t_xmax</th><th>Visibility</th><th>Comment</th></tr></thead><tbody><tr><td>Record 5</td><td>pre_txid</td><td>concur_txid</td><td><em><strong>visible</strong></em></td><td>只能看到并发事务修改之前的记录</td></tr><tr><td>Record 6</td><td>concur_txid</td><td>invalid</td><td>invisible</td><td>并发事务做出的修改都应该不可见</td></tr></tbody></table><ul><li>Rule 8（并发事务还未提交）和 Rule 9（并发事务已经提交）对应 Record 5 的情况。</li><li>Rule 4（并发事务还未提交）和 Rule 5（并发事务已经提交）对应 Record 6 的情况。</li></ul><h2 id="总结">总结</h2><p>从上文可以看出，我们根据情景来归纳整理，比单纯地根据 <code>t_xmin</code> 事务的状态来整理有逻辑得多。</p><p>这里我们也可以根据 <code>t_xmin</code> 的事务状态反过来整理一下：</p><ul><li><code>Status (t_xmin) = ABORTED</code><ul><li>一定不可见<ul><li>Rule 1：已经中止的事务写入的记录不可见</li></ul></li></ul></li><li><code>Status (t_xmin) = IN_PROGRESS</code><ul><li>只有自己更新的，最后一条记录可见<ul><li>Rule 10：非常老的记录不可见</li><li>Rule 7：修改前的记录不可见</li><li>Rule 3：不是最新的修改记录不可见</li><li>Rule 2：最新的修改记录可见</li></ul></li><li>如果被还未提交的并发事务修改了，那么<ul><li>Rule 8：修改前记录可见</li><li>Rule 4：修改后记录不可见</li></ul></li></ul></li><li><code>Status (t_xmin) = COMMITED</code><ul><li>上轮事务提交的，本轮中未被修改的记录可见<ul><li>Rule 6：最新的，未被修改的记录可见</li></ul></li><li>如果被已经提交的并发事务修改了，那么<ul><li>Rule 9：修改前的记录可见</li><li>Rule 5：修改后的记录不可见</li></ul></li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>Database</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Talk</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Paper Note: Ad Hoc Transactions in Web Applications: The Good, the Bad, and the Ugly</title>
    <link href="/2023/11/30/Papers/Distributed%20Transactions/ad-hoc-transactions-in-web-applications/"/>
    <url>/2023/11/30/Papers/Distributed%20Transactions/ad-hoc-transactions-in-web-applications/</url>
    
    <content type="html"><![CDATA[<blockquote><p>这篇文章讲道理不应该写这么长的，但讲的东西比较“好玩”，于是就多记录了一些。</p></blockquote><h2 id="FAQ">FAQ</h2><h4 id="What-is-an-ad-hoc-transaction"><em>What is an ad hoc transaction?</em></h4><p>It refers to database operations coordinated by application code. Specifically, developers might explicitly use locking primitives and validation procedures to implement concurrency control amid the application code to coordinate critical database operations.</p><h4 id="Why-do-not-use-database-transactions-instead"><em>Why do not use database transactions instead?</em></h4><p>For flexibility or efficiency.</p><p>在一般的数据库使用场景下，伴随着数据库的隔离级别提升，性能下降十分严重，为此，应用层临时事务需要做到既利用低隔离级别的数据库防止性能下降，又要实现应用层的事务机制防止数据一致性错误等问题。</p><h4 id="What-is-a-false-conflict-in-database-systems"><em>What is a false conflict in database systems?</em></h4><p>In database systems, a false conflict, also known as a phantom conflict, occurs when a transaction appears to conflict with other transactions, but in reality, it does not. This can happen in situations where transactions are using optimistic concurrency control or multi-version concurrency control mechanisms.</p><p>A false conflict might occur in scenarios like the following:</p><ul><li>Two transactions are reading and writing different parts of a data structure, like separate rows in a database table, but the isolation mechanism inaccurately perceives them as overlapping operations on the same item.</li><li>In systems that use row-versioning, when multiple versions of data are stored to support concurrent operations, a transaction might conflict with an older version of a row that is not actually relevant to the current state of the database.</li><li>When a range lock conflicts with an insert operation into the database, even though the new record does not actually interfere with the transaction holding the range lock.</li></ul><blockquote><p>For example, let’s say there is a transaction attempting to read all records where the value is between 1 and 10. If another transaction inserts a record with a value of 11, a simplistic locking mechanism might block this operation due to a range lock on 1 to 10, even though the insert doesn’t actually conflict with the read operation.</p></blockquote><p><em><strong>False conflicts can lead to unnecessary transaction rollbacks, reduced concurrency, and lower overall system performance.</strong></em> Database systems aim to minimize the occurrence of false conflicts to maintain high levels of efficiency and ensure good performance under concurrent access patterns. Techniques for reducing false conflicts include fine-grained locking, multi-version concurrency control (MVCC), and validation-based concurrency control schemes.</p><h4 id="What-is-ORM-provided-invariant-validation"><em>What is ORM-provided invariant validation?</em></h4><p>It refers to checks that ensure the data managed by the ORM adheres to certain predefined rules or constraints at all times.</p><p>ORM-provided invariant validation might include things like:</p><ul><li>Field Validation: Ensuring that data fields contain valid information, such as checking for non-null values in required fields, string length, or pattern matching.</li><li>State Validation: Confirming that an object’s state is valid when it transitions from one state to another—commonly used in state machines within an object.</li><li>Consistency Checks: These validations help ensure that the entire system remains in a consistent state. For instance, if an ORM deletes an object, it could enforce the deletion of all associated objects to maintain referential integrity.</li></ul><h4 id="What-is-a-predicate-lock-in-database-systems"><em>What is a predicate lock in database systems?</em></h4><p>A predicate lock is a type of lock that is used to ensure the consistency of data by restricting access based on a specific condition or a predicate. Unlike traditional locking mechanisms that lock individual rows or tables, predicate locks are generally more granular and are used to lock a set of rows that satisfy a certain condition.</p><p>For example, if a transaction is executed to update all rows in a table where the value of a certain column is greater than 100, <strong>a predicate lock would prevent other transactions from inserting, updating, or deleting rows that have a column value greater than 100 until the first transaction is completed.</strong></p><p>However, predicate locking can be expensive in terms of performance due to the overhead of checking conditions, and not all database management systems implement predicate locks.</p><h4 id="What-is-gap-lock-in-database-systems"><em>What is gap lock in database systems?</em></h4><p>In database systems, a gap lock is a type of lock that is used to prevent phantom reads by transactions in serializable and repeatable read isolation levels.</p><p>A gap lock is not a lock on an actual record, but rather on the “gap” between records. It effectively prevents other transactions from inserting new records into ranges that have been read by a transaction that holds the gap lock until the original transaction is complete. This ensures repeatable reads, meaning the same SELECT query will return the same set of rows throughout the transaction.</p><p>For example, let’s say there is a table with an indexed column containing values {1, 2, 4}. If a transaction were to run a query to select records with indexed values less than 3, it would lock the gap before 1, between 1 and 2, and between 2 and 4. If another transaction tries to insert a record with the indexed value of 3, it would be blocked until the first transaction is complete. The gap lock in this case prevents a phantom insert of a value that would affect the original transaction’s result set.</p><p>Gap locking is often associated with InnoDB storage engine in MySQL, where it is implemented to enforce the next-key lock for preventing phantom reads. However, gap locking can have an impact on performance because it increases lock contention and reduces concurrency.</p><h2 id="Introduction">Introduction</h2><p>简单来说，研究人员有以下几个发现：</p><ul><li>Every studied application uses ad hoc transactions on critical APIs.</li><li>Ad hoc transactions’ usages and implementations are much more flexible than database transactions.</li><li>Ad hoc transactions are prone to errors.</li><li>Ad hoc transactions can have performance benefits under high-contention workloads.<ul><li>Using application semantics such as access patterns, ad hoc transactions’ CC could be implemented in a simple yet precise way.</li></ul></li></ul><h2 id="Background-and-Motivation">Background and Motivation</h2><p>Like database transactions, ad hoc transactions provide isolation semantics such as serializability to database operations. The difference is that ad hoc transactions coordinate operations with application code—<strong>it is the application developers, instead of database developers, who design and implement the CC.</strong></p><p>论文作者们工作量还是比较大的，他们先选取了几种类型下的 8 个代表应用，然后直接分析其源代码，比如说直接查找 lock，concurrency, consistency 等关键字，然后找到并识别那些隔离了数据库操作的代码。最后针对以下三个问题做了分析和调研：</p><ul><li>How are ad hoc transactions constructed among applications?</li><li>Can ad hoc transactions always ensure the correct semantics?</li><li>How is ad hoc transactions’ performance, especially in comparison with database transactions?</li></ul><h2 id="Characteristics-of-Ad-Hoc-Transactions">Characteristics of Ad Hoc Transactions</h2><p>Th cases can still be classified into <em>pessimistic</em> ad hoc transactions (65/91) and <em>optimistic</em> ad hoc transactions (26/91):</p><ul><li>In pessimistic cases, developers explicitly use locks to block conflicting database operations in ad hoc transactions.</li><li>Meanwhile, optimistic ad hoc transactions execute operations aggressively and validate the execution result before writing updates back to the database system.</li></ul><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231130202805493.png" alt=""></p><blockquote><p>(a) and (b) belongs to pessimistic ad hoc transactions, while © is an optimistic ad hoc transactions.</p></blockquote><h3 id="What-Do-Ad-Hoc-Transactions-Coordinate">What Do Ad Hoc Transactions Coordinate?</h3><h4 id="All-Database-Operations-vs-Specific-Database-Operations">All Database Operations vs. Specific Database Operations</h4><p>论文中给出了以下伪代码：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs rust"><span class="hljs-keyword">in</span>: sku_id, requested <br><span class="hljs-title function_ invoke__">lock</span>(sku_id) <br>sku := Select * <span class="hljs-built_in">From</span> SKUs Where id=sku_id <br><span class="hljs-keyword">if</span> sku.quantity &gt;= requested: <br> sku.quantity -= requested <br> <span class="hljs-comment">// the followig statements are auto-generated by ORM.save(sku) </span><br> Transaction Start <br> Update SKUs Set quantity=sku.quantity Where id=sku.id<br> Update Products Set updated_at=<span class="hljs-title function_ invoke__">now</span>() Where id=sku.product_id <br> category_ids := Select category_id <br>  <span class="hljs-built_in">From</span> Categories Join ProductCategories Using category_id <br>  Where product_id=sku.product_id <br> Update Categories Set updated_at=<span class="hljs-title function_ invoke__">now</span>() Where id In category_ids <br> Transaction Commit <br><span class="hljs-title function_ invoke__">unlock</span>(sku_id)<br></code></pre></td></tr></table></figure><p>在这段代码中，很明显对 sku 的操作是需要序列化的 (为了防止 <em>lost update</em>)，所以就需要在开头和末尾进行上锁。值得注意的是，如果直接用 <code>Transaction Start/Commit</code> 替换掉 <code>lock()/unlock()</code> 的话，性能可能会下降：因为整个事务需要序列化，如果有两个事务同时在执行对 Category 相关的操作，有可能会导致死锁从而使事务退出。</p><blockquote><p>However, with ad hoc transactions, only the critical SKU operations are serialized, and Categories accesses are executed in MySQL’s default isolation level, Repeatable Read, which does not acquire reader locks.</p></blockquote><h4 id="Individual-Requests-vs-Multiple-Requests">Individual Requests vs. Multiple Requests</h4><p>有些时候单个 ad hoc transaction 有可能涉及到多个 database request，比如下面的这个关于修改帖子的伪代码：</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231130205056132.png" alt=""></p><p>这段代码中，开发者使用了 optimistic ad hoc transaction：在更新帖子之前，需要先检查一致性，注意必须用锁来保证验证和提交这两个操作的原子性。</p><p>像这样的 LLT，如果不使用乐观的并发控制的话，可能会导致长时间阻塞，对于 LLT，也有一些机制可以处理，比如 Sagas 和 savepoints。</p><blockquote><p>Alternatively, developers can set savepoints after handling each request when coordinating multi-request user interactions with conventional, long-lived database transactions. When the application detects an error (except for fatal errors such as deadlocks), it can explicitly roll back the transaction state to previously set savepoints instead of aborting the entire LLT.</p></blockquote><h4 id="Database-Operation-vs-Non-Database-Operations">Database Operation vs. Non-Database Operations</h4><p>The flexibility of ad hoc transactions is also reflected in coordinating non-database operations. A web application may use several storage systems to persist its data. Thus, it needs to ensure data consistency across different systems.</p><p>讲道理这种操作需要类似于 XA 的协议来保证事务的原子性，但是很多数据库不支持这些分布式事务协议，所以开发者只能采用 ad hoc transaction 的模式来实现类型功能。</p><h3 id="How-is-The-Coordination-Implemented">How is The Coordination Implemented?</h3><blockquote><p>Developers need to manually coordinate ad hoc transactions, including locking (for pessimistic cases) and validation (for optimistic cases). However, the locking primitives and validation procedures usually have different implementations.</p></blockquote><p>这一节主要讲了开发者们在锁和验证步骤上的具体实现，锁的实现可以分为：</p><ul><li>利用现有系统的锁<ul><li>利用数据库中的 <code>Select For Update</code> 语句</li><li>直接利用编程语言中的特性，比如 Java 的 <code>synchronized</code></li></ul></li><li>自己实现的锁<ul><li>在 Redis 中实现的租约锁</li><li>在数据库中专门留出一张锁的表</li><li>内存中实现，比如 <code>ConcurrentHashMap</code></li></ul></li></ul><h3 id="What-Are-The-Coordination-Granularities">What Are The Coordination Granularities?</h3><p>Developers often have a deep understanding of applications that enables them to customize the coordination granularity.</p><p>直觉上，开发者可能会用细粒度的协作来避免 false conflict，但研究发现 ad hoc transaction 经常将多个请求放在一起并用一个锁，这样可以大幅度的减少 ad hoc transaction 并发控制的复杂度和死锁的可能性。</p><p>研究发现，超过一半的 ad hoc transaction 都只用了单个锁来协调多个数据库请求。原因是开发者经常能识别出以下两种访问模式。</p><h4 id="Associated-Accesses">Associated Accesses</h4><blockquote><p>Given two database rows, r1 and r2, if accesses to r2 always happen in a transaction that also accesses r1, we say r2 is associatively accessed with r1 and refer to this access pattern as the associated access pattern.</p></blockquote><p>在进行一对多关系时经常会遇到这种访问模式，在这种情况下，如果我们能结合语义进行加锁，大概率只需要用一把锁。考虑 <code>Figure1 a</code> 中的情况,访问购物车 (Cart) 和该购物车所包含的商品 (Item)：在 Item 这张表中，里面的 row 只会以特定的形式访问到，并不会有理论上的随机读写，就可以不在这些 row 上加细粒度的锁。</p><p>这样也能避免事务之间的冲突：这样的锁明确地在前期序列化冲突事务，从而避免了在使用数据库事务时可能发生的终止。在 PostgreSQL 中，一个事务中的购物车更新会由于写写冲突，中止掉所有在更新之前发生的冲突事务。在 MySQL 中，购物车更新和商品插入都可能形成死锁，因为其他事务可能已经以共享模式锁定了这两个表。</p><h4 id="Read-Modify-Writes">Read-Modify-Writes</h4><p>In a 2PL system without sufficient deadlock prevention mechanisms, such as MySQL, there can be a deadlock if two concurrent transactions perform the RMW on the same row.</p><p>考虑 <code>Figure1 b</code> 中的情况，用一把锁就可以避免可能的死锁问题。</p><h4 id="Discussion">Discussion</h4><p>Reducing the number of locks simplifies the implementation and avoids potential deadlocks. However, <em><strong>such optimizations can rarely be used in database systems because they highly rely on application semantics.</strong></em></p><h4 id="Fine-Grained-vs-Coarse-Grained">Fine-Grained vs. Coarse-Grained</h4><p>使用比数据库更细粒度的控制可以更好地避免 false conflict，比如使用基于列的控制：</p><blockquote><p>Developers could coordinate database accesses at the column granularity if they know which fields are used.</p></blockquote><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231130213035736.png" alt=""></p><p>Though these operations have no column-level conflicts, if they access the same row, an RDBMS using row locks cannot execute them in parallel.</p><p>Optimistic ad hoc transactions can also benefit from column-based coordination — <strong>they only need to validate whether specific column values have been updated.</strong></p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231130213240511.png" alt=""></p><p>It performs value-based validation on the updated content column to detect concurrent changes. <strong>Any concurrent update to other columns, including <code>view_cnt</code> increments, will not interfere with content updates.</strong></p><p>还有一种细粒度的控制方案是使用 predicate locks：</p><blockquote><p>Predicate locks can avoid false conflicts caused by the gap lock used in the major RDBMSs.</p></blockquote><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231130215857374.png" alt=""></p><blockquote><p>Suppose transaction Txn1 and Txn2 with <code>order_id</code> of 10 and 11:</p><p>Suppose executing line 3 of Txn1 causes the RDBMS to acquire a gap lock on the index interval (9, 12), blocking concurrent inserts to this range so that re-executing line 3 can obtain repeatable results. Meanwhile, line 5 in Txn 2 inserts a new payment row for another order whose order_id equals 11. Though this insert does not interfere with Txn 1’s line 3, it would nevertheless be blocked by the gap lock.</p></blockquote><p>后面的话主要是讲了一些错误处理和正确性问题，这里就不多赘述了。</p><h2 id="Conclusion">Conclusion</h2><p>Ad hoc transactions are much more flexible than database transactions, which is a double-edged sword—they potentially have performance benefits but are prone to correctness issues.</p>]]></content>
    
    
    <categories>
      
      <category>Distributed</category>
      
      <category>Transactions</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PaperNote</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>A Piece Of: ThreadLocal</title>
    <link href="/2023/11/29/Pieces/a-piece-of-threadlocal/"/>
    <url>/2023/11/29/Pieces/a-piece-of-threadlocal/</url>
    
    <content type="html"><![CDATA[<h2 id="原理">原理</h2><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/v2-c78d9add1be08b178b8405fcce7f5ccb_b.jpg" alt="img"></p><p>ThreadLocal 是一种线程局部变量，它为每个线程提供了一个独立的变量副本，所以每个线程都可以拥有自己的局部变量，互不影响。</p><p>ThreadLocal 可以做到线程隔离的原因在于，每次创建 ThreadLocal 的时候，都会创建一个新的线程局部存储区，这个存储区只存在于当前线程中，其他线程无法访问到。这样就实现了线程之间的隔离，每个线程都可以在自己的线程局部存储区中保存自己的数据，互不影响。</p><h2 id="使用方法">使用方法</h2><h3 id="管理-Connection">管理 Connection</h3><p>ThreadLocal 的相关知识我查过多次，一直不理解为什么使用 ThreadLocal 可以起到“管理 Connection”的作用，我之前的疑问是这样的：</p><p>数据库连接在同一时间只能被一个线程所持有，线程在申请数据库连接时也是线程安全的。Java 多线程访问同一个 java.Sql.Connection 会导致事务错乱。如果 ThreadLocal 的作用是“提供副本”的话，那么多个线程拿到的不就是同一个 Connection 了？</p><p>其实是这样的：</p><p>如果不使用 ThreadLocal，你当然可以用局部变量的方式来保证线程封闭（Thread Confinement），即在一个函数中先从连接池中获取连接，执行完逻辑后再归还连接。但如果说你必须要使用到一个全局变量的 Connection 呢？</p><p>如果不使用 ThreadLocal，就会出现不同的线程使用同一个全局变量的问题，自然不满足“一个数据库连接在同一时间只能被一个线程所持有”的限制。</p><p>每当一个线程需要数据库连接时，它就从数据库连接池中取出一个连接，存到 ThreadLocal 中，这样虽然不同线程的数据库连接都叫 <code>dbConn</code>,但都是独立的 Connection。</p><blockquote><p>在 Spring 的 Web 项目中，我们通常会将业务分为 Controller 层，Service 层，Dao 层，我们都知道@Autowired 注解默认使用单例模式，那么不同请求线程进来之后，由于 Dao 层使用单例，那么负责数据库连接的 Connection 也只有一个，如果每个请求线程都去连接数据库，那么就会造成线程不安全的问题，Spring 是如何解决这个问题的呢？<br>在 Spring 项目中 Dao 层中装配的 Connection 肯定是线程安全的，其解决方案就是采用 ThreadLocal 方法，当每个请求线程使用 Connection 的时候，都会从 ThreadLocal 获取一次，如果为 null，说明没有进行过数据库连接，连接后存入 ThreadLocal 中，如此一来，每一个请求线程都保存有一份自己的 Connection，于是便解决了线程安全问题。</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">DatabaseUtil</span> &#123;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-type">DataSource</span> <span class="hljs-variable">dataSource</span> <span class="hljs-operator">=</span> ...; <span class="hljs-comment">// 数据库连接池</span><br>    <br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> ThreadLocal&lt;Connection&gt; connectionHolder = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ThreadLocal</span>&lt;&gt;();<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> Connection <span class="hljs-title function_">getConnection</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> SQLException &#123;<br>        <span class="hljs-type">Connection</span> <span class="hljs-variable">conn</span> <span class="hljs-operator">=</span> connectionHolder.get();<br>        <span class="hljs-keyword">if</span> (conn == <span class="hljs-literal">null</span>) &#123;<br>            conn = dataSource.getConnection();<br>            connectionHolder.set(conn);<br>        &#125;<br>        <span class="hljs-keyword">return</span> conn;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">closeConnection</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> SQLException &#123;<br>        <span class="hljs-type">Connection</span> <span class="hljs-variable">conn</span> <span class="hljs-operator">=</span> connectionHolder.get();<br>        <span class="hljs-keyword">if</span> (conn != <span class="hljs-literal">null</span>) &#123;<br>            conn.close();<br>            connectionHolder.remove();<br>        &#125;<br>    &#125;<br>&#125;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">MyServlet</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">HttpServlet</span> &#123;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">doGet</span><span class="hljs-params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="hljs-keyword">throws</span> ServletException, IOException &#123;        <br>        <span class="hljs-type">Connection</span> <span class="hljs-variable">conn</span> <span class="hljs-operator">=</span> <span class="hljs-literal">null</span>;<br>        <span class="hljs-keyword">try</span> &#123;<br>            conn = DatabaseUtil.getConnection();<br><br>            <span class="hljs-comment">// do something with the database connection</span><br>            <span class="hljs-comment">// ...</span><br><br>        &#125; <span class="hljs-keyword">catch</span> (SQLException e) &#123;<br>            <span class="hljs-comment">// handle exception</span><br>        &#125; <span class="hljs-keyword">finally</span> &#123;<br>            <span class="hljs-keyword">if</span> (conn != <span class="hljs-literal">null</span>) &#123;<br>                <span class="hljs-keyword">try</span> &#123;<br>                    DatabaseUtil.closeConnection();<br>                &#125; <span class="hljs-keyword">catch</span> (SQLException e) &#123;<br>                    <span class="hljs-comment">// handle exception</span><br>                &#125;<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>在这个示例中，DatabaseUtil 类通过 ThreadLocal 来存储数据库连接。每个请求线程从连接池获取连接时，会先检查 ThreadLocal 中是否已经存在了一个连接，如果没有就创建一个新连接并将其存储到 ThreadLocal 中，否则直接从 ThreadLocal 中获取已有的连接。在请求处理完毕后，关闭连接并从 ThreadLocal 中删除对象引用，以便及时释放资源和避免内存泄漏。</p><p>在这个示例中，线程最大并发数受到数据库连接池配置和线程池大小的影响。如果连接池最大连接数比线程池大小要小，那么就可能出现线程阻塞或者无法获取到数据库连接的情况。因此，合理地配置连接池大小和线程池大小是保证应用程序性能和稳定性的重要因素。</p><h3 id="携带数据">携带数据</h3><p>同一个线程中经常会用到的数据就可以保存在 ThreadLocal 中，比如 Session 数据之类的。</p><h2 id="内存泄漏">内存泄漏</h2><p>一句话总结：由于 ThreadLocalMap 的生命周期跟 Thread 一样长，如果没有手动删除对应 key 就会导致内存泄漏。</p><p>具体信息可以参考这篇文章：<a href="https://juejin.cn/post/7250734439709458469">ThreadLocal源码详解及内存泄漏原理 - 掘金</a></p><h2 id="思考">思考</h2><p>ThreadLocal 结合线程池使用时会有几个问题，分别对应着管理 Connection 和携带数据。</p><p>背景原因是：</p><p>用了线程池之后，线程执行完成后，归还线程池，并不会销毁；所以线程持有的 Threadlocal 对象还保持引用，如果不清理 Threadlocal 中的内容，则会把之前执行的信息带入到本次线程的执行中。</p><h3 id="管理-Connection-2">管理 Connection</h3><p>如果 ThreadLocal 配合线程池进行使用，并且 ThreadLocal 中管理的是数据库连接的话，如果只是关闭连接，但是不从 ThreadLocal 里 remove，就会导致该线程再下次复用时会直接调用上次的已经关闭的连接，导致出错。</p><p>如果不关闭连接的话，一定程度上起到了数据库连接池的作用，相当于进行了连接的复用。</p><h3 id="携带数据-2">携带数据</h3><p>有时我们会在一个接口中缓存某些数据到 ThreadLocal 中，但是我们要意识到，处理请求的这些线程是由 tomcat 提供的，而 tomcat 提供的线程都是配置在一个线程池中的。</p><p>也就是说，线程是可能被重用的，如果线程一旦被重用，而 ThreadLocal 的数据没有及时重置，就会导致数据被混乱使用。</p><p>具体情况可以查看这篇文章：<a href="https://blog.csdn.net/BASK2312/article/details/128640770">不规范使用ThreadLocal导致的bug</a></p><h3 id="能否用线程池-ThreadLocal-的方式来替代数据库连接池呢？">能否用线程池 + ThreadLocal 的方式来替代数据库连接池呢？</h3><p>看了 Epoxy 的源代码，我以为 Epoxy 会因为没有数据库连接池来进行连接的复用，而导致单次请求都会重新连接一次数据库，造成响应时间过长。</p><p>但测试中发现不是的，原因就是前文提到的“用了线程池之后，线程执行完成后，归还线程池，并不会销毁，所以线程持有的 Threadlocal 对象还保持引用”，在某种意义上就实现了数据库连接的复用。</p><p>比如 Tomcat 有一个线程池，线程池里的线程会不断复用，如果把数据库连接保存到线程的 ThreadLocal 中，那么在该线程下次得到执行时，数据库的连接仍然存在，就能直接使用，某种意义上就起到了数据库连接池的复用效果。为什么还需要数据库连接池来做复用呢？或者说把数据库连接保存到 ThreadLocal 中来复用有什么缺点？</p><p>在网上一顿查（其实主要还是问了 GPT），归纳一下：</p><p>在某些情况下，可以使用 ThreadLocal 来存储数据库连接，从而实现连接的复用。不过这种方式相对于使用专门的数据库连接池来说，存在以下一些缺点：</p><ul><li>资源管理不够灵活：使用 ThreadLocal 保存数据库连接会导致连接与线程生命周期绑定，而线程池中的线程通常会一直存在，不会频繁地创建与销毁。这意味着一旦连接被保存到 ThreadLocal 中，它会一直被占用直到线程终止，即使这个连接已不再需要了。这种方式缺乏有效的资源管理和回收策略。</li><li>连接泄漏的风险：如果开发者忘记在适当的时候关闭或清理 ThreadLocal 中的数据库连接，可能导致连接永远不会被释放，引起连接泄漏。</li><li>无法应对负载变化：由于 ThreadLocal 方式下的连接数是和线程数一一对应的，所以无法根据实际的数据库负载来动态调整连接数。而数据库连接池可以根据当前的负荷，动态地创建或释放连接。</li><li>缺少高级特性：数据库连接池通常提供很多高级特性，例如连接验证（自动检测并丢弃不可用的连接）、连接重试、负载均衡、读写分离、统计和监控等功能。而用 ThreadLocal 实现的连接复用缺乏这些特性。</li><li>多数据源管理困难：在实际的复杂应用场景中，可能会用到多个数据库。使用 ThreadLocal 方式管理多数据源的复用将会非常复杂和容易出错。</li><li>事务管理的复杂性：数据库连接池通常和事务管理器集成，可以帮助你更好地管理事务。单独使用 ThreadLocal 来管理连接，则会让事务管理变得复杂。</li><li>连接的创建和销毁开销：尽管 ThreadLocal 可以复用连接，但在高并发场景下，ThreadLocal 的方式可能导致每个线程都需要初始化自己的数据库连接，而数据库连接的创建和销毁是昂贵的操作，会造成不必要的性能开销。</li></ul><p>总结来说，ThreadLocal 提供了一种简单的方法来实现线程级别的数据库连接复用，但是它没有专门的数据库连接池强大和灵活。在需要管理数据库连接生命周期、动态调整连接数量、提供高可用性和高性能的场景下，使用专门的数据库连接池是更好的选择。</p>]]></content>
    
    
    <categories>
      
      <category>Pieces</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Java</tag>
      
      <tag>Concurrency</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Note: WSL2 Mirrored 网络模式下异常情况总结</title>
    <link href="/2023/11/25/Talks/talk-about-wsl2-network-mode-problems/"/>
    <url>/2023/11/25/Talks/talk-about-wsl2-network-mode-problems/</url>
    
    <content type="html"><![CDATA[<h2 id="Background">Background</h2><p>前段时间看到了 <a href="https://devblogs.microsoft.com/commandline/windows-subsystem-for-linux-september-2023-update/">Windows Subsystem for Linux September 2023 update - Windows Command Line</a> 这篇文章后，发现了 WSL 2 的新网络模式挺有意思的：</p><blockquote><p>Networking improvements are a consistent top ask for WSL, and this feature aims to improve the networking experience in WSL! This is a complete overhaul on the traditional NAT networking architecture of WSL, to an entirely new networking mode called “Mirrored”. The goal of this mode is to mirror the network interfaces that you have on Windows into Linux, to add new networking features and improve compatibility.</p><p>Here are the current benefits to enabling this mode:</p><ul><li>IPv6 support</li><li>Connect to Windows servers from within Linux using the localhost address 127.0.0.1</li><li>Connect to WSL directly from your local area network (LAN)</li><li>Improved networking compatibility for VPNs</li><li>Multicast support</li></ul></blockquote><p>于是果断升级了了 Preview 版的 WSL 2，但是最近在使用时遇到了两个问题，还是花了一段时间来解决，所以还是在这里记录一下。</p><h2 id="SSH-Connect">SSH Connect</h2><p>我之前买了一台 M2 的 Mac Mini 放在寝室里面用，为了把那台内存 24GB 的拯救者也用上，就打算有些使用 VSCode 的工作就直接通过 SSH 连过去用，本来以为把 WSL 的网络模式设为 Miorred 后就能直连，但其实至少还有以下几步：</p><ul><li>在 WSL 中安装 SSH (注意不需要在 Windows 中进行 SSH 的相关配置)<ul><li>这里如果要设置开机启动的话还要多一步，因为 systemctl 不能直接在 WSL 中使用</li></ul></li><li>设置端口，配置 SSH Keys</li></ul><p>然后我用 Mac Mini 在局域网中直连却被拒绝了，去网上一顿搜才发现是 HyperV 的防火墙还要设置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">New-NetFirewallHyperVRule -Name <span class="hljs-string">&quot;WSL 2&quot;</span> -Action Allow -Direction Inbound -LocalAddress Any -RemoteAddress Any -Protocol Any -LocalPort Any -RemotePort Any<br></code></pre></td></tr></table></figure><p>如果是只想放行一个端口的话也行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">New-NetFirewallHyperVRule -DisplayName <span class="hljs-string">&quot;allow WSL ssh&quot;</span> -Direction Inbound -LocalPorts 2222 -Action Allow<br></code></pre></td></tr></table></figure><p>这样就能随便连啦。</p><h2 id="Docker-Forwarding-Ports">Docker Forwarding Ports</h2><p>把 WSL2 的网络模式更改后，一直没咋使用 Docker，有段时间嫌它占资源，甚至都没允许它开机启动，最近突然需要用它临时开几个数据库用用，突然发现容器能正常运行，但是连接总是被拒绝。</p><p>急着用的那段时间我猜到了是这个新的网络模式的锅，毕竟在那篇博客里说了微软家的亲儿子 VSCode 使用这个新网络模式时都会有不兼容的情况，所以赶紧换回了原来的 NAT 模式。</p><p>今天没事了我又去研究了一下，我一开始以为是 HyperV 防火墙的锅，放行了对应的端口后还是连接不上，又去网上一顿找，找到了这篇帖子：<a href="https://github.com/microsoft/WSL/issues/10494">WSL 2.0: <code>networkingMode=mirrored</code> makes Docker unable to forward ports · Issue #10494 · microsoft/WSL</a>。</p><hr><blockquote><p>2024/01/22 更新</p></blockquote><p>此问题可以通过升级 Docker Desktop 至 4.25.0 及更高版本解决。我当前的 <code>.wslconfig</code> 恢复为了：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs config"># Settings apply across all Linux distros running on WSL 2<br>[wsl2]<br>memory=8GB<br>swap=4GB<br>[experimental]<br>autoMemoryReclaim=gradual<br>sparseVhd=true<br>networkingMode=mirrored<br>dnsTunneling=true<br>firewall=false<br>autoProxy=true<br># hostAddressLoopback=true<br># ignoredPorts=5432,3306,27017,6379<br></code></pre></td></tr></table></figure><hr><p>这篇帖子的大概意思就是说，现在 WSL 的团队还在和 Docker 那边的开发团队合作解决这个问题，目前只有临时的解决方案，后续的具体解决办法可以跟踪这个 issue，这里摘抄一名哥们的总结：</p><h3 id="Option1-without-docker-desktop">Option1 - without docker desktop</h3><p>Edit <code>%USERPROFILE%\.Wslconfig</code> file (create it, if doesn’t exist) and add this section</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs config">[experimental]<br>NetworkingMode=mirrored<br>HostAddressLoopback=true<br></code></pre></td></tr></table></figure><p>Restart WSL, then in your distro, edit <code>/etc/docker/daemon.json</code> and add</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br><span class="hljs-attr">&quot;iptables&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>Then <code>sudo systemctl restart docker</code>.</p><p>With this, both normal port usage like <code>python3 -m http.server</code> and docker port usage like <code>docker run -p &quot;8080:8080&quot; --rm -t mendhak/http-https-echo:26</code> are accessible from Windows side. The disadvantage is that <code>iptables</code> is now disabled.</p><h3 id="Option-2-with-Docker-Desktop">Option 2 - with Docker Desktop</h3><p>Edit <code>%USERPROFILE%\.wslconfig</code> file (create it, if doesn’t exist) and add this section</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs config">[experimental]<br>NetworkingMode=mirrored<br>HostAddressLoopback=true<br>IgnoredPorts = 8000,8080<br></code></pre></td></tr></table></figure><p>Restart WSL and ensure Docker Desktop is running. With this, the normal port usage stops working if it uses a port listed above. Eg the Python http. Server isn’t accessible over 8000 anymore (at least in my testing). Instead use a different port, like <code>python3 -m http. server 8001</code>. Docker ports will work as normal as long as the port is listed in the ignoredPorts above, like <code>docker run -p &quot;8080:8080&quot; --rm -t mendhak/http-https-echo:26</code></p><p><em><strong>The disadvantage here is you have to know which ports you’ll be using with Docker.</strong></em> And it doesn’t look like ignoredPorts accepts ranges of ports either so it can get pretty tedious.</p><p>目前我使用的是第二种方案，因为平常就使用 Docker 去运行一些数据库，所以需要暴露的端口相对固定，所以直接这么配置：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs config">ignoredPorts=5432,3306,27017,6379<br></code></pre></td></tr></table></figure><p>And ignoredPorts only applies to docker containers it seems, not simple python http servers, unless I messed up?<br>Did anyone run into the ignoredPorts issue as I did, for non-Docker applications?</p>]]></content>
    
    
    <categories>
      
      <category>Dev</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Note</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Paper Note: Cobra: Making Transactional Key-Value Stores Verifiably Serializable</title>
    <link href="/2023/11/23/Papers/Distributed%20Transactions/cobra/"/>
    <url>/2023/11/23/Papers/Distributed%20Transactions/cobra/</url>
    
    <content type="html"><![CDATA[<h2 id="Analyze">Analyze</h2><p>这篇论文关注在<strong>如何使用黑盒的方式验证</strong>键值存储的的可串行化。</p><h3 id="Background">Background</h3><p>如今许多客户选择使用云数据库提供的键值存储服务，客户程序的正确性受到云数据库的正确性的影响，云数据库的正确性常常通过可串行化来定义，即客户的事务仿佛以串行的方式执行，那么云数据库是否符合了可串行化的约束？这个问题有几个挑战，一方面数据库是黑盒的，我们无法得到数据库的代码，只能分析数据库的行为，即输入和输出，另一方面需要在数据库不断运行中，同步验证其是否符合可串行化的要求，这需要验证手段高效并具有可扩展性。</p><p>这篇论文的直觉来源于 SMT solver 以及计算能力的进步，认为其足以自动化的验证可串行化的问题，于是他们基于 SMT solver 提出 Cobra 框架，Cobra 包含一系列技术，做到了高效可扩展的验证可串行化，实验表明 Cobra 能验证实际场景下数据库的可串行化。</p><h3 id="Structures">Structures</h3><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231123172905410.png" alt=""></p><p>Each client request is one of five operations: start, commit, abort (which refer to <em>transactions</em>), and read and write (which refer to <em>keys</em>).</p><p><em><strong>History collectors</strong></em> sit between clients and the database, capturing the requests that clients issue and the (possibly wrong) results delivered by the database.</p><p>A <em><strong>verifier</strong></em> retrieves history fragments from collectors and attempts to verify whether the history is serializable.</p><p>The verifier proceeds in rounds; each round consists of a witness search, the input to which is logically the output of the previous round and new history fragments.</p><h3 id="Graph-and-the-Problem">Graph and the Problem</h3><p>A history imposes dependencies:</p><ul><li><em>read-dependency</em></li><li><em>write-dependency</em></li><li><em>anti-dependency</em></li></ul><p>A serialization graph (of a history and a given version order) is a graph whose vertices are all transactions in the history and edges are all dependencies described above.</p><p><em><strong>A history H is serializable iff there exists a version order such that the serialization graph arising from H and that version order is acyclic.</strong></em></p><h4 id="Polygraph">Polygraph</h4><p>In a polygraph, vertices (V) are transactions and edges (E) are read-dependencies. Note that read-dependencies are evident from the history because values are unique. There is a set, C, which we call <em>constraints</em>, that captures possible (but unknown) dependencies.</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231123195713518.png" alt=""></p><p>The constrain is shown as two dashed arrows connected by an arc. This constraint captures the fact that <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">T_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> cannot happen in between <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">T_3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</p><p>A directed graph is called <em>compatible</em> with a polygraph if the graph has the same nodes and known edges in the polygraph, and the graph chooses one edge out of each constraint.</p><p>A crucial fact is:</p><ul><li>There exists an acyclic directed graph that is compatible with the polygraph associated to a history H, iff there exists an acyclic serialization graph G of H.</li><li><strong>If there is such an acyclic serialization graph for H, then H is serializable</strong>.</li></ul><p>Putting these facts together yields a brute-force approach for verifying serializability: <em><strong>first, construct a polygraph from a history; second, search for a compatible graph that is acyclic.</strong></em></p><h3 id="Improvements-made-by-COBRA">Improvements made by COBRA</h3><p>我们可以将这个问题编码成 SMT solver 可以自动求解的约束，假如采用暴力求解的方式，搜索空间将是指数级 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mrow><mi mathvariant="normal">∣</mi><mi>C</mi><mi mathvariant="normal">∣</mi></mrow></msup></mrow><annotation encoding="application/x-tex">2^{|C|}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.888em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="mord mtight">∣</span></span></span></span></span></span></span></span></span></span></span></span>，其中|C|代表约束的个数，对于大型的历史，SMT solver 无法在有限时间内解决这个问题。</p><p>Cobra 提出了一系列技术来简化 Polygraph 中的约束：</p><ul><li>合并写</li><li>约束合并</li><li>剪枝</li></ul><p>这里以合并写为例进行介绍，合并写技术基于一个事务中先读某个键再写这个键（read-modify-write）这种特别的形式，如图所示的情况下，其中所有的读写都针对同一个键，左边代表原本约束的个数有 4 个，通过合并写技术可以将约束的个数减少为右边所示一个。</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231123200412012.png" alt=""></p><p>除了约束的简化，为了支持对不断增长的历史的验证，Cobra 对历史进行一轮一轮的验证，为了控制历史的有界性，需要在每一轮后对验证过的历史进行删除。测试表明 Cobra 能够检测出已经发现的可串行化问题，并且带来的 overhead 可以忽略不计。</p><h3 id="Limitations">Limitations</h3><ul><li>There is no guarantee that cobra terminates in reasonable time.</li><li>Cobra supports only a key-value API, and thus does not handle range queries and SQL operations such as “join” and “sum”.</li><li>Cobra does not yet support async (event-driven) I/O patterns in clients.</li><li>Cobra mostly punts fault-tolerance of the verifier and collectors</li></ul><h2 id="References">References</h2><ul><li><a href="https://www.usenix.org/system/files/osdi20-tan.pdf">osdi20-tan.pdf</a></li><li><a href="https://zhuanlan.zhihu.com/p/527078775">OSDI 2020 论文笔记连载</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Distributed</category>
      
      <category>Transactions</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PaperNote</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Paper Note: Epoxy: ACID Transactions Across Diverse Data Stores</title>
    <link href="/2023/11/22/Papers/Distributed%20Transactions/epoxy/"/>
    <url>/2023/11/22/Papers/Distributed%20Transactions/epoxy/</url>
    
    <content type="html"><![CDATA[<h2 id="Summary">Summary</h2><p>一句话总结，就是：<strong>Re-implement the multi-version concurrency control mechanism of Postgres on shim layers.</strong></p><p>因为这篇文章在组会上做了汇报，所以我就直接贴 PPT 了。</p><h2 id="Content">Content</h2><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/%E5%B9%BB%E7%81%AF%E7%89%873.png" alt=""></p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/%E5%B9%BB%E7%81%AF%E7%89%874.png" alt=""></p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/%E5%B9%BB%E7%81%AF%E7%89%875.png" alt=""></p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/%E5%B9%BB%E7%81%AF%E7%89%876.png" alt=""></p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/%E5%B9%BB%E7%81%AF%E7%89%877.png" alt=""></p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/%E5%B9%BB%E7%81%AF%E7%89%878.png" alt=""></p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/%E5%B9%BB%E7%81%AF%E7%89%879.png" alt=""></p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/%E5%B9%BB%E7%81%AF%E7%89%8710.png" alt=""></p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/%E5%B9%BB%E7%81%AF%E7%89%8711.png" alt=""></p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/%E5%B9%BB%E7%81%AF%E7%89%8712.png" alt=""></p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/%E5%B9%BB%E7%81%AF%E7%89%8713.png" alt=""></p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/%E5%B9%BB%E7%81%AF%E7%89%8714.png" alt=""></p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/%E5%B9%BB%E7%81%AF%E7%89%8715.png" alt=""></p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/%E5%B9%BB%E7%81%AF%E7%89%8716.png" alt=""></p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/%E5%B9%BB%E7%81%AF%E7%89%8717.png" alt="幻灯片17"></p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/%E5%B9%BB%E7%81%AF%E7%89%8718.png" alt="幻灯片18"></p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/%E5%B9%BB%E7%81%AF%E7%89%8719.png" alt="幻灯片19"></p>]]></content>
    
    
    <categories>
      
      <category>Distributed</category>
      
      <category>Transactions</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PaperNote</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Paper Note: Zab: High-performance broadcast for primary-backup systems</title>
    <link href="/2023/11/15/Papers/zab/"/>
    <url>/2023/11/15/Papers/zab/</url>
    
    <content type="html"><![CDATA[<h2 id="FAQ">FAQ</h2><p><em>What is the difference between receive and deliver?</em></p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231115165229785.png" alt="image-20231115165229785"></p><p><em>What does it mean by saying “Zab’s transaction log doubles as the database write-ahead transaction log” in page 3?</em></p><p>ZooKeeper uses an in-memory database and stores transaction logs (Write-ahead log) and periodic snapshots on disk.</p><blockquote><p>Before a transaction is executed and its changes are applied to the in-memory database, it is first logged. This means that if the system crashes before the changes can be applied, the transaction can be replayed from the log to ensure data integrity.</p></blockquote><p>Because of the need of recovering failures in Zab, Zab also need to store transaction logs.</p><p>Because the transaction log is used both for replicating data across the ZooKeeper ensemble (via Zab) and as the write-ahead transaction log, each transaction is written to disk only once. It’s not logged separately for replication and for the purpose of the in-memory database durability. <strong>The same log is used for both, which optimizes disk operations.</strong></p><h2 id="Analyze">Analyze</h2><h3 id="Requirements">Requirements</h3><p>ZooKeeper 对于下层的广播协议做了如下要求：</p><ul><li><em>Reliable delivery</em><ul><li>If a message, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">m</span></span></span></span>, is delivered by one server, then it will be eventually delivered by all correct servers.</li></ul></li><li><em>Total order</em><ul><li>If message <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span></span></span></span> is delivered before message <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span></span></span></span> by one server, then every server that delivers <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span></span></span></span> delivers <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span></span></span></span> before <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span></span></span></span>.</li></ul></li><li><em>Causal order</em><ul><li>If message <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span></span></span></span> causally precedes message <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span></span></span></span> and <strong>both messages are delivered</strong>, then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span></span></span></span> must be ordered before <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span></span></span></span>.</li></ul></li><li><em>Prefix property</em><ul><li>If <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">m</span></span></span></span> is the last message delivered for a leader <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span></span></span></span>, any message proposed before <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">m</span></span></span></span> by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span></span></span></span> must also be delivered.</li></ul></li></ul><p>With these three guarantees we can maintain correct replicas of the ZooKeeper database:</p><ul><li>The reliability and total order guarantees <strong>ensure that all of the replicas have a consistent state</strong>;<ul><li>Replicate State Machine 的思想，初始状态一致，操作一致，那么最后的状态肯定也是一致的。</li></ul></li><li>The causal order ensures that the replicas have state correct from the perspective of the application using Zab;<ul><li>Total order 只能保证所有副本的状态是一致的，由于不一定包含 causal order，<strong>对于上层应用来说</strong>，消息的递送可能是“乱序”的，即最基本的因果关系都没有遵循。</li></ul></li><li>The leader proposes updates to the database based on requests received.</li></ul><p>It is important to observe that there are two types of causal relationships taken into account by Zab:</p><ul><li>If two messages, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span></span></span></span>, are sent by the same server and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span></span></span></span> is proposed before <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span></span></span></span>, we say that <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span></span></span></span> causally precedes <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span></span></span></span>;<ul><li>同一个进程内部的 “Happened Before” 关系。</li></ul></li><li>Zab assumes a single leader server at a time that can commit proposals. If a leader changes, <strong>any previously proposed messages causally precede messages proposed by the new leader</strong>.<ul><li>如果 Leader 发生改变，前任 Leader 可能还有刚接受但未 broadcast 的事件，如果该进程之后重新获得 Leadership，这样的事件不应该被提交。</li></ul></li></ul><p>We do not assume synchronized clocks, but we do assume that servers perceive time pass at approximately the same rate. (We use timeouts to detect failures.)</p><h2 id="Protocol">Protocol</h2><p>Zab’s protocol consists of two modes: recovery and broadcast.</p><h3 id="Broadcast">Broadcast</h3><p>广播的过程整体比较像 2PC, 但是由于没有 abort 这个选项，所以 Zab 可以在收到大多数节点的 ack 后就进行提交，而不需要等待所有节点进行响应。</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/v2-4a0c818d44d19ab6cd90564a498f00f1_b.jpg" alt="img"></p><p>消息广播的具体细节：</p><ul><li>Leader 服务器接收到请求后在进行广播事务 Proposal 之前会为这个事务分配一个 ZXID，再进行广播。</li><li>Leader 服务器会为每个 Follower 服务器都各自分配一个单独的队列，然后将需要广播的事务 Proposal 依次放入这些队列中去，并根据 FIFO 策略进行消息的发送。<ul><li>其实就是一个 TCP 会话。</li></ul></li><li>每个 Follower 服务器在接收到后都会将其以事务日志的形式写入到本地磁盘中，并且在成功写入后返回 Leader 服务器一个 ACK 响应。</li><li>当有超过半数的服务器 ACK 响应后，Leader 就会广播一个 Commit 消息给所有的 Follower 服务器，Follower 接收到后就完成对事务的提交操作。</li></ul><h3 id="Recovery">Recovery</h3><p>To enable such a protocol to work despite failures of the leader there are two specific guarantees we need to make: we must never forget delivered messages and we need to let go of messages that are skipped.</p><p><strong>A message that gets delivered on one machine must be delivered on all even if that machine fails.</strong></p><p>This situation can easily occur if the leader commits a message and then fails before the COMMIT reaches any other server.</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231115212322951.png" alt="image-20231115212322951"></p><blockquote><p>Because the leader committed the message, a client could have seen the result of the transaction in the message, so the transaction must be delivered to all other servers eventually so that the client sees a consistent view of the service.</p></blockquote><p><strong>A skipped message must remain skipped.</strong></p><p>This situation can easily occur if a proposal gets generated by a leader and the leader fails before anyone else sees the proposal.</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231115212652799.png" alt="image-20231115212652799"></p><p>针对以上两个条件，Zab 在选 Leader 时只需要选出拥有最大 ZXID 的进程就行：</p><blockquote><p>If the leader election protocol guarantees that the new leader has the highest proposal number in a quorum of servers, a newly elected leader will also have all committed messages.</p><p>Before proposing any new messages a newly elected leader first makes sure that all messages that are in its transaction log have been proposed to and committed by a quorum of followers.</p></blockquote><p>奔溃恢复模式下 Leader 选举的过程细节如下：</p><ul><li>检测节点处于 LOOKING 阶段，开发选举 Leader</li><li>发起投票时有两种情况：</li><li>在服务启动的初始阶段，每个服务器都会投票给自己以（myid，zxid）的信息形式发送，那初始阶段没有 zxid 值，就会发送（myid，0）</li><li>在服务器运行期间，每个服务器上的 zxid 都有值，且 zxid 都不相同，所以就正常发送（myid，zxid）</li><li>各节点收到信息后将收到的（myid，zxid）和自己的比较，比较的过程前面已经说过，这里不再赘述</li><li>然后判断是否有半数的机器投票选出 Leader，如果否，在进入新一轮投票，直到选出</li><li>选出 Leader 后，其他节点就变成 Follower 角色，并向 Leader 发送自己服务器的最大 zxid ，Leader 服务器收到后会和自己本地的提议缓存队列进行比较，使用对应的策略进行同步。</li><li>当同步完成，集群就可以正常的处理请求了，就进入消息广播模式了。</li></ul><h4 id="Examples">Examples</h4><p>假设一开始 x 为 30，客户端发送请求：x+1</p><p>有几种情况：</p><ol><li>Leader 自己确认了这个（31），而 follower 都没有收到 commit（30），leader 重启后两者不一致</li><li>Leader 自己确认了这个（31），而 follower 都没有收到 commit（30），重新选举后会如何</li><li>Leader 自己确认了这个（31），而部分 follower 没有（30），但部分收到了，重新选举后会如何</li></ol><p>在上述情况中，读请求可能拿到不一样的数据，但由于写操作被限制了所以他能保证最终一致性。</p><p>我们把 Leader 的工作编号一下：</p><ol><li>发送 x=31 给所有 follower。</li><li>确认大多数 follower 已经复制了这个操作。</li><li>向所有 follower 发送 commit。</li></ol><p>这个过程的唯一变数其实出在第二步，所有的 Leader 启动时会加载本地日志，对他来说历史操作只有两种情况:</p><ul><li>已提交<ul><li>对于已提交的操作自然是无需理会。</li></ul></li><li>未提交<ul><li>对于未提交的操作 Leader 会重新确认一下是不是大多数 follower 都复制好了。</li></ul></li></ul><p>所以现在我们来看看，如果 Leader 重启了（或者是新当选了），他会回放本地未提交的日志（比如上述的30+1，只要有节点收到了该操作，zxid 更大的会当选）：</p><ul><li>如果发现此操作是已经被大多数 follower 复制了：他会把 commit 结果直接发给大家。</li><li>如果发现此操作还没被大多数 follower 复制：他会先广播到大多数都复制了再 commit。</li></ul><p>可以总结一下：</p><ul><li>如果 Leader 广播了一个操作并且成功被任意 Follower 收到，那么这个操作一定会被提交。<ul><li>被大多数 Follower 收到，直接 commit。</li><li>没有被大多数 Follower 收到，但新的 Leader 一定会有这条记录，所以会先广播再 commit。</li></ul></li><li>如果 Leader 只是收到了一个操作，还未来得及广播，就挂掉了，无论是否重连，这个操作都会被忽略。</li></ul><h2 id="References">References</h2><ul><li><a href="http://diyhpl.us/~bryan/papers2/distributed/distributed-systems/zab.totally-ordered-broadcast-protocol.2008.pdf">zab.totally-ordered-broadcast-protocol.2008.pdf</a></li><li><a href="https://zhuanlan.zhihu.com/p/267291281">zookeeper 核心之 ZAB 协议就这么简单！</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Distributed</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PaperNote</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>DDIA: Chapter 9 Consistency and Consensus</title>
    <link href="/2023/11/13/Books/Design%20Data-Intensive%20Applications/chapter-9-consistency-and-consensus/"/>
    <url>/2023/11/13/Books/Design%20Data-Intensive%20Applications/chapter-9-consistency-and-consensus/</url>
    
    <content type="html"><![CDATA[<blockquote><p>本章是这本书最酣畅淋漓的一章，涉及到了一致性和共识问题的方方面面，知识点多而不失条理。第一部分先讲了 Linearizability, 为后面的知识点做铺垫。到了 “Ordering Guarantees” 这一小节，从因果关系的带来的 “Happened Before” 的关系开始讲起，讲到了序列号和 Lamport Timestamp，提出来 Lamport Timestamp 的一个缺点：无法在某事件发生时判断是否有冲突，然后引出了全序关系广播，在全序关系广播中又讲到了和 Linearizable 之间的等价关系，最后引出共识算法。太精彩了，值得反复阅读！</p></blockquote><h2 id="Consistency-Guarantees">Consistency Guarantees</h2><p>Most replicated databases provide at least <em>eventual consistency</em>, which means that if you stop writing to the database and wait for some unspecified length of time, then eventually all read requests will return the same value.</p><p>A better name for eventual consistency may be <em>convergence</em>, as we expect all replicas to eventually converge to the same value.</p><blockquote><p><em>convergence</em>，直接译为收敛感觉最为形象，引用数学里的意思：随着某个值的变化，某个东西的状态最终趋于一个特定值。</p></blockquote><p>Systems with stronger guarantees may have worse performance or be less fault-tolerant than systems with weaker guarantees. Nevertheless, stronger guarantees can be appealing because they are easier to use correctly.</p><h2 id="Linearizability">Linearizability</h2><p>In a linearizable system, as soon as one client successfully completes a write, all clients reading from the database must be able to see the value just written. Maintaining the illusion of a single copy of the data means guaranteeing that the value read is the most recent, up-to-date value, and doesn’t come from a stale cache or replica.</p><blockquote><p>In other words, linearizability is a <em>recency guarantee</em>.</p></blockquote><h3 id="What-Makes-a-System-Linearizable">What Makes a System Linearizable?</h3><p>The basic idea behind linearizability is simple: to make a system appear as if there is only a single copy of the data.</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231110202052600.png" alt="image-20231110202052600"></p><h3 id="Linearizability-Versus-Serializability">Linearizability Versus Serializability</h3><ul><li><em>Serializability</em><ul><li>Serializability is an isolation property of <em>transactions</em>, where every transaction may read and write multiple objects.</li><li>It guarantees that transactions behave the same as if they had executed in some serial order.</li><li>It is okay for that serial order to <strong>be different from</strong> the order in which transactions were actually run.</li></ul></li><li><em>Linearizability</em><ul><li>Linearizability is a recency guarantee on reads and writes of a register.</li><li>It doesn’t group operations together into transactions, so it does not prevent problems such as write skew.</li></ul></li></ul><p>A database may provide both serializability and linearizability, and this combination is known as <em>strict serializability</em> or <em>strong one-copy serializability</em>.</p><p><strong>Implementations of serializability based on two-phase locking or actual serial execution are typically linearizable.</strong></p><h3 id="Relying-on-Linearizability">Relying on Linearizability</h3><h4 id="Locking-and-Leader-election">Locking and Leader election</h4><p>A system that uses single-leader replication needs to ensure that there is indeed only one leader, not several. One way of electing a leader is to use a lock: every node that starts up tries to acquire the lock, and the one that succeeds becomes the leader.</p><p>No matter how this lock is implemented, it must be linearizable: all nodes must agree which node owns the lock; otherwise it is useless.</p><blockquote><p>Coordination services like Apache ZooKeeper and etcd are often used to implement distributed locks and leader election. They use consensus algorithms to implement linearizable operations in a fault-tolerant way.</p></blockquote><p>严格意义上来说， ZooKeeper 和 etcd 都只提供线性写，即可能会读到旧数据，但是你可以请求一个线性读的操作：</p><ul><li>etcd calls this a <em>quorum read</em></li><li>in ZooKeeper you need to call <code>sync()</code></li></ul><h4 id="Constraints-and-uniqueness-guarantees">Constraints and uniqueness guarantees</h4><p>Uniqueness constraints are common in databases: for example, a username or email address must uniquely identify one user, and in a file storage service there cannot be two files with the same path and filename.</p><p>If you want to enforce this constraint <strong>as the data is written</strong> (such that if two people try to concurrently create a user or a file with the same name, one of them will be returned an error), you need linearizability.</p><p>This situation is actually similar to a lock: when a user registers for your service, you can think of them acquiring a “lock” on their chosen username.</p><h4 id="Cross-channel-timing-dependencies">Cross-channel timing dependencies</h4><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231110204511807.png" alt="image-20231110204511807"></p><p>If the file storage service is linearizable, then this system should work fine. If it is not linearizable, there is the risk of a race condition: the message queue (steps 3 and 4) might be faster than the internal replication inside the storage service. In this case, when the resizer fetches the image (step 5), it might see an old version of the image, or nothing at all. If it processes an old version of the image, the full-size and resized images in the file storage become permanently inconsistent.</p><p>This problem arises because there are two different communication channels between the web server and the resizer: the file storage and the message queue. Without the recency guarantee of linearizability, race conditions between these two channels are possible.</p><h3 id="Implementing-Linearizable-Systems">Implementing Linearizable Systems</h3><p>The most common approach to making a system fault-tolerant is to use replication. Let’s revisit the replication methods and compare whether they can be made linearizable:</p><ul><li><em>Single-leader replication (potentially linearizable)</em><ul><li>In a system with single-leader replication, the leader has the primary copy of the data that is used for writes, if you make reads from the leader, or from synchronously updated followers, they have the <em>potential</em> to be linearizable.</li></ul></li><li><em>Multi-leader replication (not linearizable)</em><ul><li>Systems with multi-leader replication are generally not linearizable, because they concurrently process writes on multiple nodes and asynchronously replicate them to other nodes.</li></ul></li><li><em>Leaderless replication (probably not linearizable)</em><ul><li>People sometimes claim that you can obtain “strong consistency” by requiring quorum reads and writes (w + r &gt; n).</li><li>Depending on the exact configuration of the quorums, and depending on how you define strong consistency, this is not quite true.</li></ul></li><li><em>Consensus algorithms (linearizable)</em><ul><li>Some consensus algorithms bear a resemblance to single-leader replication. However, consensus protocols contain measures to prevent split brain and stale replicas.</li></ul></li></ul><h4 id="Linearizability-and-quorums">Linearizability and quorums</h4><p>Intuitively, it seems as though strict quorum reads and writes should be linearizable in a Dynamo-style model. However, when we have variable network delays, it is possible to have race conditions, as demonstrated below:</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231110205316862.png" alt="A non-linearizable execution, despite using a strict quorum."></p><p>The initial value of x is 0, and a writer client is updating x to 1 by sending the write to all three replicas (n = 3, w = 3). Concurrently, client A reads from a quorum of two nodes (r = 2) and sees the new value 1 on one of the nodes. Also concurrently with the write, client B reads from a different quorum of two nodes, and gets back the old value 0 from both.</p><p>This execution is nevertheless not linearizable: B’s request begins after A’s request completes, but B returns the old value while A returns the new value.</p><blockquote><p>Interestingly, it is <em>possible</em> to make Dynamo-style quorums linearizable at the cost of reduced performance:</p><ul><li>A reader must perform read repair synchronously, before returning results to the application.</li><li>A writer must read the latest state of a quorum of nodes before sending its writes.<br>Moreover, only linearizable read and write operations can be implemented in this way; a linearizable compare-and-set operation cannot, because it requires a consensus algorithm.</li></ul></blockquote><h3 id="The-Cost-of-Linearizability">The Cost of Linearizability</h3><h4 id="The-CAP-theorem">The CAP theorem</h4><p>The trade-off is as follows:</p><ul><li>If your application <em>requires</em> linearizability, and some replicas are disconnected from the other replicas due to a network problem, then some replicas cannot process requests while they are disconnected: they must either wait until the network problem is fixed, or return an error (either way, they become <em>unavailable</em>).</li><li>If your application does <em>not require</em> linearizability, then it can be written in a way that each replica can process requests independently, even if it is disconnected from other replicas (e.g., multi-leader). In this case, the application can remain <em>available</em> in the face of a network problem, but its behavior is not linearizable.</li></ul><blockquote><p>Thus, a better way of phrasing CAP would be <em>either Consistent or Available when Partitioned</em>.</p></blockquote><p>The CAP theorem as formally defined is of very narrow scope: it only considers one consistency model (namely linearizability) and one kind of fault (network partitions, vi or nodes that are alive but disconnected from each other). It doesn’t say anything about network delays, dead nodes, or other trade-offs.</p><p><strong>Thus, although CAP has been historically influential, it has little practical value for designing systems.</strong></p><h4 id="Linearizability-and-network-delays">Linearizability and network delays</h4><p>Although linearizability is a useful guarantee, surprisingly few systems are actually linearizable in practice.</p><p>If you want linearizability, the response time of read and write requests is at least proportional to the uncertainty of delays in the network.</p><p>A faster algorithm for linearizability does not exist, but weaker consistency models can be much faster, so this trade-off is important for latency-sensitive systems.</p><h2 id="Ordering-Guarantees">Ordering Guarantees</h2><p>Something about ordering:</p><ul><li>the main purpose of the leader in single-leader replication is to determine the <em>order of writes</em> in the replication log—that is, the order in which followers apply those writes. If there is no single leader, conflicts can occur due to concurrent operations.</li><li>Serializability, is about ensuring that transactions behave as if they were executed in <em>some sequential order</em>.</li><li>The use of timestamps and clocks in distributed systems is another attempt to introduce order into a disorderly world, for example to determine which one of two writes happened later.</li></ul><h3 id="Ordering-and-Causality">Ordering and Causality</h3><p>There are several reasons why ordering keeps coming up, and one of the reasons is that it helps preserve <em>causality</em>.</p><blockquote><p>Causality imposes an ordering on events: cause comes before effect; a message is sent before that message is received; the question comes before the answer.</p></blockquote><p>If a system obeys the ordering imposed by causality, we say that it is <em>causally consistent</em>.</p><h4 id="The-Causal-order-is-not-a-total-order">The Causal order is not a total order</h4><p>A <em>total order</em> allows any two elements to be compared, so if you have two elements, you can always say which one is greater and which one is smaller.</p><p>The difference between a total order and a partial order is reflected in different database consistency models:</p><ul><li><em>Linearizability</em><ul><li>In a linearizable system, we have a <em>total order</em> of operations: if the system behaves as if there is only a single copy of the data, and every operation is atomic, this means that for any two operations we can always say which one happened first.</li></ul></li><li><em>Causality</em><ul><li>We said that two operations are concurrent if neither happened before the other. Two events are ordered if they are causally related (one happened before the other), but they are incomparable if they are concurrent. This means that causality defines a <em>partial order</em>, not a total order: some operations are ordered with respect to each other, but some are incomparable.</li></ul></li></ul><p>Therefore, according to this definition, there are no concurrent operations in a linearizable datastore: there must be a single timeline along which all operations are totally ordered.</p><p>Concurrency would mean that <strong>the timeline branches and merges again</strong>—and in this case, operations on different branches are incomparable.</p><h4 id="Linearizability-is-stronger-than-causal-consistency">Linearizability is stronger than causal consistency</h4><p>So what is the relationship between the causal order and linearizability? The answer is that linearizability implies causality: any system that is linearizable will preserve causality correctly.</p><p>The good news is that a middle ground is possible. Linearizability is not the only way of preserving causality—there are other ways too. A system can be causally consistent without incurring the performance hit of making it linearizable.</p><p>In fact, causal consistency is the strongest possible consistency model that does not slow down due to network delays, and remains available in the face of network failures.</p><h3 id="Sequence-Number-Ordering">Sequence Number Ordering</h3><p>However, there is a better way: we can use sequence numbers or timestamps to order events. A timestamp need not come from a time-of-day clock. It can instead come from a logical clock, which is an algorithm to generate a sequence of numbers to identify operations, typically using counters that are incremented for every operation.</p><p>Such sequence numbers or timestamps are compact, and they provide a total order.</p><p>只要我们获得了所有事件的全局排序，那么各种一致性模型对于读写操作所呈现的排序要求，很自然就能得到满足。</p><p>In particular, we can create sequence numbers in a total order that is consistent with causality: we promise that if operation A causally happened before B, then A occurs before B in the total order (A has a lower sequence number than B).</p><blockquote><p>Concurrent operations may be ordered arbitrarily.</p><p>Such a total order captures all the causality information, but also imposes more ordering than strictly required by causality.</p></blockquote><p><strong>In a database with single-leader replication, the replication log defines a total order of write operations that is consistent with causality.</strong></p><h4 id="Non-causal-sequence-number-generators">Non-causal sequence number generators</h4><p>If there is not a single leader (perhaps because you are using a multi-leader or leaderless database, or because the database is partitioned), it is less clear how to generate sequence numbers for operations. Various methods are used in practice:</p><ul><li>Each node can generate its own independent set of sequence numbers. For example, if you have two nodes, one node can generate only odd numbers and the other only even numbers.</li><li>You can attach a timestamp from a time-of-day clock (physical clock) to each operation. Such timestamps are not sequential, but if they have sufficiently high resolution, they <em>might be sufficient</em> to totally order operations.</li><li>You can preallocate blocks of sequence numbers.</li></ul><p>These three options all perform better and are more scalable than pushing all operations through a single leader that increments a counter.</p><p>However, they all have a problem: the sequence numbers they generate are <em>not consistent with causality</em>.</p><h4 id="Lamport-timestamps">Lamport timestamps</h4><blockquote><p>通过说明分布式下序列号生成失去了因果关系的一致性，引出了一种新的解决方法：Lamport Timestamp.</p></blockquote><p>Although the three sequence number generators just described are inconsistent with causality, there is actually a simple method for generating sequence numbers that is consistent with causality. It is called a <em>Lamport timestamp</em>(“time, clocks, and the ordering of event in the distributed systems”).</p><p>Each node has a unique identifier, and each node keeps a counter of the number of operations it has processed. The Lamport timestamp is then simply a pair of <code>(counter, node ID)</code>.</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231111155713795.png" alt="Lamport timestamps provide a total ordering consistent with causality."></p><p>A Lamport timestamp bears no relationship to a physical time-of-day clock, <strong>but it provides total ordering</strong>: if you have two timestamps, the one with a greater counter value is the greater timestamp; if the counter values are the same, the one with the greater node ID is the greater timestamp.</p><p>The key idea about Lamport timestamps, which makes them consistent with causality, is the following: every node and every client keeps track of the <em>maximum</em> counter value it has seen so far, and includes that maximum on every request.</p><p>When a node receives a request or response with a maximum counter value greater than its own counter value, it immediately increases its own counter to that maximum.</p><p>As long as the maximum counter value is carried along with every operation, <strong>this scheme ensures that the ordering from the Lamport timestamps is consistent with causality, because every causal dependency results in an increased timestamp.</strong></p><p>直观一点解释，因果性体现在哪些方面：</p><ul><li>同一个进程内部的前后两个操作<strong>可能</strong>具有因果性：<ul><li>Lamport Timestamp 保证了后进行的操作时间戳一定比前面进行的操作大。</li></ul></li><li>不同进程之间，消息的发送方和消息的接收方<strong>可能</strong>具有因果性：<ul><li>Lamport Timestamp 保证了消息的接收方的时间戳一定比消息发送方的时间戳大。</li></ul></li></ul><h4 id="Timestamp-ordering-is-not-sufficient">Timestamp ordering is not sufficient</h4><blockquote><p>“很有启发的一集。”</p></blockquote><p>Although Lamport timestamps define a total order of operations that is consistent with causality, they are not quite sufficient to solve many common problems in distributed systems.</p><p>For example, consider a system that needs to ensure that a username uniquely identifies a user account. If two users concurrently try to create an account with the same username, one of the two should succeed and the other should fail.</p><p>At first glance, it seems as though a total ordering of operations (e.g., using Lamport timestamps) should be sufficient to solve this problem: if two accounts with the same username are created, pick the one with the lower timestamp as the winner (the one who grabbed the username first), and let the one with the greater timestamp fail. Since timestamps are totally ordered, this comparison is always valid.</p><p>This approach works for determining the winner after the fact: <strong>once you have collected all the username creation operations in the system, you can compare their timestamps.</strong> However, it is not sufficient when a node has just received a request from a user to create a username, and needs to decide <em>right now</em> whether the request should succeed or fail.</p><p>The problem here is that <strong>the total order of operations only emerges after you have collected all of the operations.</strong> If another node has generated some operations, but you don’t yet know what they are, you cannot construct the final ordering of operations.</p><p>To conclude: <strong>in order to implement something like a uniqueness constraint for usernames, it’s not sufficient to have a total ordering of operations — you also need to know when that order is finalized.</strong></p><p>If you have an operation to create a username, and you are sure that no other node can insert a claim for the same username ahead of your operation in the total order, then you can safely declare the operation successful. This idea of knowing when your total order is finalized is captured in the topic of <em>total order broadcast</em>.</p><h3 id="Total-Order-Broadcast">Total Order Broadcast</h3><p>As discussed, single-leader replication determines a total order of operations by choosing one node as the leader and sequencing all operations on a single CPU core on the leader.</p><p>The challenge then is how to scale the system if the throughput is greater than a single leader can handle, and also how to handle failover if the leader fails. In the distributed systems literature, this problem is known as <em>total order broadcast</em> or <em>atomic broadcast</em>.</p><p>很多时候系统里的全序关系都是由 single-leader 维护的，因为所有的读和写请求都由它处理，最后写入日志的顺序就是整个系统中的全序顺序。但是如果系统的吞吐量大于了单个节点能够处理的范围或者当前的 Leader 挂掉了，全序关系广播就能发挥作用了。</p><p>Total order broadcast is usually described as a protocol for exchanging messages between nodes. Informally, it requires that two safety properties always be satisfied:</p><ul><li><em>Reliable delivery</em><ul><li>No messages are lost: if a message is delivered to one node, it is delivered to all nodes.</li></ul></li><li><em>Totally ordered delivery</em><ul><li>Messages are delivered to every node in the same order.</li></ul></li></ul><h4 id="Using-total-order-broadcast">Using total order broadcast</h4><p>Consensus services such as ZooKeeper and etcd actually implement total order broadcast.</p><blockquote><p>This fact is a hint that there is a strong connection between total order broadcast and consensus.</p></blockquote><p>Total order broadcast is exactly what you need for database replication: if every message represents a write to the database, and every replica processes the same writes in the same order, then the replicas will remain consistent with each other (aside from any temporary replication lag). This principle is known as <em>state machine replication</em>.</p><p>An important aspect of total order broadcast is that <strong>the order is fixed at the time the messages are delivered</strong>: a node is not allowed to retroactively insert a message into an earlier position in the order if subsequent messages have already been delivered. This fact makes total order broadcast stronger than timestamp ordering.</p><p>Another way of looking at total order broadcast is that it is a way of creating a log (as in a replication log, transaction log, or write-ahead log): delivering a message is like appending to the log. Since all nodes must deliver the same messages in the same order, all nodes can read the log and see the same sequence of messages.</p><h4 id="Implementing-linearizable-storage-using-total-order-broadcast">Implementing linearizable storage using total order broadcast</h4><blockquote><p>注意这节的小标题是用 total order broadcast 实现一个 linearizable storage.</p></blockquote><p>Total order broadcast is asynchronous: messages are guaranteed to be delivered reliably in a fixed order, but there is no guarantee about <em>when</em> a message will be delivered (so one recipient may lag behind the others). By contrast, linearizability is a <em>recency guarantee</em>: a read is guaranteed to see the latest value written.</p><p>所以如何解决前文提到的那个用户名限制的问题呢？</p><p>Imagine that for every possible username, you can have a linearizable register with an atomic compare-and-set operation.</p><p>Every register initially has the value null (indicating that the username is not taken). When a user wants to create a username, you execute a compare-and-set operation on the register for that username, setting it to the user account ID, under the condition that the previous register value is null. If multiple users try to concurrently grab the same username, only one of the compare-and-set operations will succeed, because the others will see a value other than null (due to linearizability).</p><blockquote><p>为什么 compare-and-set 机制需要 linearizability 呢？</p><p>你可以这么想：compare-and-set 操作是有 <em>recency</em> 需求的，即必须保证每次 compare 操作都一定能读到最新的数据，然而只有 linearizability 才能提供这种 <em>recency guarantee</em>。</p></blockquote><p>You can implement such a linearizable compare-and-set operation as follows by using total order broadcast as an append-only log:</p><ol><li>Append a message to the log, tentatively indicating the username you want to claim.</li><li>Read the log, and wait for the message you appended to be delivered back to you.</li><li>Check for any messages claiming the username that you want.</li></ol><ul><li>If the first message for your desired username is your own message, then you are successful: you can commit the username claim (perhaps by appending another message to the log) and acknowledge it to the client.</li><li>If the first message for your desired username is from another user, you abort the operation.</li></ul><blockquote><p>A similar approach can be used to implement serializable multi-object transactions on top of a log.</p></blockquote><p>While this procedure ensures linearizable writes, it doesn’t guarantee linearizable reads — if you read from a store that is asynchronously updated from the log, it may be stale. (To be precise, the procedure described here provides <em>sequential consistency</em>, sometimes also known as <em>timeline consistency</em>, a slightly weaker guarantee than <em>linearizability</em>.) To make reads linearizable, there are a few options:</p><ul><li>You can sequence reads through the log by appending a message, reading the log, and performing the actual read when the message is delivered back to you.<ul><li>etcd somehow works like this.</li></ul></li><li>If the log allows you to fetch the position of the latest log message in a linearizable way, you can query that position, wait for all entries up to that position to be delivered to you, and then perform the read.<ul><li>This is the idea behind ZooKeeper’s <code>sync()</code> operation.</li></ul></li><li>You can make your read from a replica that is synchronously updated on writes, and is thus sure to be up to date.<ul><li>This technique is used in chain replication.</li></ul></li></ul><h4 id="Implementing-total-order-broadcast-using-linearizable-storage">Implementing total order broadcast using linearizable storage</h4><blockquote><p>用 linearizable storage 实现一个 total order broadcast</p></blockquote><p>The easiest way is to assume you have a linearizable register that stores an integer and that has an atomic increment-and-get operation. Alternatively, an atomic compare-and-set operation would also do the job.</p><p>The algorithm is simple:</p><ul><li>For every message you want to send through total order broadcast, you increment-and-get the linearizable integer</li><li>Attach the value you got from the register as a sequence number to the message.</li><li>You can then send the message to all nodes (resending any lost messages), and the recipients will deliver the messages consecutively by sequence number.</li></ul><p>Note that unlike Lamport timestamps, the numbers you get from incrementing the linearizable register form a sequence with no gaps. <strong>Thus, if a node has delivered message 4 and receives an incoming message with a sequence number of 6, it knows that it must wait for message 5 before it can deliver message 6.</strong></p><p>这里结合 linearizable storage 来说明一下如何利用全序关系广播来维护唯一性限制的，用注册用户名来说明：</p><p>首先分为上层应用和下层协议：</p><ol><li>用户在输入用户名后，上层应用向下层协议提出消息。</li><li>上层应用监视下层协议的消息提交，如果第一条有关某用户名的声称是自己提交的，那么该用户名可用，否则已经被占用。</li><li>下层协议收到消息后，向 linearizable storage 执行 increment-and-get 操作获取序列号。</li><li>获取序列号后，下层协议先向自己的上层应用提交该消息，再向其他所有节点广播该消息。</li></ol><p>步骤 3 是需要时间的，如果上层应用在提出消息后还没收到自己的消息时，收到了来自于其他节点的关于相同用户名的声称，则知晓该用户名已经被占用。</p><p>This is the key difference between total order broadcast and timestamp ordering.</p><p>How hard could it be to make a linearizable integer with an atomic increment-and-get operation?</p><p>As usual, if things never failed, it would be easy: you could just keep it in a variable on one node. The problem lies in handling the situation when network connections to that node are interrupted, and restoring the value when that node fails.</p><p>In general, if you think hard enough about linearizable sequence number generators, you inevitably end up with a consensus algorithm.</p><p>This is no coincidence: it can be proved that a linearizable compare-and-set (or increment-and-get) register and total order broadcast are <em>both equivalent to consensus</em>. That is, if you can solve one of these problems, you can transform it into a solution for the others.</p><p>This is quite a profound and surprising insight!</p><h2 id="Distributed-Transactions-and-Consensus">Distributed Transactions and Consensus</h2><p>Consensus is one of the most important and fundamental problems in distributed computing. On the surface, it seems simple: informally, the goal is simply to <em>get several nodes to agree on something</em>.</p><h3 id="Atomic-Commit-and-Two-Phase-Commit-2-PC">Atomic Commit and Two-Phase Commit (2 PC)</h3><h4 id="Introduction-to-two-phase-commit">Introduction to two-phase commit</h4><p>Two-phase commit is an algorithm for achieving atomic transaction commit across multiple nodes—i.e., to ensure that either all nodes commit or all nodes abort.</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231112155232884.png" alt="A successful execution of two-phase commit"></p><h4 id="A-system-of-promises">A system of promises</h4><p>In a bit more detail:</p><ol><li>When the application wants to begin a distributed transaction, it requests a transaction ID from the coordinator. This transaction ID is globally unique.</li><li>The application begins a single-node transaction on each of the participants, and attaches the globally unique transaction ID to the single-node transaction. All reads and writes are done in one of these single-node transactions.</li><li>When the application is ready to commit, the coordinator sends a prepare request to all participants, tagged with the global transaction ID.</li><li>When a participant receives the prepare request, it makes sure that it can definitely commit the transaction under all circumstances.</li><li>When the coordinator has received responses to all prepare requests, it makes a definitive decision on whether to commit or abort the transaction.</li><li>Once the coordinator’s decision has been written to disk, the commit or abort request is sent to all participants. If this request fails or times out, the coordinator must retry forever until it succeeds.</li></ol><p>Thus, the protocol contains two crucial “points of no return”:</p><ol><li>When a participant votes “yes,” it promises that it will definitely be able to commit later (although the coordinator may still choose to abort).</li><li>Once the coordinator decides, that decision is irrevocable. Those promises ensure the atomicity of 2 PC.</li></ol><h3 id="Distributed-Transactions-in-Practice">Distributed Transactions in Practice</h3><p>Some implementations of distributed transactions carry a heavy performance penalty —for example, distributed transactions in MySQL are reported to be over 10 times slower than single-node transactions.</p><p>Two quite different types of distributed transactions are often conflated:</p><ul><li><em>Database-internal distributed transactions</em><ul><li>Some distributed databases (i.e., databases that use replication and partitioning in their standard configuration) support internal transactions among the nodes of that database.</li><li>In this case, all the nodes participating in the transaction are running the same database software.</li></ul></li><li><em>Heterogeneous distributed transactions</em><ul><li>In a <em>heterogeneous</em> transaction, the participants are two or more different technologies: for example, two databases from different vendors, or even non-database systems such as message brokers.</li></ul></li></ul><h4 id="Limitations-of-distributed-transactions">Limitations of distributed transactions</h4><p>XA transactions solve the real and important problem of keeping several participant data systems consistent with each other, but as we have seen, they also introduce major operational problems. In particular, the key realization is that the transaction coordinator is itself a kind of database:</p><ul><li>If the coordinator is not replicated but runs only on a single machine, it is a single point of failure for the entire system.</li><li>Many server-side applications are developed in a stateless model (as favored by HTTP), with all persistent state stored in a database.</li><li>Since XA needs to be compatible with a wide range of data systems, it is necessarily a lowest common denominator.</li></ul><h3 id="Fault-Tolerant-Consensus">Fault-Tolerant Consensus</h3><p>The consensus problem is normally formalized as follows: one or more nodes may <em>propose</em> values, and the consensus algorithm <em>decides</em> on one of those values.</p><p>In this formalism, a consensus algorithm must satisfy the following properties:</p><ul><li><em>Uniform agreement</em><ul><li>No two nodes decide differently.</li></ul></li><li><em>Integrity</em><ul><li>No node decides twice.</li></ul></li><li><em>Validity</em><ul><li>If a node decides value v, then v was proposed by some node.</li></ul></li><li><em>Termination</em><ul><li>Every node that does not crash eventually decides some value.</li><li>This is a <em>liveness</em> property.</li><li>In particular, 2PC does not meet the requirements for termination.</li></ul></li></ul><p>The uniform agreement and integrity properties define the core idea of consensus: <strong>everyone decides on the same outcome, and once you have decided, you cannot change your mind.</strong></p><h4 id="Consensus-algorithms-and-total-order-broadcast">Consensus algorithms and total order broadcast</h4><p>The best-known fault-tolerant consensus algorithms are Viewstamped Replication (VSR), Paxos, Raft, and Zab. There are quite a few similarities between these algorithms, but they are not the same.</p><p>Remember that total order broadcast requires messages to be delivered exactly once, in the same order, to all nodes. If you think about it, this is equivalent to performing several rounds of <em>consensus</em>: in each round, nodes propose the message that they want to send next, and then decide on the next message to be delivered in the total order.</p><p>So, total order broadcast is equivalent to repeated rounds of consensus (each consensus decision corresponding to one message delivery):</p><ul><li>Due to the agreement property of consensus, all nodes decide to deliver the same messages in the same order.</li><li>Due to the integrity property, messages are not duplicated.</li><li>Due to the validity property, messages are not corrupted and not fabricated out of thin air.</li><li>Due to the termination property, messages are not lost.</li></ul><p>Viewstamped Replication, Raft, and Zab implement total order broadcast directly, because that is more efficient than doing repeated rounds of one-value-at-a-time consensus. In the case of Paxos, this optimization is known as Multi-Paxos.</p><h4 id="Single-leader-replication-and-consensus">Single-leader replication and consensus</h4><blockquote><p>粗看本章的内容，好像第 5 章讲到的 single-leader replication 已经是个全序关系广播了：it takes all the writes to the leader and applies them to the followers in the same order, thus keeping replicas up to date.</p><p>作者在这个小节回答了这个疑问。</p></blockquote><p>The answer comes down to how the leader is chosen. If the leader is manually chosen and configured by the humans in your operations team, you essentially have a “consensus algorithm” of the dictatorial variety: only one node is allowed to accept writes (i.e., make decisions about the order of writes in the replication log), and if that node goes down, the system becomes unavailable for writes until the operators manually configure a different node to be the leader. Such a system can work well in practice, but it does not satisfy the termination property of consensus because it requires human intervention in order to make progress.</p><p>Some databases perform automatic leader election and failover, promoting a follower to be the new leader if the old leader fails. This brings us closer to fault-tolerant total order broadcast, and thus to solving consensus.</p><p>However, there is a problem. We previously discussed the problem of split brain, and said that all nodes need to agree who the leader is—otherwise two different nodes could each believe themselves to be the leader, and consequently get the database into an inconsistent state. Thus, we need consensus in order to elect a leader. But if the consensus algorithms described here are actually total order broadcast algorithms, and total order broadcast is like single-leader replication, and single-leader replication requires a leader, then…</p><blockquote><p>It seems that in order to elect a leader, we first need a leader. In order to solve consensus, we must first solve consensus. How do we break out of this conundrum?</p></blockquote><h4 id="Epoch-numbering-and-quorums">Epoch numbering and quorums</h4><p>All of the consensus protocols discussed so far internally use a leader in some form or another, but they don’t guarantee that the leader is unique. Instead, they can make a weaker guarantee: the protocols define an <em>epoch number</em> (called the <em>ballot number</em> in Paxos, <em>view number</em> in Viewstamped Replication, and <em>term number</em> in Raft) and guarantee that <strong>within each epoch, the leader is unique.</strong></p><p>Thus, we have two rounds of voting: once to choose a leader, and a second time to vote on a leader’s proposal. The key insight is that the quorums for those two votes must overlap.</p><h4 id="Limitations-of-consensus">Limitations of consensus</h4><p>The benefits of consensus algorithm come at a cost:</p><ul><li>The process by which nodes vote on proposals before they are decided is a kind of synchronous replication.</li><li>Consensus systems always require a strict majority to operate. This means you need a minimum of three nodes in order to tolerate one failure.</li><li>Consensus systems generally rely on timeouts to detect failed nodes. Frequent leader elections result in terrible performance because the system can end up spending more time choosing a leader than doing any useful work.</li><li>Sometimes, consensus algorithms are particularly sensitive to network problems.</li></ul><h3 id="Membership-and-Coordination-Services">Membership and Coordination Services</h3><p>As an application developer, you will rarely need to use ZooKeeper directly, because it is actually not well suited as a general-purpose database. It is more likely that you will end up relying on it indirectly via some other project: for example, HBase, Hadoop YARN, OpenStack Nova, and Kafka all rely on ZooKeeper running in the background.</p><p>ZooKeeper and etcd are designed to hold small amounts of data that can fit entirely in memory. That small amount of data is replicated across all the nodes using a fault-tolerant total order broadcast algorithm.</p><blockquote><p>Total order broadcast is just what you need for database replication: if each message represents a write to the database, applying the same writes in the same order keeps replicas consistent with each other.</p></blockquote><p>ZooKeeper is modeled after Google’s Chubby lock service, implementing not only total order broadcast (and hence consensus), but also an interesting set of other features that turn out to be particularly useful when building distributed systems:</p><ul><li><em>Linearizable atomic operations</em><ul><li>Using an atomic compare-and-set operation, you can implement a lock.</li></ul></li><li><em>Total ordering of operations</em><ul><li>when some resource is protected by a lock or lease, you need a <em>fencing token</em> to prevent clients from conflicting with each other in the case of a process pause.</li></ul></li><li><em>Failure detection</em></li><li><em>Change notifications</em></li></ul><h2 id="Summary">Summary</h2><blockquote><p>之前几章的 Summary 我都是随便看看，但这章的 Summary 真的有含金量，所以还是总结一波。</p></blockquote><p>We looked in depth at linearizability, a popular consistency model: its goal is to make replicated data appear as though there were only a single copy, and to make all operations act on it atomically.</p><p>We also explored causality, which imposes an ordering on events in a system (what happened before what, based on cause and effect). Unlike linearizability, which puts all operations in a single, totally ordered timeline, causality provides us with a weaker consistency model: some things can be concurrent, so the version history is like a timeline with branching and merging. Causal consistency does not have the coordination overhead of linearizability and is much less sensitive to network problems.</p><p>However, even if we capture the causal ordering (for example using Lamport timestamps), we saw that some things cannot be implemented this way: We considered the example of ensuring that a username is unique and rejecting concurrent registrations for the same username.This problem led us toward <em>consensus</em>.</p><p>With some digging, it turns out that a wide range of problems are actually reducible to consensus and are equivalent to each other:</p><ul><li><em>Linearizable compare-and-set registers</em><ul><li>The register needs to atomically <em>decide</em> whether to set its value, based on whether its current value equals the parameter given in the operation.</li></ul></li><li><em>Atomic transaction commit</em><ul><li>A database must <em>decide</em> whether to commit or abort a distributed transaction.</li></ul></li><li><em>Total order broadcast</em><ul><li>The messaging system must <em>decide</em> on the order in which to deliver messages.</li></ul></li><li><em>Locks and leases</em><ul><li>When several clients are racing to grab a lock or lease, the lock <em>decides</em> which one successfully acquired it.</li></ul></li><li><em>Membership/coordination service</em><ul><li>Given a failure detector (e.g., timeouts), the system must <em>decide</em> which nodes are alive, and which should be considered dead because their sessions timed out.</li></ul></li><li><em>Uniqueness constraint</em><ul><li>When several transactions concurrently try to create conflicting records with the same key, the constraint must <em>decide</em> which one to allow and which should fail with a constraint violation.</li></ul></li></ul><p><strong>All of these are straightforward if you only have a single node, or if you are willing to assign the decision-making capability to a single node.</strong> This is what happens in a single-leader database: all the power to make decisions is vested in the leader, which is why such databases are able to provide linearizable operations, uniqueness constraints, a totally ordered replication log, and more.</p><p>However, if that single leader fails, there are three ways of handling that situation:</p><ul><li>Wait for the leader to recover, and accept that the system will be blocked in the meantime.</li><li>Manually fail over by getting humans to choose a new leader node and reconfigure the system to use it.</li><li>Use an algorithm to automatically choose a new leader. This approach requires a <em>consensus</em> algorithm, and it is advisable to use a proven algorithm that correctly handles adverse network conditions.</li></ul><p>Although a single-leader database can provide linearizability without executing a consensus algorithm on every write, it still requires consensus to maintain its leadership and for leadership changes.</p>]]></content>
    
    
    <categories>
      
      <category>Design Data-Intensive Applications</category>
      
    </categories>
    
    
    <tags>
      
      <tag>BookNote</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Paper Note: CAP Twelve Years Later: How the &quot;Rules&quot; have Changed</title>
    <link href="/2023/11/12/Papers/cap-twelve-years-later/"/>
    <url>/2023/11/12/Papers/cap-twelve-years-later/</url>
    
    <content type="html"><![CDATA[<h2 id="FAQ">FAQ</h2><p><em>what is a version vector?</em></p><p>A version vector is a construct used in distributed systems to track the version of data across different nodes in a network, ensuring consistency and helping to resolve conflicts. Version vectors are particularly useful in systems where multiple nodes may independently modify data and then need to synchronize with each other without relying on a central authority. This concept is fundamental in the context of eventual consistency and conflict resolution in distributed databases, file systems, and data replication scenarios.</p><p>Each node in the system maintains a version vector for any piece of data it is responsible for. A version vector is essentially an array or a map of logical counters, with one counter for every node that could potentially update the data. Here’s a simplified representation of how a version vector might work:</p><ol><li>Each node in the system is assigned a unique identifier.</li><li>Whenever a node updates a piece of data, it increments its counter in the version vector associated with that data.</li><li>When nodes exchange data, they also share the corresponding version vectors.</li><li>On receiving an updated piece of data, a node can compare the received version vector with its local version vector to determine if the update is new, older, or concurrent with its own updates.</li></ol><p><strong>Based on the comparison, the node can decide whether to accept the update, reject it, or merge it in case of concurrent updates.</strong></p><blockquote><p>Merging may involve application-specific conflict resolution logic.</p></blockquote><p>For example, consider three nodes, A, B, and C. Each has a version vector:</p><ul><li>A’s version vector might be {A:2, B:1, C:0}, indicating that A has seen two updates from itself and one from B.</li><li>B’s version vector could be {A:1, B:2, C:1}, showing it has seen one update from A, two from itself, and one from C.</li><li>C’s version vector might be {A:0, B:1, C:1}, showing it saw one update from B and one from itself.</li></ul><p>If node A sends an update to C, C can compare A’s version vector with its own. If A’s vector is higher for A’s counter and equal or lower for all the other counters, C can conclude that the update from A is more recent and should be applied.</p><p>Version vectors are a key part of the broader category of vector clocks, which are used for similar purposes but can capture causal relationships between events in distributed systems. They are necessary for conflict-free replicated data types (CRDTs), which rely on these mechanisms for conflict-free data synchronization across distributed nodes.</p><p><em>what is a commutative operation?</em></p><p>A commutative operation is a binary operation that yields the same result regardless of the order of the operands. This property is one of the fundamental characteristics of certain mathematical operations. In formal terms, an operation <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∗</mo></mrow><annotation encoding="application/x-tex">\ast</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4653em;"></span><span class="mord">∗</span></span></span></span> on a set <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span> is commutative if, for all elements <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span></span></span></span> in <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span>:</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>a</mi><mo>∗</mo><mi>b</mi><mo>=</mo><mi>b</mi><mo>∗</mo><mi>a</mi><mtext> </mtext></mrow><annotation encoding="application/x-tex">a \ast b = b \ast a </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4653em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span><span class="mord"> </span></span></span></span></span></p><p>Common examples of commutative operations in arithmetic include addition and multiplication. For any two numbers <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span>, the following always holds true:</p><p class='katex-block katex-error ' title='ParseError: KaTeX parse error: Can&#039;t use function &#039;$&#039; in math mode at position 15: x + y = y + x $̲$ $$ x \times y…'>x + y = y + x $$ $$ x \times y = y \times x </p><p>In the context of computer science and programming, the concept of commutativity is also important. It plays a critical role in parallel and distributed computing, as commutative operations can be executed in any order without affecting the final outcome. This allows for optimizations such as parallel processing and conflict-free merge operations in distributed systems.</p><p>For example, in a distributed database, <strong>if two transactions are performing commutative operations, they can be safely executed in parallel or in any order without causing inconsistency in the database.</strong> This is crucial for designing highly available and scalable systems.</p><h2 id="Introduction">Introduction</h2><p>这篇文章没啥难度，主要是讲了 CAP 理论的一些常见误解和现在的 CAP 理论发展的情况。</p><p>The “2 of 3” formulation was always misleading because it tended to oversimplify the tensions among properties.</p><p>CAP prohibits only a tiny part of the design space: perfect availability and consistency in the presence of partitions, which are rare.</p><p>The modern CAP goal should be to maximize combinations of consistency and availability that make sense for the <strong>specific application</strong>.</p><blockquote><p>对于不同的应用，解决方案一般是不同的，后文讲到了许多案例。</p></blockquote><h2 id="对-CAP-的误解">对 CAP 的误解</h2><p>The NoSQL movement is about creating choices that focus on availability first and consistency second; databases that adhere to ACID properties (atomicity, consistency, isolation, and durability) do the opposite.</p><p>As the “CAP Confusion” sidebar explains, the “2 of 3” view is misleading on several fronts：</p><ul><li>First, because partitions are rare, there is little reason to forfeit C or A when the system is not partitioned.</li><li>Second, the choice between C and A can occur many times within the same system <strong>at very fine granularity</strong>.</li><li>Finally, all three properties are <strong>more continuous than binary</strong>.</li></ul><h2 id="有关延迟">有关延迟</h2><p>Operationally, the essence of CAP takes place during a timeout, a period when the program must make a fundamental decision — the partition <em>decision</em>:</p><ul><li>Cancel the operation and thus decrease availability.</li><li>Or proceed with the operation and thus risk inconsistency.</li></ul><blockquote><p>Retrying communication to achieve consistency, for example, via Paxos or a two-phase commit, just delays the decision.</p></blockquote><p>Failing to achieve consistency within the time bound implies a partition and thus a choice between C and A for this operation.</p><p>Sometimes it makes sense to forfeit strong C to avoid the high latency of maintaining consistency over a wide area.</p><p>Yahoo’s PNUTS system incurs inconsistency by maintaining remote copies asynchronously. However, it makes the master copy local, which decreases latency. This strategy works well in practice because single user data is naturally partitioned according to the user’s (normal) location. Ideally, each user’s data master is nearby.</p><h2 id="CAP-带来的困惑">CAP 带来的困惑</h2><p>简单整理了一下：</p><ul><li>If users cannot reach the service at all, there is no choice between C and A except when part of the service runs on the client.</li><li>Independent, self-consistent subsets can make forward progress while partitioned, although it is not possible to ensure global invariants.</li><li>If the choice is CA, and then there is a partition, the choice must revert to C or A. It is best to think about this probabilistically: choosing CA should mean that the probability of a partition is far less than that of other systemic failures, such as disasters or multiple simultaneous faults.<ul><li>In practice, most groups assume that a datacenter (single site) has no partitions within, and thus design for CA within a single site.</li><li>Given the high latency across the wide area, it is relatively common to forfeit perfect consistency across the wide area for better performance.</li></ul></li><li>Another aspect of CAP confusion is the hidden cost of forfeiting consistency, which is the need to know the system’s invariants. <strong>The subtle beauty of a consistent system is that the invariants tend to hold even when the designer does not know what they are.</strong></li></ul><h2 id="如何处理网络分区">如何处理网络分区</h2><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231113193814121.png" alt="image-20231113193814121"></p><p>The key idea is to manage partitions very explicitly, including not only detection, but also a specific recovery process and a plan for all of the invariants that might be violated during a partition. This management approach has three steps:</p><ul><li>Detect the start of a partition.</li><li>Enter an explicit partition mode that may limit some operations.</li><li>Initiate partition recovery when communication is restored.</li></ul><p>简单总结一下，就是：</p><ul><li>检测到分区情况出现</li><li>进入到一个可能会限制操作的显式分区模式<ul><li>有两种操作：<ul><li>限制操作，降低可用性</li><li>不限制操作，但是要记录额外的信息，方便分区恢复时使用</li></ul></li></ul></li><li>通讯恢复后发起分区恢复操作<ul><li>为了重新恢复一致性，并且补偿之前不一致的错误</li></ul></li><li>在决定限制操作时，一般是根据系统必须遵守的不变量来决定<ul><li>如果不限制操作，就有可能违反不变量，必须在分区恢复时修复该不变量</li><li>如果限制操作，就可以保证维护特定的不变量</li><li>对于外部事件来说，一般就是延迟执行直到分区恢复后</li></ul></li></ul><h2 id="分区恢复">分区恢复</h2><p>设计者必须解决两个困难的问题：</p><ul><li>不同分区的状态在分区恢复后必须一致</li><li>必须补偿在网络分区时出现的错误决策</li></ul><p>It is generally easier to fix the current state by starting from the state at the time of the partition and rolling forward both sets of operations in some manner, maintaining consistent state along the way.</p><p>大部分系统都不能自行解决冲突，比如 CVS，出现冲突后需要用户手动解决。但是如果在分区时限制用户操作，是可能的：</p><p>A case in point is text editing in Google Docs, 11 which limits operations to applying a style and adding or deleting text.</p><p>Delaying risky operations is one relatively easy implementation of this strategy.</p><p>最后论文提到了两种局限性较大但是能自动合并冲突的方法：</p><ul><li>Using commutative operations.</li><li>Using commutative replicated data types (CRDTs).</li></ul><h2 id="错误补偿">错误补偿</h2><p>There are various ways to fix the invariants, including trivial ways such as “last writer wins” (which ignores some updates).</p><p>Smarter approaches that merge operations, and human escalation. An example of the latter is airplane overbooking: boarding the plane is in some sense partition recovery with the invariant that there must be at least as many seats as passengers. If there are too many passengers, some will lose their seats, and ideally customer service will compensate those passengers in some way.</p><p>The idea of compensation is really at the core of fixing such mistakes; designers must create compensating operations that both restore an invariant and more broadly correct an externalized mistake.</p><p>Some researchers have formally explored compensating transactions as a way to deal with long-lived transactions. Long-running transactions face a variation of the partition decision: <em>is it better to hold locks for a long time to ensure consistency, or release them early and expose uncommitted data to other transactions but allow higher concurrency?</em></p><p>Thus, to abort the larger transaction, the system must undo each already committed sub-transaction by issuing a new transaction that corrects for its effects — the compensating transaction.</p><p>侧边栏中还提到了 ATM 的例子：</p><p>The ATM system designer could choose to prohibit withdrawals during a partition, since it is impossible to know the true balance at that time, but that would compromise availability. Instead, using stand-in mode (partition mode), modern ATMs limit the net withdrawal to at most <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span>, where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> might be $200.</p><p>Below this limit, withdrawals work completely; when the balance reaches the limit, the system denies withdrawals.</p><p>In general, because of communication delays, the banking system depends not on consistency for correctness, but rather on auditing and compensation.</p>]]></content>
    
    
    <categories>
      
      <category>Distributed</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PaperNote</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Research: 6.824 Lab2B 中异常情况的分析</title>
    <link href="/2023/11/08/Talks/6.824-lab2b-research/"/>
    <url>/2023/11/08/Talks/6.824-lab2b-research/</url>
    
    <content type="html"><![CDATA[<p>写这篇文章的原因是之前在测试 6.824 Lab2B 时总是会出现几个错误，去提了 <a href="https://github.com/OneSizeFitsQuorum/MIT6.824-2021/issues/35">issue</a> 后也没有得到令人信服的结果，自己有一点头绪但是没验证，这事就这么放着了。</p><p>然后最近有个同样做 6.824 的同学给我发了邮件，说他也遇到了同样的问题，重新分析了一下后，本来想简单回复一下的，结果回复的内容越写越多，就干脆直接整理为一篇文章，供大家参考。</p><h2 id="异常情况">异常情况</h2><p>我之前在对 Lab2B 进行测试时，总是有几个简单的测试点过不了，仿佛代码即使正确，也总是可能出错。我经过分析后发现，都遵循以下这种错误模式：</p><ol><li>Leader 接收了来自上层的请求，还未提交该日志或者只有他提交了日志（该日志已经被 major 收到）时，就因为收到了其他 peer 的 RequestVote RPC 重新变回了 Follower。</li><li>重新选举后再次成为 Leader 后，由于旧任期的 Log 不能被新任期的 Leader 提交，所以之前的日志无法提交。</li><li>没有新的请求进来，导致该日志一致无法提交，然后 2 秒后超时，测试无法通过。</li><li>错误提示都是 <code>one(xxx) failed to reach agreement</code>。</li></ol><h3 id="为什么会出现">为什么会出现</h3><p>在 Lab2B 最开始的几个测试中，测试的编写者为了简化测试，测试代码中提交 command 的操作均为 <code>cfg.one(cmd, servers, false)</code>，这个函数的第三个参数名为 <code>retry</code>，控制的是对于一个请求，是否需要在超时后重新提交。</p><p>这里 <code>retry</code> 被设置为了 false，也就是说整个执行过程中只会调用 <code>rf.Start()</code> 一次，如果遇见了上文说的异常情况，就会被卡住，最后出现超时报错的情况。</p><p>也就是说，<strong>所谓的异常情况就是恰好遇见了一个 timing 加上 Lab2B 前面的几个测试有“缺陷”造成的</strong>。</p><h3 id="no-op-机制">no-op 机制</h3><p>Raft 协议中本身是没有这个问题的，在<a href="https://pdos.csail.mit.edu/6.824/papers/raft-extended.pdf">论文</a>第 13 页中说明了一个节点在当选 Leader 后会发送一个 no-op 的日志，这样新 Leader 就能把 no-op 以及它之前未提交的日志一起提交，就不会卡住了。</p><p>而且就如同我在 issue 里面说的，那些 <code>cfg.one()</code> 中 <code>retry=false</code> 的测试才可能出现这样的问题，原因在 <code>cfg.one()</code> 的注释中也说明了:</p><blockquote><p>if retry==false, calls Start() only once, in order to simplify the early Lab 2B tests.</p></blockquote><p>那么它是怎么简化那些测试的呢，其实是假想了最简单的情况（即不考虑 no-op 机制的情况）：通过比较 <code>cfg.one()</code> 返回的 index 和理想中的 index 做判断，如果两者相等，那么测试就能通过。</p><p>比如我提交了三次 command，那么这三次的 command 对应的 log index 就应该是 1，2，3，三次 <code>cfg.one()</code> 返回的 index 也应该是 1，2，3。实现了 no-op 机制的话，三次 <code>cfg.one()</code> 返回的可能是 1，3，4（index 为 2 的日志是 no-op）。</p><p>所以添加了 no-op 机制的话，会导致 log index 不可控地发生变化，进而导致测试失败。</p><p>这个问题好像无解了，难道真的是测试的编写人员没有考虑到这种 corner case 吗？</p><h2 id="理论分析">理论分析</h2><p>我们可以考虑一下什么情况下会出现我之前描述的那种异常情况呢？</p><p>一个必要条件是出现 Leader 换届。</p><p>那什么情况下会发生 Leader 换届呢？</p><p>只有当某个节点发生 election timeout 之后才会出现。</p><p>这里我们可以考虑分布式系统中的 NPC 问题：</p><ul><li>Network Delay</li><li>Process Pause</li><li>Clock Drift</li></ul><p>由于 Raft 没有对各个服务器之间的时钟有着同步的限制，并且 golang 底层测量时间都用的是单调时钟，正常情况下（特别是在能稳定复现的情况下）Clock Drift 的问题不用考虑。</p><h3 id="Network-Delay">Network Delay</h3><p>测试中都模拟的是 Network Delay 的情况，比如：</p><ul><li>消息会丢失</li><li>消息会延迟到达</li></ul><p>消息会丢失/消息会延迟到达意味着网络是不可靠的，这种情况下可能会发生 Leader 换届，也就有可能发生那种异常情况。</p><p>但是在我提到的那三个测试中（<code>TestBasicAgree2B</code>,<code>TestFollowerFailure2B</code>,<code>TestLeaderFailure2B</code>），网络都是可靠的，因为这些测试的环境配置都是 <code>cfg := make_config(t, servers, false, false)</code>，其中的 <code>unreliable</code> 被设置成了 <code>false</code>。</p><p>我们可以查看一下网络环境的源代码：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-comment">// func (rn *Network) processReq(req reqMsg)</span><br><span class="hljs-keyword">if</span> reliable == <span class="hljs-literal">false</span> &#123;<br>   <span class="hljs-comment">// short delay</span><br>   ms := (rand.Int() % <span class="hljs-number">27</span>)<br>   time.Sleep(time.Duration(ms) * time.Millisecond)<br>  &#125;<br><br><span class="hljs-keyword">if</span> reliable == <span class="hljs-literal">false</span> &amp;&amp; (rand.Int()%<span class="hljs-number">1000</span>) &lt; <span class="hljs-number">100</span> &#123;<br>   <span class="hljs-comment">// drop the request, return as if timeout</span><br>   req.replyCh &lt;- replyMsg&#123;<span class="hljs-literal">false</span>, <span class="hljs-literal">nil</span>&#125;<br>   <span class="hljs-keyword">return</span><br>  &#125;<br></code></pre></td></tr></table></figure><p>这段代码说明，只要网络被配置为了 <code>reliable</code> ，就不会出现消息丢失或者消息延迟到达的情况，说明实验模拟的网络环境是一个理想环境，节点不会因为网络环境而出现 election timeout。</p><p><strong>所以问题不出在 Network Delay 上。</strong></p><h3 id="Process-Pause">Process Pause</h3><p>问题有可能是出在了 Process Pause 上，可能有几种原因：</p><ul><li>GC （垃圾回收）</li><li>负载过重导致线程调度时某些线程迟迟得不到运行（我猜想的，到底会不会出现这种情况没有考证过）</li></ul><p>两种情况都可能会导致异常情况的发生，我们可以假设下面的这个情景：</p><p>一个 Leader 进程由于 GC 被暂停了 1s（负载过重同理），期间无法发送 <code>heartbeat</code>，而 Follower 的进程正常运行，导致在 election timeout 这段时间中没有收到来自 Leader 的 AppendEntries RPC，所以发起新一轮选举，Term 改变，异常情况随之发生。</p><h2 id="实验模拟">实验模拟</h2><p>进行完了理论分析，我们可以动手进行实验来验证一下。</p><p>根据我们在上文中提到的假设：负载过重导致超时，我们可以从负载和超时两方面进行验证：</p><ul><li>如果负载增加的情况，异常情况增多</li><li>或者 election timeout 设置的越短，异常情况越多，</li><li>把 <code>cfg.one()</code> 中的 <code>retry</code> 参数设置为 true，理论上异常情况应该不会发生。</li></ul><p>我们就可以认为该假设是成立的。</p><h3 id="负载增加">负载增加</h3><p>设置六次实验，每次实验跑 Lab2B 中的 <code>TestRPCBytes2B</code> 10000 次：</p><ul><li>并发数为 200</li><li>并发数为 150</li><li>并发数为 100</li><li>并发数为 50</li><li>并发数为 32</li><li>并发数为 16</li></ul><p><strong>并发数为 200</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">dstest -p 200 -n 10000 -o pause_test_200 TestRPCBytes2B<br></code></pre></td></tr></table></figure><table><thead><tr><th>Test</th><th>Failed</th><th>Total</th><th>Time</th></tr></thead><tbody><tr><td>TestRPCBytes2B</td><td>590</td><td>10000</td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>17.76</mn><mo>±</mo><mn>7.28</mn></mrow><annotation encoding="application/x-tex">17.76 \pm 7.28</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">17.76</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">±</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">7.28</span></span></span></span></td></tr></tbody></table><p><strong>并发数为 150</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">dstest -p 150 -n 10000 -o pause_test_150 TestRPCBytes2B<br></code></pre></td></tr></table></figure><table><thead><tr><th>Test</th><th>Failed</th><th>Total</th><th>Time</th></tr></thead><tbody><tr><td>TestRPCBytes2B</td><td>68</td><td>10000</td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8.24</mn><mo>±</mo><mn>1.76</mn></mrow><annotation encoding="application/x-tex">8.24 \pm 1.76</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">8.24</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">±</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1.76</span></span></span></span></td></tr></tbody></table><p><strong>并发数为 125</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">dstest -p 125 -n 10000 -o pause_test_125 TestRPCBytes2B<br></code></pre></td></tr></table></figure><table><thead><tr><th>Test</th><th>Failed</th><th>Total</th><th>Time</th></tr></thead><tbody><tr><td>TestRPCBytes2B</td><td>32</td><td>10000</td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6.61</mn><mo>±</mo><mn>1.16</mn></mrow><annotation encoding="application/x-tex">6.61 \pm 1.16</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">6.61</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">±</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1.16</span></span></span></span></td></tr></tbody></table><p><strong>并发数为 100</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">dstest -p 100 -n 10000 -o pause_test_100 TestRPCBytes2B<br></code></pre></td></tr></table></figure><p><strong>执行情况</strong></p><table><thead><tr><th>Test</th><th>Failed</th><th>Total</th><th>Time</th></tr></thead><tbody><tr><td>TestRPCBytes2B</td><td>9</td><td>10000</td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5.21</mn><mo>±</mo><mn>1.00</mn></mrow><annotation encoding="application/x-tex">5.21 \pm 1.00</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">5.21</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">±</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1.00</span></span></span></span></td></tr></tbody></table><p><strong>并发数为 75</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">dstest -p 75 -n 10000 -o pause_test_75 TestRPCBytes2B<br></code></pre></td></tr></table></figure><table><thead><tr><th>Test</th><th>Failed</th><th>Total</th><th>Time</th></tr></thead><tbody><tr><td>TestRPCBytes2B</td><td>2</td><td>10000</td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3.95</mn><mo>±</mo><mn>0.84</mn></mrow><annotation encoding="application/x-tex">3.95 \pm 0.84</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">3.95</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">±</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.84</span></span></span></span></td></tr></tbody></table><p><strong>并发数为 50</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">dstest -p 50 -n 10000 -o pause_test_50 TestRPCBytes2B<br></code></pre></td></tr></table></figure><table><thead><tr><th>Test</th><th>Failed</th><th>Total</th><th>Time</th></tr></thead><tbody><tr><td>TestRPCBytes2B</td><td>1</td><td>10000</td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2.78</mn><mo>±</mo><mn>0.59</mn></mrow><annotation encoding="application/x-tex">2.78 \pm 0.59</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">2.78</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">±</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.59</span></span></span></span></td></tr></tbody></table><p><strong>并发数为 25</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">dstest -p 25 -n 10000 -o pause_test_25 TestRPCBytes2B<br></code></pre></td></tr></table></figure><table><thead><tr><th>Test</th><th>Failed</th><th>Total</th><th>Time</th></tr></thead><tbody><tr><td>TestRPCBytes2B</td><td>2</td><td>10000</td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.42</mn><mo>±</mo><mn>0.59</mn></mrow><annotation encoding="application/x-tex">1.42 \pm 0.59</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.42</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">±</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.59</span></span></span></span></td></tr></tbody></table><h4 id="Summary">Summary</h4><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231108132222640.png" alt="image-20231108132222640"></p><p>把数据统计为图表后可以看到，负载越高出现异常情况的概率就越大。</p><h3 id="改变-Timeout">改变 Timeout</h3><p>这里统一选取并发数为 150 的情况作为基准。</p><p>Election Timeout:   <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>200</mn><mo>∼</mo><mn>300</mn><mi>m</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">200 \sim 300ms</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">200</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">300</span><span class="mord mathnormal">m</span><span class="mord mathnormal">s</span></span></span></span></p><table><thead><tr><th>Test</th><th>Failed</th><th>Total</th><th>Time</th></tr></thead><tbody><tr><td>TestRPCBytes2B</td><td>172</td><td>10000</td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8.04</mn><mo>±</mo><mn>1.47</mn></mrow><annotation encoding="application/x-tex">8.04 \pm 1.47</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">8.04</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">±</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1.47</span></span></span></span></td></tr></tbody></table><p>Election Timeout:   <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>300</mn><mo>∼</mo><mn>400</mn><mi>m</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">300 \sim 400ms</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">300</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">400</span><span class="mord mathnormal">m</span><span class="mord mathnormal">s</span></span></span></span></p><table><thead><tr><th>Test</th><th>Failed</th><th>Total</th><th>Time</th></tr></thead><tbody><tr><td>TestRPCBytes2B</td><td>68</td><td>10000</td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8.24</mn><mo>±</mo><mn>1.76</mn></mrow><annotation encoding="application/x-tex">8.24 \pm 1.76</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">8.24</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">±</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1.76</span></span></span></span></td></tr></tbody></table><p>Election Timeout: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>400</mn><mo>∼</mo><mn>500</mn><mi>m</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">400 \sim 500ms</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">400</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">500</span><span class="mord mathnormal">m</span><span class="mord mathnormal">s</span></span></span></span></p><table><thead><tr><th>Test</th><th>Failed</th><th>Total</th><th>Time</th></tr></thead><tbody><tr><td>TestRPCBytes2B</td><td>16</td><td>10000</td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10.31</mn><mo>±</mo><mn>2.73</mn></mrow><annotation encoding="application/x-tex">10.31 \pm 2.73</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">10.31</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">±</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2.73</span></span></span></span></td></tr></tbody></table><p>Election Timeout: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>500</mn><mo>∼</mo><mn>600</mn><mi>m</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">500 \sim 600ms</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">500</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">600</span><span class="mord mathnormal">m</span><span class="mord mathnormal">s</span></span></span></span></p><table><thead><tr><th>Test</th><th>Failed</th><th>Total</th><th>Time</th></tr></thead><tbody><tr><td>TestRPCBytes2B</td><td>16</td><td>10000</td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>7.92</mn><mo>±</mo><mn>1.46</mn></mrow><annotation encoding="application/x-tex">7.92 \pm 1.46</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">7.92</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">±</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1.46</span></span></span></span></td></tr></tbody></table><p>Election Timeout: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>600</mn><mo>∼</mo><mn>700</mn><mi>m</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">600 \sim 700ms</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">600</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">700</span><span class="mord mathnormal">m</span><span class="mord mathnormal">s</span></span></span></span></p><table><thead><tr><th>Test</th><th>Failed</th><th>Total</th><th>Time</th></tr></thead><tbody><tr><td>TestRPCBytes2B</td><td>14</td><td>10000</td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>7.87</mn><mo>±</mo><mn>1.40</mn></mrow><annotation encoding="application/x-tex">7.87 \pm 1.40</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">7.87</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">±</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1.40</span></span></span></span></td></tr></tbody></table><p>Election Timeout: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>700</mn><mo>∼</mo><mn>800</mn><mi>m</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">700 \sim 800ms</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">700</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">800</span><span class="mord mathnormal">m</span><span class="mord mathnormal">s</span></span></span></span></p><table><thead><tr><th>Test</th><th>Failed</th><th>Total</th><th>Time</th></tr></thead><tbody><tr><td>TestRPCBytes2B</td><td>12</td><td>10000</td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8.14</mn><mo>±</mo><mn>2.40</mn></mrow><annotation encoding="application/x-tex">8.14 \pm 2.40</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">8.14</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">±</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2.40</span></span></span></span></td></tr></tbody></table><p>Election Timeout: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>800</mn><mo>∼</mo><mn>900</mn><mi>m</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">800 \sim 900ms</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">800</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">900</span><span class="mord mathnormal">m</span><span class="mord mathnormal">s</span></span></span></span></p><table><thead><tr><th>Test</th><th>Failed</th><th>Total</th><th>Time</th></tr></thead><tbody><tr><td>TestRPCBytes2B</td><td>9</td><td>10000</td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8.01</mn><mo>±</mo><mn>2.09</mn></mrow><annotation encoding="application/x-tex">8.01 \pm 2.09</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">8.01</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">±</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2.09</span></span></span></span></td></tr></tbody></table><h5 id="Summary-2">Summary</h5><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231108132352257.png" alt="image-20231108132352257"></p><p>把数据统计为图表后可以看到，election timeout 设置的越长，出现异常情况的概率就越低。</p><h3 id="更改参数">更改参数</h3><p>将 <code>TestRPCBytes2B</code> 中的 <code>cfg.one()</code> 参数改为 true，重新跑一次下面的命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">dstest -p 150 -n 10000 -o pause_test_150_retry TestRPCBytes2B<br></code></pre></td></tr></table></figure><p>得到的结果是：</p><table><thead><tr><th>Test</th><th>Failed</th><th>Total</th><th>Time</th></tr></thead><tbody><tr><td>TestRPCBytes2B</td><td>2</td><td>10000</td><td>8.38 +/- 1.73</td></tr></tbody></table><p>其中的两次失败都是因为重试次数超过 2 次导致 RPC Byte 数量过大。</p><h2 id="实际分析">实际分析</h2><p>我选取了实验模拟中的一次记录，分析了它的日志和 <code>trace</code> 文件</p><h3 id="日志分析">日志分析</h3><p>如果假设成立，那么我们在日志中应该观察到 Leader 并没有按照固定的 <code>HeartbeatInterval</code> 发送心跳检测。</p><p>以下是日志截取：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs bash">...<br>0103294 TIMR S1 Leader, checking heartbeats <span class="hljs-keyword">in</span> T1<br>...<br>0107883 TIMR S1 Leader, checking heartbeats <span class="hljs-keyword">in</span> T1<br>...<br>0112964 TIMR S1 Leader, checking heartbeats <span class="hljs-keyword">in</span> T1<br>...<br>0129159 TIMR S1 Leader, checking heartbeats <span class="hljs-keyword">in</span> T1<br>...<br>0132759 CLNT S1 accepted Client<span class="hljs-string">&#x27;s request Lqog</span><br><span class="hljs-string">0132783 TIMR S1 Leader, checking heartbeats in T1</span><br><span class="hljs-string">0132783 LOG1 S1 -&gt; S0 Sending (with heartbeat) in T1 &#123;T:1 preLogIdx:9 preLogT:1 len:1 lCommit:9&#125;</span><br><span class="hljs-string">0132784 LOG1 S1 -&gt; S2 Sending (with heartbeat) in T1 &#123;T:1 preLogIdx:9 preLogT:1 len:1 lCommit:9&#125;</span><br><span class="hljs-string">0199527 LEAD S2 timeout, starts a new election for T2</span><br><span class="hljs-string">0199569 LEAD S0 timeout, starts a new election for T2</span><br><span class="hljs-string">0199707 TIMR S1 Leader, checking heartbeats in T1</span><br><span class="hljs-string">0199709 LOG1 S1 -&gt; S0 Sending (with heartbeat) in T1 &#123;T:1 preLogIdx:9 preLogT:1 len:1 lCommit:9&#125;</span><br><span class="hljs-string">0199710 LOG1 S1 -&gt; S2 Sending (with heartbeat) in T1 &#123;T:1 preLogIdx:9 preLogT:1 len:1 lCommit:9&#125;</span><br><span class="hljs-string">0199713 VOTE S1 stepping down from leader in T2</span><br><span class="hljs-string">0199714 VOTE S1 votes for S2 in T2</span><br><span class="hljs-string">0199714 PERS S1 persisting state in T2: &#123;T:2 VF:2 LogLength:11&#125;, rf.getFirstLogIndex:0</span><br><span class="hljs-string">0212364 VOTE S2 received vote from S1 (for T2) in T2</span><br><span class="hljs-string">0212366 LEAD S2 achieved Majority for T2 (2), converting to leader</span><br><span class="hljs-string">0212368 LEAD S2 heartbeat reset triggered manually</span><br><span class="hljs-string">...</span><br><span class="hljs-string">// repeat pattern</span><br><span class="hljs-string">0212369 TIMR S2 Leader, checking heartbeats in T2</span><br><span class="hljs-string">0212370 LOG1 S2 -&gt; S0 Sending heartbeat in T2 &#123;T:2 preLogIdx:10 preLogT:1 len:0 lCommit:9&#125;</span><br><span class="hljs-string">0212371 LOG1 S2 -&gt; S1 Sending heartbeat in T2 &#123;T:2 preLogIdx:10 preLogT:1 len:0 lCommit:9&#125;</span><br><span class="hljs-string">...</span><br></code></pre></td></tr></table></figure><p>分析一下这段日志：</p><ul><li>一开始 S1 确实在按照 50ms 的间隔发送心跳检测:<ul><li><code>0103294 TIMR S1 Leader, checking heartbeats in T1</code></li><li><code>0107883 TIMR S1 Leader, checking heartbeats in T1</code></li><li><code>0112964 TIMR S1 Leader, checking heartbeats in T1</code></li></ul></li><li>S1 收到了来自上层的请求：<ul><li><code>0132759 CLNT S1 accepted Client's request Lqog</code></li></ul></li><li>时隔 <strong>670ms</strong>，S1 才发送了下一轮的心跳检测:<ul><li><code>0132783 TIMR S1 Leader, checking heartbeats in T1</code></li><li><code>0199707 TIMR S1 Leader, checking heartbeats in T1</code></li></ul></li><li>在这 670ms 中，S0 和 S2 由于没有收到来自于 Leader S1 的心跳检测超时了并开始了下一轮选举：<ul><li><code>0199527 LEAD S2 timeout, starts a new election for T2</code></li><li><code>0199569 LEAD S0 timeout, starts a new election for T2</code></li></ul></li><li>S2 被选举为新的 Leader，开始发送心跳检测</li><li>由于旧任期的 Log 不能被新任期的 Leader 提交，所以 <code>Lqog</code> 无法被提交，卡住了</li></ul><p>时隔 670ms 后 S1 才发送了下一轮的心跳检测，可以推断这段时间内发生了 GC 或者在 670ms 内这个进程都未得到调度并执行，符合我们的推断。</p><p>但到底是什么原因呢？</p><p>我们可以记录并查看 trace 文件来寻找：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// func TestRPCBytes2B(t *testing.T)</span><br>traceName := <span class="hljs-string">&quot;trace-&quot;</span> + randstring(<span class="hljs-number">5</span>)<br>traceFile, _ := os.Create(traceName)<br><span class="hljs-keyword">defer</span> traceFile.Close()<br>t.Logf(<span class="hljs-string">&quot;trace file: %s&quot;</span>, traceName)<br>trace.Start(traceFile)<br><span class="hljs-keyword">defer</span> trace.Stop()<br><br><span class="hljs-comment">// using go tool</span><br><span class="hljs-keyword">go</span> tool trace trace-xxx<br></code></pre></td></tr></table></figure><h3 id="Trace-文件分析">Trace 文件分析</h3><p>打开上述日志对应的 trace 文件后，我们可以查看所有 goroutine 的执行情况和垃圾回收的情况。</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231108125355851.png" alt="image-20231108125355851"></p><p>查看之后可以发现，确实是发生了长达 620ms 的垃圾回收！</p><p>在 <em>stop-the-wold(STW)</em> 期间，所有的线程都会被暂停执行，等待垃圾回收完成。</p><blockquote><p>为什么会有长达 620ms 的垃圾回收呢？</p><p>个人推测与 CPU 负载过高有关。</p></blockquote><h2 id="结论">结论</h2><p>异常情况是由 GC 引起的，GC 导致 Leader 不能以正常频率发送心跳检测，导致 Follower 重新开始选举。</p><p>测试的编写人员假设了网络环境是理想的，却猜不到有同学在本地跑的时候负载过大发生长时间GC而导致测试失败的情况。</p>]]></content>
    
    
    <categories>
      
      <category>6.824</category>
      
    </categories>
    
    
    <tags>
      
      <tag>6.824</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Talk about Consistency and Consensus</title>
    <link href="/2023/11/07/Talks/talk-about-consistency-and-consensus/"/>
    <url>/2023/11/07/Talks/talk-about-consistency-and-consensus/</url>
    
    <content type="html"><![CDATA[<h2 id="ACID-中的一致性">ACID 中的一致性</h2><p>我们现在关注的是其中的 C，即一致性 <em>Consistency</em>。它是什么意思呢？通俗地说，它指的是任何一个数据库事务的执行，都应该让整个数据库保持在「一致」的状态：</p><ul><li>ACID 中的「一致性」，是对于整个数据库的「一致」状态的维持。抽象来看，对数据库每进行一次事务操作，它的状态就发生一次变化。这相当于把数据库看成了状态机，只要数据库的起始状态是「一致」的，并且每次事务操作都能保持「一致性」，那么数据库就能始终保持在「一致」的状态上 (Consistency Preservation)。</li><li>所谓状态是不是「一致」，其实是由业务层规定的。比如转账的例子，“转账前后账户总额保持不变”，这个规定只对于「转账」这个特定的业务场景有效。如果换一个业务场景，「一致」的概念就不是这样规定了。所以说，ACID 中的「一致性」，其实是体现了业务逻辑上的合理性，并不是由数据库本身的技术特性所决定的。</li></ul><p>为了让事务总是能保持 ACID 的一致性，我们需要在实现上考虑哪些因素呢？</p><ul><li>出错情况 (failure/error)<ul><li>事务本身的实现逻辑可能存在错误，这需要应用层进行恰当的编码来保证。</li><li>需要 ACID 中的 A（原子性）来保障。简言之，原子性保障了事务的执行要么全部成功，要么全部失败，而不允许出现“只执行了一半”这种“部分成功”的情况。</li></ul></li><li>并发行为<ul><li>需要 ACID 中的 I（隔离性）来保障了。什么是隔离性呢？它对于并发执行的多个事务进行合理的排序，保障了不同事务的执行互不干扰。换言之，隔离性这种特性，能够让并发执行的多个事务就好像是按照「先后顺序」执行的一样。</li></ul></li></ul><h3 id="Summary">Summary</h3><ul><li>ACID 中的一致性，是个很偏应用层的概念。这跟 ACID 中的原子性、隔离性和持久性有很大的不同。原子性、隔离性和持久性，都是数据库本身所提供的技术特性；而一致性，则是由特定的业务场景规定的。</li><li>要真正做到 ACID 中的一致性，它是要依赖数据库的原子性和隔离性的（应对错误和并发）。</li><li>最后，ACID 中的一致性，甚至跟分布式都没什么直接关系。它跟分布式的唯一关联在于，在分布式环境下，它所依赖的数据库原子性和隔离性更难实现。</li></ul><p><strong>总之，ACID中的一致性，是一个非常特殊的概念。除了数据库事务处理，它很难扩展到其它场景，也跟分布式理论中的其它「一致性」概念没有什么关系。</strong></p><h2 id="分布式事务与共识算法的关系">分布式事务与共识算法的关系</h2><p>共识问题 (consensus problem)。这是分布式系统中的一个十分基础而核心的问题，它表示如何在分布式系统中的多个节点之间就某事达成共识。</p><p>网上通常提到的「分布式一致性协议」，或者「分布式一致性算法」，一般来说就是解决这里的共识问题的算法。</p><blockquote><p>这些算法或协议，经常包含 Paxos 之类，但也可能包括两阶段提交协议 (2 PC)或三阶段提交协议 (3 PC)。</p></blockquote><p>ACID 中的原子性，要求事务的执行要么全部成功，要么全部失败，而不允许出现“部分成功”的情况。在分布式事务中，这要求参与事务的所有节点，要么全部执行 Commit 操作，要么全部执行 Abort 操作。换句话说，参与事务的所有节点，需要在“执行 Commit 还是 Abort”这一点上达成一致（其实就是共识）。这个问题在学术界被称为<strong>原子提交问题</strong>（<em>Atomic Commitment Problem</em>），而能够解决原子提交问题的算法，则被称为<strong>原子提交协议</strong>（<em>Atomic Commitment Protocal</em>，简称<strong>ACP</strong>）。2PC 和3PC，属于原子提交协议两种不同的具体实现。</p><p>我们可以发现原子提交问题和共识问题的关联：</p><ul><li>共识问题，解决的是如何在分布式系统中的多个节点之间就某个提议达成共识。</li><li>原子提交问题，解决的是参与分布式事务的所有节点在“执行 Commit 还是 Abort”这一点上达成共识。</li><li>所以，原子提交问题是共识问题的一个特例。（？）</li></ul><p>一些细节的不同，可能导致非常大的差异。当我们描述共识问题的时候，我们说的是在<strong>多个节点</strong>之间达成共识；而当我们描述原子提交问题的时候，我们说的是在<strong>所有节点</strong>之间达成共识。这个细微的差别，让这两类问题，几乎变成了完全不同的问题（谁也替代不了谁）：</p><ul><li>Paxos 协议为例，它只要求网络中的大部分节点达成共识就可以了，这样 Paxos 才能提供一定的容错性，只要网络中发生故障的节点不超过一半仍然能够正常工作（不会被阻塞）</li><li>对于解决原子提交问题的 2PC 或者 3PC 来说，即使只有一个节点发生故障了，其它节点也不能擅自决策进行 Commit 操作。所以，原子提交协议必须保证在参与分布式事务的<strong>所有节点</strong>（包括故障的节点）上对于“执行 Commit 还是 Abort”达成共识。</li></ul><p>原子提交问题可以被抽象成一个新的一致性问题，称为 uniform consensus 问题，它是与通常的共识问题（consensus problem）不同的问题，而且是更难的问题。uniform consensus，要求所有节点（包括故障节点）都要达成共识；而 consensus 问题只关注没有发生故障的节点达成共识。</p><h3 id="Summary-2">Summary</h3><ul><li>共识问题（consensus problem），解决的是如何在分布式系统中的多个节点之间就某个提议达成共识。它只关注没有发生故障的节点达成共识就可以了。</li><li>在分布式事务中，ACID 中的原子性，引出了原子提交问题，它解决的是参与分布式事务的所有节点在“执行 Commit 还是 Abort”这一点上达成共识。原子提交问题属于 uniform consensus 问题，要求所有节点（包括故障节点）都要达成共识，是比 consensus 问题更难的一类问题。</li><li>Paxos 和解决拜占庭将军问题的算法，解决的是 consensus 问题；2PC/3PC，解决的是一个特定的 uniform consensus 问题。</li></ul><h2 id="CAP-与线性一致性">CAP 与线性一致性</h2><p>CAP 的三个字母分别代表了分布式系统的三个特性：一致性（Consistency）、可用性（Availability）和分区容错性（Partition-tolerance）。而 CAP 定理指出：任何一个分布式系统只能同时满足三个特性中的两个。但是，这一描述曾经引发了非常多的误解。</p><p>CAP 中的 C，也就是一致性，它是什么意思呢？在证明 CAP 定理的原始论文中，C 指的是 <em>linearizable consistency</em>，也就是「线性一致性」。更精简的英文表达则是 <em>linearizability</em>。</p><blockquote><p><strong>线性一致性</strong>（<em>linearizability</em>）是 CAP 中的 C 的原始定义。而很多人在谈到 CAP 时，则会把这个 C 看成是<strong>强一致性</strong>（<em>strong consistency</em>）。这其实也没错，因为线性一致性的另一个名字，就是强一致性。</p></blockquote><p>所以线性一致性是什么意思呢？</p><p>大体上是说，在一个并发执行的环境中，不同的操作之间可能是有严格的先后关系的（一个操作执行结束之后另一个操作才开始执行），也可能是并发执行的（一个操作还没执行结束，另一个操作就开始执行了）；如果能够把所有操作排列成一个「合法」的全局线性顺序，那么这些操作就是满足线性一致性的。当然，在这个重新排列的过程中，原来就存在的严格的先后关系，必须得以保持。</p><p>对于一个分布式存储系统来说，线性一致性的含义可以用一个具体的描述来取代：对于任何一个数据对象来说，<strong>系统表现得就像它只有一个副本一样</strong>。</p><h2 id="一致性模型的来历">一致性模型的来历</h2><p>我们之所以使用分布式系统，无非是因为分布式系统能带来一些「好处」，比如容错性、可扩展性等等。为了获得这些「好处」，分布式系统实现上常用的方法是复制 (<em>replication</em>) 和分片 (<em>sharding</em>)。而我们将要讨论的一致性模型 (<em>consistency model</em>)，主要是与复制有关。</p><p>复制带来的具体「好处」主要是体现在两个方面：</p><ul><li>容错 (<em>fault tolerance</em>)。即使某些网络节点发生故障，由于原本保存着在故障节点上的数据在正常节点上还有备份，所以整个系统仍然可能是可用的。这也是我们期待分布式系统能够提供的「高可用」特性。</li><li>提升吞吐量。将一份数据复制多份并保存在多个副本节点上，还顺便带来一个好处：对于同一个数据对象的访问请求（至少是读请求）可以由多个副本节点分担，从而使得整个系统可以随着请求量的增加不断扩展。</li></ul><p>而复制带来的最大的挑战就是数据一致性问题。严格意义上来说，让所有副本在任何时刻都保持一致是不可能的，因为副本之间的数据同步是需要时间的。但是只要系统能够保证，每当我们去「观察」的时候（即读取数据副本的时候），系统表现出来的行为是一致的，就可以了。</p><p>所以我们应该从系统用户（使用系统的开发者）的角度来对数据一致性的要求进行定义。</p><p>讨论一个例子：用户 A 先在第1个副本上执行 x=42，然后用户 B 再在第2个副本上执行 x=43，最后用户 C 在第3个副本上读取_x_的值。仍然为了让系统“表现得像只有一个副本”，直觉上看，用户 C 读取到的_x_的值似乎应该是43。但是，也不一定非要如此。因为两个写操作是分别由用户 A 和用户 B 发起的，他们并不知道彼此谁先谁后（虽然从时间上看用户 A 的写操作确实在先）。所以，我们也可以选择认为用户 B 执行 x=43在用户 A 执行 x=42之前。这样的话，用户 C 读取到的 x 的值就应该是42。（这种排序<strong>满足顺序一致性，但不满足线性一致性</strong>。）</p><p>一个系统在数据一致性上的具体表现如何，取决于系统对关键事件（读写操作）的排序和执行采取什么样的规则和限制。比如在上述的例子中，虽然两种排序结果不同，但它们都做到了让系统“表现得像只有一个副本”。它们的不同在于，前一种排序遵循了不同用户的操作的时间先后顺序，而后一种排序没有。</p><p>一个分布式系统对于读写操作的某种排序和执行规则，就定义了一种一致性模型 (<em>consistency model</em>)。当一个系统选定了某种特定的一致性模型（比如线性一致性或顺序一致性），那么你就只能看到这种一致性模型所允许的那些操作序列。</p><h2 id="顺序一致性和线性一致性">顺序一致性和线性一致性</h2><ul><li>顺序一致性：<em>sequential consistency</em></li><li>线性一致性：<em>linearizability</em></li></ul><h3 id="顺序一致性">顺序一致性</h3><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/640.png" alt="Example 1"></p><ul><li><em>A</em> --&gt; w_i(<em>x</em>)，表示一个写操作：第 i 个进程向数据对象 x 写入了值 A。</li><li>r_i(<em>x</em>) --&gt; <em>A</em>，表示一个读操作：第 i 个进程从数据对象 x 中读到了值 A。</li></ul><p>上图的这样一个执行过程，是否满足顺序一致性？</p><p><strong>顺序一致性</strong>定义：如果一个并发执行过程所包含的所有读写操作能够重排成一个全局线性有序的序列，并且这个序列满足以下两个条件，那么这个并发执行过程就是满足顺序一致性的：</p><ul><li><strong>条件I</strong>：重排后的序列中每一个读操作返回的值，必须等于前面对同一个数据对象的最近一次写操作所写入的值。</li><li><strong>条件 II</strong>：原来每个进程中各个操作的执行先后顺序，在这个重排后的序列中必须保持一致。</li></ul><p>简单重排一下：</p><ol><li>写 A</li><li>读 A</li><li>写 C</li><li>读 C</li><li>写 B</li><li>读 B</li></ol><p>这个序列是满足顺序一致性的两个条件的，所以上图的执行过程是满足顺序一致性的。</p><p>为什么顺序一致性会这样定义呢？</p><p>首先，重排成一个全局线性有序的序列，相当于系统对外表现出了一种「假象」，原本多进程并发执行的操作，好像是顺序执行的一样。顺序一致性正是遵循了这种「系统假象」，系统对外表现就好像在操作一个单一的副本，执行顺序也必然是可以看做顺序执行的：</p><ul><li>条件 I 规定了系统的表现是合理的（即合乎逻辑的）；</li><li>条件 II 则保证了以任何进程的视角来看，它所发起的操作执行顺序都是符合它原本的预期的。</li></ul><p>总之，一个满足顺序一致性的系统，对外表现就好像总是在操作一个副本一样。</p><p>下图是一个不满足顺序一致性的例子：</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/640-20231106201453194.png" alt="Example 2"></p><h3 id="线性一致性">线性一致性</h3><p>线性一致性的定义，与顺序一致性非常相似，也是试图把所有读写操作重排成一个全局线性有序的序列，但除了满足前面的条件 I 和条件 II 之外，还要同时满足一个条件：</p><ul><li><strong>条件 III</strong>：不同进程的操作，如果在时间上不重叠，那么它们的执行先后顺序，在这个重排后的序列中必须保持一致。</li></ul><p>所以下图这个例子是不满足线性一致性的：</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/640.png" alt="Example 1"></p><blockquote><p>C 已经成功写入了，P_3 的第一次读是不会读到 A 的。</p></blockquote><p>下图是满足线性一致性的：</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/640-20231106201807555.png" alt="Example 3"></p><p>重排后一个有效的序列是：</p><ol><li>写 A</li><li>读 A</li><li>写 C</li><li>读 C</li><li>写 B</li><li>读 B</li></ol><p>现在我们可以仔细分析一下条件 II 和条件 III，它们囊括了任意两个操作之间所有可能的先后关系：</p><ul><li>进程内的任意两个操作之间，总是先后顺序执行的（执行时间上不可能重叠）；而根据条件II，它们的先后顺序在最后重排后的序列中也会保持。</li><li>不同进程的不同操作之间，在执行时间上可能重叠（并发执行），也可能不重叠。根据条件 III，不重叠的两个操作，它们在时间上的先后顺序，在最后重排后的序列中会得以保持。而对于执行时间上重叠的两个操作，它们在最后重排后的序列中的先后顺序没有规定。</li></ul><h3 id="Summary-3">Summary</h3><ul><li>线性一致性隐含了时效性保证（<em>recency guarantee</em>）。它保证我们总是能读到数据最新的值。</li><li>在顺序一致性中，我们有可能读到旧版本的数据。</li></ul><h2 id="最终一致性">最终一致性</h2><p>系统维持强一致性是有成本的。想要维持越强的一致性，就需要在副本节点之间做更多的通信和协调工作，因此会降低操作的总延迟，进而降低整个系统的性能。</p><p>从20世纪90年代中期开始，互联网开始蓬勃发展，系统的规模也变得越来越大。人们设计大型分布式系统的指导思想，也逐步开始更倾向于系统的高可用性和高性能。取舍的结果就是，降低系统提供的一致性保障。这其中非常重要的一条思路就是最终一致性。</p><p>最终一致性的定义如下：</p><blockquote><p>Eventual consistency. This is a specific form of weak consistency; the storage system guarantees that if no new updates are made to the object, eventually all accesses will return the last updated value.<br>最终一致性是弱一致性的一种特殊形式；存储系统保证，如果对象没有新的修改操作，那么所有的访问最终都会返回最新写入的值。</p></blockquote><p>虽然最终一致性和本文前面讨论的线性一致性或顺序一致性在命名上非常相似，但它的定义却与后两者存在非常大的差别。深层的原因在于，它们其实属于不同类别的系统属性 (<em>property</em>)。</p><ul><li>线性一致性和顺序一致性属于 <em>safety property</em>（安全性）；</li><li>最终一致性属于 <em>liveness property</em>（活性）</li></ul><blockquote><p>实际上，最终一致性有点名不副实，它更好的名字可能是收敛性 (<em>convergence</em>)，表示所有副本最终都会收敛到相同的值。</p></blockquote><h2 id="一致性的强弱关系">一致性的强弱关系</h2><p>一致性模型的强弱关系，其实是有更严格的定义的：</p><ul><li>当且仅当一个一致性模型所能接受的执行过程，都能被另一个一致性模型所接受时（前者的集合是后者集合的子集），我们就说前者是比后者「更强」(<em>stronger</em>) 的一致性模型。</li></ul><p>仔细分析一下也能知道，一致性模型的强弱关系定义，是基于 safety 属性定义的。所以，将线性一致性或顺序一致性与最终一致性比较强弱，这并不是一个严格的做法。实际上，就像我们前一小节所讨论的，最终一致性在 safety 方面提供的保证为零，它是属于 liveness 的概念。一个系统可以在提供最终一致性的同时，也提供另外一种更强一点的带有 safety 属性的一致性（比如因果一致性）。</p>]]></content>
    
    
    <categories>
      
      <category>Distributed</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Talk</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Paper Note: Chain Replication</title>
    <link href="/2023/11/06/Papers/chain-replication/"/>
    <url>/2023/11/06/Papers/chain-replication/</url>
    
    <content type="html"><![CDATA[<h2 id="FAQ">FAQ</h2><p><em>Is chain replication used in practice over other things like Raft or Paxos?</em></p><p>Systems often use both.</p><p>A common way of building distributed systems is to use a configuration server (called the master in the paper) for maintaining configuration info (e.g., who is primary) and a replication system for replicating data.</p><p>Paxos/Raft are commonly-used to build the configuration server while the replication system often uses primary-backup or chain replication.</p><p>The reason to use Raft/Paxos for configuration server is <strong>it must handle split-brain syndrome</strong>.</p><p>The reason to use primary/backup for data replication is that it is simpler than Raft/Paxos and Raft, for example, is not good at for replicating large amounts of data. <strong>The replication system can rely on the configuration server to avoid split-brain syndrome.</strong></p><p><em>What are the tradeoffs of Chain Replication vs Raft or Paxos?</em></p><p>Both CR and Raft/Paxos are replicated state machines. They can be used to replicate any service that can fit into a state machine mold (basically, processes a stream of requests one at a time).</p><p>CR is likely to be faster than Raft because the CR head does less work than the Raft leader: the CR head sends writes to just one replica, while the Raft leader must send all operations to all followers. CR has a performance advantage for reads as well, since it serves them from the tail (not the head), while the Raft leader must serve all client requests.</p><p>However, Raft/Paxos and CR differ significantly in their failure properties:</p><ul><li><em>Fault Tolerant</em><ul><li>If there are N replicas, a CR system can recover if even a single replica survives.</li><li>Raft and Paxos require a majority of the N replicas to be available in order to operate.</li></ul></li><li><em>Handle Faults</em><ul><li>A CR chain has to pause updates if there’s even a single failure, and must wait for the configuration server to notice and reconfigure the chain.</li><li>Raft/Paxos, in contrast, can continue operating without interruption as long as a majority is available.</li></ul></li></ul><p><em>This scheme would be bad if we care about latency right?</em></p><p>Yes and No.</p><ul><li>Yes, the latency of update operations is proportional to the length of the chain.</li><li>No, the latency of read operation is low: only the tail is involved.</li></ul><h2 id="Analyze">Analyze</h2><h3 id="Key-Features">Key Features</h3><ul><li>The approach is intended for supporting large-scale storage services that exhibit high throughput and availability without sacrificing strong consistency guarantees.</li><li>Chain replication supports high throughput for query and update requests, high availability of data objects, and strong consistency guarantees.</li></ul><h3 id="Basic-Structures">Basic Structures</h3><h4 id="System-View">System View</h4><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231106205642569.png" alt="image-20231106205642569"></p><p>可以说这篇论文中最重要的一张图就是这个了，这张图至少说明了三个特性：</p><ul><li>所有的 query 都只经过 tail。</li><li>所有的 reply 都由 tail 产生。</li><li>所有的 update 请求都需要从 head 开始处理，经过一条链最终到达 tail。</li></ul><p>这个结构也说明了为什么链式复制拥有这高性能这一特性：</p><ul><li>相比于平常的 Primary/Backup 的复制机制，链式复制将 master 的负载分担到了 head 和 tail 两台服务器的身上，所以能更快。</li></ul><h4 id="Protocol-View">Protocol View</h4><p>链式复制需要建立在 Fail-stop 的基础上：</p><ul><li>Each server halts in response to a failure rather than making erroneous state transitions. (很明显的 CP 系统)</li><li>A server’s halted state can be detected by the environment.</li></ul><p>简单的运行逻辑已经在 System View 中说明了，有一点需要提出来说的是，这个系统是如何保证强一致性的呢？</p><p>Strong consistency thus follows because <strong>query requests and update requests are all processed serially at a single server</strong> (the tail).</p><h3 id="Fault-Tolerance">Fault Tolerance</h3><p>作者假设了一个永不失败的 master，拥有以下职责：</p><ul><li>Detects failures of servers.</li><li>Informs each server in the chain of its new predecessor or new successor in the new chain obtained by deleting the failed server.</li><li>Informs clients which server is the head and which is the tail of the chain.</li></ul><blockquote><p>可以把这个 master 想成一个 Paxos/Raft 构成的集群。</p></blockquote><p>master 能够检测三种类型的异常：</p><ul><li>头结点异常</li><li>尾节点异常</li><li>中间节点异常</li></ul><p>作者提到了一个更新传播不等式（Update Propagation Invariant）: 对于满足 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>≤</mo><mi>j</mi></mrow><annotation encoding="application/x-tex">i \le j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7955em;vertical-align:-0.136em;"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span>  的节点 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span> (即 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 在链中是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span> 的前继节点)，有</p><p class="katex-block "><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>H</mi><mi>i</mi><mi>s</mi><msubsup><mi>t</mi><mrow><mi>o</mi><mi>b</mi><mi>j</mi><mi>I</mi><mi>D</mi></mrow><mi>j</mi></msubsup><mo>⪯</mo><mi>H</mi><mi>i</mi><mi>s</mi><msubsup><mi>t</mi><mrow><mi>o</mi><mi>b</mi><mi>j</mi><mi>I</mi><mi>D</mi></mrow><mi>i</mi></msubsup></mrow><annotation encoding="application/x-tex">Hist^j_{objID} \preceq Hist^i_{objID}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.38em;vertical-align:-0.4374em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal">i</span><span class="mord mathnormal">s</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9426em;"><span style="top:-2.3987em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">bj</span><span class="mord mathnormal mtight" style="margin-right:0.07847em;">I</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span></span></span></span><span style="top:-3.1809em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4374em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">⪯</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2578em;vertical-align:-0.3831em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal">i</span><span class="mord mathnormal">s</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8747em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">bj</span><span class="mord mathnormal mtight" style="margin-right:0.07847em;">I</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3831em;"><span></span></span></span></span></span></span></span></span></span></span></p><blockquote><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mi>i</mi><mi>s</mi><msubsup><mi>t</mi><mrow><mi>o</mi><mi>b</mi><mi>j</mi><mi>I</mi><mi>D</mi></mrow><mi>i</mi></msubsup></mrow><annotation encoding="application/x-tex">Hist^i_{objID}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2439em;vertical-align:-0.4192em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal">i</span><span class="mord mathnormal">s</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8247em;"><span style="top:-2.4169em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">bj</span><span class="mord mathnormal mtight" style="margin-right:0.07847em;">I</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192em;"><span></span></span></span></span></span></span></span></span></span> 代表的是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 通过的 update 请求序列。<br>这个不等式在原文中给我看迷糊了，其实很简单，就是说 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span> 的请求序列是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 的一个前缀。（即每个节点收到的更新序列是前一个节点收到的更新序列的前缀。）</p></blockquote><p>如果该更新传播不等式在系统中成立，那么就能说明 head 处理的更新序列和 tail 处理的更新序列顺序上是一致的，也就能保证整个系统维持了线性一致性。</p><h4 id="Failure-of-the-Head">Failure of the Head</h4><p>This case is handled by the master removing H from the chain and making the successor to H the new head of the chain.</p><p>删除 head 会导致 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mi>e</mi><mi>n</mi><mi>d</mi><mi>i</mi><mi>n</mi><msub><mi>g</mi><mrow><mi>o</mi><mi>b</mi><mi>j</mi><mi>I</mi><mi>D</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Pending_{objID}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">d</span><span class="mord mathnormal">in</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">bj</span><span class="mord mathnormal mtight" style="margin-right:0.07847em;">I</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 发生变化（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mi>e</mi><mi>n</mi><mi>d</mi><mi>i</mi><mi>n</mi><msub><mi>g</mi><mrow><mi>o</mi><mi>b</mi><mi>j</mi><mi>I</mi><mi>D</mi></mrow></msub></mrow><annotation encoding="application/x-tex">Pending_{objID}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">d</span><span class="mord mathnormal">in</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">bj</span><span class="mord mathnormal mtight" style="margin-right:0.07847em;">I</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 指的是被服务器接收但是还没有被 tail 处理的更新请求序列）。从 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>e</mi><mi>n</mi><mi>d</mi><mi>i</mi><mi>n</mi><msub><mi>g</mi><mrow><mi>o</mi><mi>b</mi><mi>j</mi><mi>I</mi><mi>D</mi></mrow></msub></mrow><annotation encoding="application/x-tex">pending_{objID}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">d</span><span class="mord mathnormal">in</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">bj</span><span class="mord mathnormal mtight" style="margin-right:0.07847em;">I</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 中移除一个请求和 Figure 1 中的 T2 是一致的，所以删除 head 与 Figure 1 中的说明是一致的。</p><h4 id="Failure-of-the-Tail">Failure of the Tail</h4><p>This case is handled by removing tail T from the chain and making predecessor T− of T the new tail of the chain.</p><p>这种操作和 Figure 1 中的 T3 是一致的。</p><h4 id="Failure-of-Other-Servers">Failure of Other Servers</h4><p>Failure of a server S internal to the chain is handled by deleting S from the chain. The master first informs S’s successor S+ of the new chain configuration and then informs S’s predecessor S−.</p><p>需要注意的是，这种情况有可能会违反之前提到的更新传播不等式，进而破坏系统的线性一致性。</p><p>这里就细说一下什么情况下会破坏该一致性：</p><p>假设有 H --&gt; S1 --&gt; S2 --&gt; S3 --&gt; T，最重要的是要理解：如果 S2 挂了，S1 是不知道 S2 和 S3 之间的发送情况的，假设 S1 给 S2 发了 5 条请求，而 S2 给 S3 发了 3 条请求，如果没有一个记录来维护发送情况，S1 就会直接给 S3 发送新的第 6 条请求，最终导致：</p><ul><li>S1 :[1,2,3,4,5,6]</li><li>S2 :[1,2,3,6]</li><li>S2 不再是 S1 的一个前缀。</li></ul><p>为了解决这个问题，作者提出了在每个节点再维护一个序列 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>e</mi><mi>n</mi><msub><mi>t</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">Sent_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>e</mi><mi>n</mi><msub><mi>d</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">Send_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 中存储的是那些 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 向后继节点转发了但是还没有被 tail 处理的更新请求序列，这个序列的变化规则就很明显了：</p><ul><li>每次 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 向后继节点转发一个请求，就在 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>e</mi><mi>n</mi><msub><mi>t</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">Sent_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 中添加一个该请求。</li><li>tail 每处理一个请求，就会往前继节点发送一个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mi>c</mi><mi>k</mi><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">ack(r)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal">c</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mclose">)</span></span></span></span>，前继节点收到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mi>c</mi><mi>k</mi><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">ack(r)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal">c</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mclose">)</span></span></span></span> 后，就在 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>e</mi><mi>n</mi><msub><mi>t</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">Sent_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 中删除一个该请求。</li></ul><p>举个对应前面例子：</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/IMG_6DF4ECB59405-1.jpeg" alt="IMG_6DF4ECB59405-1"></p><p>所以可以总结一个规律：对于满足 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>≤</mo><mi>j</mi></mrow><annotation encoding="application/x-tex">i \le j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7955em;vertical-align:-0.136em;"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span>  的节点 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span>，有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 的更新序列等于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span> 的更新序列和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>e</mi><mi>n</mi><msub><mi>t</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">Sent_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的补集，在论文中体现为 <em>Inprocess Request Invariant</em>。</p><p>这个不等式就为如何维护更新传播不等式提供了指导性意见：</p><ul><li>S- 收到了 S+ 是它的新后继节点这一信息后，首先把 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>e</mi><mi>n</mi><msub><mi>t</mi><msup><mi>S</mi><mo>−</mo></msup></msub></mrow><annotation encoding="application/x-tex">Sent_{S^-}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3419em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7027em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mbin mtight">−</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 中的请求序列转发给 S+。</li></ul><p>所以整个更新流程可以如下图（具体的其他细节在这里就省略了）：</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231106221608835.png" alt="image-20231106221608835"></p><ol><li>Message 1 informs S+ of its new role;</li><li>Message 2 acknowledges and informs the master what is the sequence number <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>n</mi></mrow><annotation encoding="application/x-tex">sn</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">n</span></span></span></span> of the last update request S+ has received;</li><li>Message 3 informs S− of its new role and of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>n</mi></mrow><annotation encoding="application/x-tex">sn</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">n</span></span></span></span> so S− can compute the suffix of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>e</mi><mi>n</mi><msub><mi>t</mi><msup><mi>S</mi><mo>−</mo></msup></msub></mrow><annotation encoding="application/x-tex">Sent_{S^-}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3419em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7027em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mbin mtight">−</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> to send to S+;</li><li>Message 4 carries that suffix.</li></ol><h4 id="Extend-a-Chain">Extend a Chain</h4><p>新增的节点 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>T</mi><mo>+</mo></msup></mrow><annotation encoding="application/x-tex">T^+</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7713em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7713em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span></span></span></span> 增加在链尾，在同步完成前先不提供查询服务，将 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mi>i</mi><mi>s</mi><msubsup><mi>t</mi><mrow><mi>o</mi><mi>b</mi><mi>j</mi><mi>I</mi><mi>D</mi></mrow><mi>T</mi></msubsup></mrow><annotation encoding="application/x-tex">Hist^T_{objID}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2605em;vertical-align:-0.4192em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal">i</span><span class="mord mathnormal">s</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-2.4169em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">bj</span><span class="mord mathnormal mtight" style="margin-right:0.07847em;">I</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192em;"><span></span></span></span></span></span></span></span></span></span> 全量复制到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mi>i</mi><mi>s</mi><msubsup><mi>t</mi><mrow><mi>o</mi><mi>b</mi><mi>j</mi><mi>I</mi><mi>D</mi></mrow><msup><mi>T</mi><mo>+</mo></msup></msubsup></mrow><annotation encoding="application/x-tex">Hist^{T^+}_{objID}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3756em;vertical-align:-0.4192em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal">i</span><span class="mord mathnormal">s</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9564em;"><span style="top:-2.4169em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">bj</span><span class="mord mathnormal mtight" style="margin-right:0.07847em;">I</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8477em;"><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192em;"><span></span></span></span></span></span></span></span></span></span>,由于复制的时间可能很长，原本的尾部 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span> 因此还并发地承担之前的责任以确保可用性，但是将这段时间的更新同时增加到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>e</mi><mi>n</mi><msub><mi>t</mi><mi>T</mi></msub></mrow><annotation encoding="application/x-tex">Sent_T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，直到全量复制完成。</p><p>之后，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span>  将之后的查询请求丢弃或者转发给新的链尾 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>T</mi><mo>+</mo></msup></mrow><annotation encoding="application/x-tex">T^+</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7713em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7713em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span></span></span></span> ，并把已有的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>e</mi><mi>n</mi><msub><mi>t</mi><mi>T</mi></msub></mrow><annotation encoding="application/x-tex">Sent_T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的请求发送给 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>T</mi><mo>+</mo></msup></mrow><annotation encoding="application/x-tex">T^+</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7713em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7713em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span></span></span></span>。然后 master 通知 client 新的链尾，并让它直接访问 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>T</mi><mo>+</mo></msup></mrow><annotation encoding="application/x-tex">T^+</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7713em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7713em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span></span></span></span>。</p><h3 id="Primary-Backup-Protocols">Primary/Backup Protocols</h3><p>In the primary/backup approach, one server, designated the <em>primary</em></p><ul><li>imposes a sequencing on client requests (and thereby ensures strong consistency holds).</li><li>distributes (in sequence) to other servers, known as backups, the client requests or resulting updates.</li><li>awaits acknowledgements from all non-faulty backups.</li><li>after receiving those acknowledgements then sends a reply to the client.</li></ul><p>With chain replication, <strong>the primary’s role in sequencing requests is shared by two replicas.</strong></p><ul><li>The head sequences update requests.</li><li>The tail extends that sequence by interleaving query requests.</li></ul><p>链式复制的一个缺点就是延时会更高，并且随着链长度的增加，延时也会成比例的线性增加。</p><blockquote><p>Chain replication does this dissemination serially, resulting in higher latency than the primary/backup approach where requests were distributed to backups in parallel.</p></blockquote><p>但是在错误处理上，链式复制所需要的时间会更短，论文中有详细的分析，这里就不多赘述了。</p><h3 id="Summary">Summary</h3><p>链式复制是一个相对比较简单的协议，支持高吞吐，高可用以及强一致性，是一个 CP 系统，而链式复制做出的取舍就是增加了时延。</p><p>CR 能够以很简单的设计实现多副本的线性一致性，不过其不能自己处理脑裂和分区的问题，因而还需要另一个高可用的配置服务器集群来协作提供高可用服务。</p>]]></content>
    
    
    <categories>
      
      <category>Distributed</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PaperNote</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>About CAP</title>
    <link href="/2023/11/06/Talks/about-cap/"/>
    <url>/2023/11/06/Talks/about-cap/</url>
    
    <content type="html"><![CDATA[<h2 id="What-is-CAP">What is CAP</h2><ul><li>Consistency: 数据一致性</li><li>Availability: 可用性</li><li>Partition Tolerance: 分区容忍性</li></ul><h3 id="Consistency">Consistency</h3><blockquote><p>指的是系统能够返回一致性的数据。</p></blockquote><p>Gilbert 和 Lynch 的论文中是这样描述一致性的：</p><blockquote><p>Any read operation that begins after a write operation completes must return that value, or the result of a later write operation.<br>在某个写操作完成之后的任何读操作都必须返回该写操作写入的值，或者再之后的写操作写入的值。</p></blockquote><p>在一个一致性的系统中，如果一个客户端写入了某个值到任意一个服务端上，并且得到了服务端的确认，那么客户端再去读的时候，不管是读的哪个服务，都期望拿到写入后的值或者是更新的值。</p><h3 id="Available">Available</h3><blockquote><p>指的是系统能保持在可用的状态。</p></blockquote><p>Gilbert 和 Lynch 的论文对可用性的描述如下：</p><blockquote><p>Every request received by a non-failing node in the system must result in a response.<br>任何一个在线的节点收到的请求必须都做出相应。</p></blockquote><p>在保证可用性的系统中，如果客户端向某个没有宕机的服务端发送了请求，服务端必须响应客户端的请求，不能选择忽略掉客户端的请求。</p><p>它要求系统内的节点们接收到了无论是写请求还是读请求，都要能处理并给回响应结果。只是它有两点必须满足的条件：</p><ul><li>返回结果必须在合理的时间以内，这个合理的时间是根据业务来定的。</li><li>需要系统内能正常接收请求的所有节点都返回结果。<ul><li>如果节点不能正常接收请求了，比如宕机了，系统崩溃了，而其他节点依然能正常接收请求，那么，我们说系统依然是可用的，也就是说，部分宕机没事儿，不影响可用性指标。</li><li>如果节点能正常接收请求，但是发现节点内部数据有问题，那么也必须返回结果，哪怕返回的结果是有问题的。</li></ul></li></ul><h3 id="Partition-Tolerance">Partition Tolerance</h3><blockquote><p>指的是系统能够容忍分区问题。</p></blockquote><p>Gilbert 和 Lynch 的论文对分区容错性的描述如下：</p><blockquote><p>The network will be allowed to lose arbitrarily many messages sent from one node to another.<br>允许网络丢失从一个服务节点到另外一个服务节点的任意信息</p></blockquote><h2 id="How-to-choose">How to choose</h2><p>在分布式系统内，P 是必然的发生的，不选 P，一旦发生分区错误，整个分布式系统就完全无法使用了，这是不符合实际需要的。所以，<strong>对于分布式系统，我们只能能考虑当发生分区错误时，如何选择一致性和可用性</strong>。</p><p>而根据一致性和可用性的选择不同，开源的分布式系统往往又被分为 CP 系统和 AP 系统:</p><ul><li>当一套系统在发生分区故障后，客户端的任何请求都被卡死或者超时，但是，系统的每个节点总是会返回一致的数据，则这套系统就是 CP 系统，经典的比如 Zookeeper。</li><li>如果一套系统发生分区故障后，客户端依然可以访问系统，但是获取的数据有的是新的数据，有的还是老数据，那么这套系统就是 AP 系统，经典的比如 Eureka。</li></ul><h2 id="常见误解">常见误解</h2><h3 id="分布式系统因为-CAP-定理放弃了-C-或者-A-中的其中一个">分布式系统因为 CAP 定理放弃了 C 或者 A 中的其中一个</h3><p>很多人觉得一套分布式系统肯定要么只有可用性要么只有一致性，不存在完整的可用性和一致性功能。</p><p>这种理解是大有问题的。因为，P 这种问题发生的概率非常低，所以：</p><p><strong>当没有出现分区问题的时候，系统就应该有完美的数据一致性和可用性。</strong></p><h3 id="C-和-A-之间的选择是针对整个分布式系统的，只能整体考虑-C-和-A-之间的选择">C 和 A 之间的选择是针对整个分布式系统的，只能整体考虑 C 和 A 之间的选择</h3><p>当分区发生的时候，其实对一致性和可用性的抉择是局部性的，而不是针对整个系统的。可能是在一些子系统做一些抉择，甚至很可能只需要对某个事件或者数据，做一致性和可用性的抉择而已。</p><p>比如，当我们做一套支付系统的时候，会员的财务相关像账户余额，账务流水是必须强一致性的。这时候，你就要考虑选 C。但是，会员的名字，会员的支付设置就不必考虑强一致性，可以选择可用性 A。</p><h2 id="不足">不足</h2><ol><li>CAP 定理本身是没有考虑网络延迟的问题的，它认为一致性是立即生效的，但是，要保持一致性，是需要时间成本的，这就导致往往分布式系统多选择 AP 方式</li><li>由于时代的演变，CAP 定理在针对所有分布式系统的时候，出现了一些力不从心的情况，导致很多时候它自己会把以前很严谨的数学定义改成了比较松弛的业务定义，类似于我们看到，CAP 定理把一致性、可用性、分区容错都变成了一个范围属性，而这和 CAP 定理本身这种数学定理般的称呼是有冲突的，出现了不符合数学严谨定义的问题。</li><li>在实践中以及后来 CAP 定理的提出者也承认，一致性和可用性并不仅仅是二选一的问题，只是一些重要性的区别，当强调一致性的时候，并不表示可用性是完全不可用的状态。比如，Zookeeper 只是在 master 出现问题的时候，才可能出现几十秒的不可用状态，而别的时候，都会以各种方式保证系统的可用性。而强调可用性的时候，也往往会采用一些技术手段，去保证数据最终是一致的。CAP 定理并没有给出这些情况的具体描述。</li><li>CAP 理论从工程角度来看只是一种状态的描述，它告诉大家当有错的时候，分布式系统可能处在什么状态。但是，状态是可能变化的。状态间如何转换，如何修补，如何恢复是没有提供方向的。</li></ol><h2 id="Reference">Reference</h2><ul><li><a href="https://zhuanlan.zhihu.com/p/338835258">CAP理论该怎么理解？为什么是三选二？为什么是CP或者AP？</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Distributed</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Talk</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Paper Note: Time, clocks, and the ordering</title>
    <link href="/2023/11/04/Papers/time,%20clocks,%20and%20the%20ordering/"/>
    <url>/2023/11/04/Papers/time,%20clocks,%20and%20the%20ordering/</url>
    
    <content type="html"><![CDATA[<h2 id="Happened-Before-关系">Happened Before 关系</h2><p>论文先从事件之间的 Happened Before 关系开始讲起</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231105150635534.png" alt="image-20231105150635534"></p><p>结合上图我们举例解释一下「Happened Before」关系：</p><ul><li>同一进程内部先后发生的两个事件之间，具有「Happened Before」关系。比如，在进程 Q 内部，q_2 表示一个消息接收事件，q_4表示另一个消息的发送事件，q_2 排在 q_4 前面执行，所以 q_2 → q_4。</li><li>同一个消息的发送事件和接收事件，具有「Happened Before」关系。比如，p_1 和 q_2分别表示同一个消息的发送事件和接收事件，所以 p_1→ q_2；同理， q_4→ r_3。</li><li>「Happened Before」满足传递关系。比如，由 p_1→ q_2， q_2→_q_4和 q_4→ r_3，可以推出 p_1 → r_3。</li></ul><p>作者然后说明了并发的概念：</p><blockquote><p>Two distinct events a and b are said to be <em>concurrent</em> if a !→ b and b !→ a.</p></blockquote><p>同时作者也描述了与因果性的关系：</p><blockquote><p>Another way of viewing the definition is to say that a→b means that it is possible for event a to causally affect event b. Two events are concurrent if neither can causally affect the other.</p></blockquote><p>需要注意的是， Happened Before 关系是一种偏序关系。</p><h2 id="逻辑时钟">逻辑时钟</h2><p>Lamport 在定义事件之间的「Happened Before」关系时特意避开了物理时间。这也就意味着，对事件的「发生时间」进行度量，只能根据逻辑时钟。</p><p>为什么要定义逻辑时钟这个概念呢？我们前面讨论过，在分布式系统中我们经常需要对不同的事件进行排序。那么，为了实现这种排序操作，我们很自然地就需要对事件的发生进行一种数值上的度量。我们希望，可以通过比较事件的时间戳数值大小，来判断事件发生的次序（即「Happened Before」关系）。这就好比我们通过看钟表上显示的数值来确定时间的流逝一样。</p><p>当然，逻辑时钟在给事件打时间戳的时候，必须要满足一定条件的。这个过程必须能在一定程度上反映出事件之间的「Happened Before」关系。</p><p>论文定义了一个时钟条件 (Clock Condition):</p><ul><li>对于任意的事件 a 和 b：如果 a→b，那么必须满足 C〈a〉 &lt; C〈b〉。</li></ul><p>对于逻辑时钟的实现，论文也简单地给出了实现了两条规则：</p><ol><li>Each process <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">P_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> increments <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mi>i</mi></mrow><annotation encoding="application/x-tex">Ci</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal">i</span></span></span></span> between any two successive events.</li><li>If event a is the sending of a message m by process <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">P_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, then the message <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">m</span></span></span></span> contains a timestamp <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>m</mi></msub><mo>=</mo><mi>C</mi><mi>i</mi><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">T_m= Ci (a)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal">i</span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mclose">)</span></span></span></span>.Upon receiving a message <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">m</span></span></span></span>, process <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">P_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> sets <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">C_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> greater than or equal to its present value and greater than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">T_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>.</li></ol><h2 id="全局排序">全局排序</h2><p>引入逻辑时钟的目的是想帮助我们判断事件之间的 Happened Before 关系，但是由于该关系的偏序性，我们不能根据两个事件对应的时间戳在数值上的大小来推断出它们之间是否存在「Happened Before」关系。</p><blockquote><p>In fact, the reason for implementing a correct system of logical clocks is to obtain such a total ordering.</p></blockquote><p>对于不具有「Happened Before」关系的两个事件来说，它们对应的时间戳数值比较大小，是没有意义的。但是，确实可以根据两个时间戳的大小，来为两个事件「指定」一个次序。这个次序是人为指定的，并不是客观上要求的。</p><p>如果我们按照逻辑时钟给出的时间戳从小到大把所有事件都排成一个序列，那么就得到了分布式系统中所有事件的全局排序。</p><p>这里需要引入一个进程编号 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">P_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，如果两个进程的时间戳一样，那么人为指定进程编号小的事件先于进程编号大的事件发生，这样的话就可以定义一个全序关系 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⇒</mo></mrow><annotation encoding="application/x-tex">\Rightarrow</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.3669em;"></span><span class="mrel">⇒</span></span></span></span> 。换句话说，它是把 “Happened Before” 关系补全为了一个全序关系。</p><blockquote><p>在图中，就可以得到  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">p_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> =&gt; <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">r_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> =&gt; <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">r_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> =&gt; <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">q_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> =&gt; <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">p_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> =&gt; <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">q_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> =&gt; <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">p_3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> =&gt; <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">q_3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> =&gt; <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>4</mn></msub></mrow><annotation encoding="application/x-tex">q_4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> =&gt; <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>5</mn></msub></mrow><annotation encoding="application/x-tex">q_5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> =&gt; <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">r_3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>=&gt; <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mn>4</mn></msub></mrow><annotation encoding="application/x-tex">p_4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> =&gt; <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>6</mn></msub></mrow><annotation encoding="application/x-tex">q_6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">6</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> =&gt; <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mn>4</mn></msub></mrow><annotation encoding="application/x-tex">r_4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> =&gt; <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mn>7</mn></msub></mrow><annotation encoding="application/x-tex">q_7</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">7</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p></blockquote><p>在这个排序中，所有事件之间的「Happened Before」关系都被保持住了；而本来不存在「Happened Before」关系的事件之间，我们也依据时间戳的大小，通过人为指定的方式得到了一个次序。总之，我们得到了所有事件的一种全局排序，而这种排序是和「Happened Before」关系（即因果顺序）保持一致的。</p><p>有了全序关系后有什么用呢？论文用它解决了一个资源互斥问题：</p><blockquote><p>多个 Process 共享一个集中资源 R，每个 Process 想使用 R 时必须申请，经过全部人同意后才可以使用，且使用完成后必须要释放 R 以供他人使用。且需要满足先申请先访问原则，还不能存在死锁的问题。</p></blockquote><p>很容易想到的是使用协调者的解决方法：</p><ul><li>存在一个至高无上的协调者管理资源分配；</li><li>协调者根据收到请求的先后顺序分配资源的使用顺序；</li></ul><p>这个方案看起来一切正常，但是可能存在一个漏洞，假如：</p><ol><li>Process 1 向协调者发起资源分配请求 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mn>1</mn></mrow><annotation encoding="application/x-tex">R1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord">1</span></span></span></span>；</li><li>Process 1 向 Process 2 发消息 M；</li><li>M 触发 Process 2 产生事件，该事件也向协调者发起资源分配请求 R 2；</li><li>R 2 先于 R1到达协调者</li></ol><p>于是就不满足上面的先申请先访问的原则了。</p><blockquote><p>暂时没想到该漏洞对应的实际例子，因为个人觉得如果两个获取锁的操作之间存在因果关系，那么第一个获取锁的操作成功后才应该向第二个进程发消息。</p></blockquote><p>Lamport 提出的方案：</p><ul><li>去掉协调者，改用分布式协调方案；</li><li>每个 Process 均有一个队列维护资源申请的消息，成为 RequestQueue</li><li>P 申请资源时，向其他 Process 广播该资源申请消息，该消息是一个三元组&lt;T, P, Action&gt;；</li><li>P 收到其他 Process 的资源申请消息时，将该消息放置于 RequestQueue 的尾部，并给申请者回复 ACK 消息；</li></ul><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/v2-88705c000df6aae837203975f9f8be14_b.png" alt="img"></p><p>而 Pi 判断某个消息 (其实代表了一个事件，因为一般是事件申请资源访问，而消息只不过是代替事件去获得访问权限)能否获得资源的访问权限的条件：</p><ul><li>该消息获得了所有节点的 ACK。</li><li>在本地的消息队列中没有比该消息更早的消息。</li></ul><p>我们仔细品味下这两个条件：</p><ul><li>获得所有节点的 ACK 这个比较容易理解，只有大家都同意了才可以访问；并且意味着这个事件已经被广播到了其他所有节点（有点像全序关系广播了）。</li><li>没有比该消息更早的消息则表示该消息是最早的申请者，注意，本地的消息队列中不仅有自己发出的资源申请访问的请求消息，还存有其他节点的资源申请访问请求；</li><li><strong>如何判断两个消息先后顺序就采用了我们上面的全序定义方案</strong>，先判断 T，相同时再判断 P。</li></ul><p>需要注意的是，本地的 Request Queue 中保存的请求消息可能会乱序，并非说队列头部是就是就旧的，队列尾部的就是最新的。因为多个节点之间存在消息传递上的延迟，先发出的请求有可能会后到达。因此，在判断时需要遍历队列上的所有消息。</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/IMG_F303EF65E6DE-1.jpeg" alt="IMG_F303EF65E6DE-1"></p><p>论文中，这个算法后面的几段话也非常的有意思。</p><p>This approach can be generalized to implement any desired synchronization for such a distributed multiprocess system.</p><p>The synchronization is specified in terms of a <em>State Machine</em>.</p><p>Each process independently simulates the execution of the State Machine, using the commands issued by all the processes.</p><p>Synchronization is achieved because <strong>all processes order the commands according to their timestamps (using the relation <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⇒</mo></mrow><annotation encoding="application/x-tex">\Rightarrow</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.3669em;"></span><span class="mrel">⇒</span></span></span></span>), so each process uses the same sequence of commands.</strong></p><p>A process can execute a command timestamped T <strong>when it has learned of all commands issued by all other processes with timestamps less than or equal to T.</strong></p><p>However, the resulting algorithm requires the active participation of all the processes. A process must know all the commands issued by other processes, so that <strong>the failure of a single process will make it impossible</strong> for any other process to execute State Machine commands, thereby halting the system.</p><p><strong>只要我们获得了所有事件的全局排序，那么各种一致性模型对于读写操作所呈现的排序要求，很自然就能得到满足。</strong> 而更近一步，事件的全局排序结合状态机复制（State Machine Replication）的思想，几乎可以为任何分布式系统的设计提供思路。</p><h2 id="逻辑时钟的异常行为">逻辑时钟的异常行为</h2><p>假设 Alice 和 Bob 是一对好朋友，他们住在两个不同的城市。Alice 在网络上观看足球比赛，现在她在自己的计算机上发出了一个查询请求（记为请求 A），用于查询比赛的比分。假设处理请求的是一个分布式系统，并且采用逻辑时钟来为请求打上时间戳。然后请求 A 返回了最新的比分。Alice 这时发现有了一个新的进球得分，于是她打电话给另一个城市的 Bob，告诉他去服务器上查询同一个比赛的比分结果。于是，Bob 通过自己的计算机发出了请求 B。由于系统采用了逻辑时钟，因此处理请求 B 的服务器有可能为请求 B 打上了一个比请求 A 更小的时间戳。对于逻辑时钟来说，这种行为属于正常情况。这是因为，一方面，逻辑时钟的定义特意避开了物理时间，系统产生的时间戳与请求的真实时间先后并没有直接关系；另一方面，在系统内部，请求 A 与请求 B 这两个事件之间，并不存在「Happened Before」关系，因此并不保证请求 B 的时间戳一定比请求 A 的时间戳更大。结果，请求 B 由于被打上了一个更小的时间戳，有可能在全局排序中排到了请求 A 的前面，所以 Bob 并没有查询到最新的球赛比分（也许只查询到了旧版本的数据，这里的行为取决于一些额外的数据库实现机制），因此与 Alice 看到的结果产生了不一致。</p><p>出现异常行为的原因在于系统不知道 Alice 给 Bob 打了电话，所以才认为给请求 B 打一个更小的时间戳是合理的。显然，让系统知道 Alice 给 Bob 打电话这个事实，是不太可能的。但我们注意到，如果考虑一下请求 A 和 B 发出的时间先后，这个问题可能就有办法解决了。</p><p>在这个例子中，Alice 给 Bob 打电话起码要花上几分钟，也就是说请求 B 发生的时间比请求 A 要晚几分钟。对于晚了这么久的请求 B，系统仍然给打了一个更小的时间戳，根本原因在于逻辑时钟是没有和真实的物理时间绑定的。因此，我们可以得到结论：仅仅使用逻辑时钟是不够的，需要使用物理时钟才行。又因为我们需要一个分布式的系统，所以物理时钟不能只有一个实例，而是最好每个进程都有自己对应的本地物理时钟。否则，运行物理时钟的进程就会成为单点，也就失去了分布式的意义。</p><p>现在我们假设，如果系统的物理时钟满足这样一个最苛刻的条件：即使 Alice 通知 Bob 的速度达到光速，系统也总是能保证对请求 B 打上的时间戳要大于请求 A 的时间戳，那么，就能保证永远不出现前面的异常行为。这样的一个时钟条件，在 Lamport 的论文中被称为 Strong Clock Condition。具体描述如下：</p><ul><li>对于任意的事件 a 和 b：如果 a➜b，那么必须满足 C〈a〉 &lt; C〈b〉。</li></ul><blockquote><ul><li>“→”表示「Happened Before」关系</li><li>“➜”表示由相对论定义的事件偏序关系</li></ul></blockquote><h3 id="时空本身定义了一种偏序">时空本身定义了一种偏序</h3><p>这里涉及到了光锥的概念：</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231105154603252.png" alt="image-20231105154603252"></p><p>根据相对论，任何信息传递的速度，最快就是光速。而一个事件要想对另一个事件产生影响，至少要在那个事件发生之前传递一定的信息到达所在的空间位置。因此，一个事件所能够影响的范围，就是以它为顶点的未来光锥内部的时空区域。以上图为例，点 P 在点 O 的未来光锥内部，因此事件 P 可能受到事件 O 的影响；而点 Q 在点 O 的未来光锥外部，因此事件 Q 不可能受到事件 O 的影响。</p><p>这些事件之间可能产生的影响关系，就是我们上一章节末尾所提到的事件偏序关系“➜”。例如，对于事件 O 和事件 P 的关系，我们可以用符号表示成：O➜P。但事件 O 和事件 Q 之间就不存在 O➜Q 的关系。</p><p>简单总结一下，就是：</p><ul><li>一个事件<strong>可能</strong>对它的未来光锥内部的任何事件产生因果性上的影响。</li><li>一个事件与它的未来光锥内部的任何事件之间，满足一个偏序关系，即“➜”。</li></ul><h2 id="物理时钟同步算法">物理时钟同步算法</h2><p>对于任意两个有偏序关系的事件（或者说可能在因果性上产生影响的两个事件），我们的物理时钟要保证总是会为后一个事件打上一个更大的时间戳。</p><p>要实现这个目标，我们面临的障碍主要来源于物理时钟的两种误差：</p><ul><li>时钟的运行速率跟真实时间的流逝速率可能有差异；</li><li>任意两个时钟的运行速率有差异，它们的读数会漂移得越来越远。</li></ul><p>Lamport 在论文中提出的物理时钟同步算法，做的事情其实就是，将这两种时钟误差考虑在内，不断地对各个进程本地的物理时钟进行微调，把误差控制在能够满足 Strong Clock Condition 的范围内。</p><ul><li>对于进程内发生的不同事件，必须保证后发生的事件比先发生的事件时间戳要大。这实际上是要求我们保证每个物理时钟实例的读数总是单调递增的。</li><li>两种机制的赛跑：一方面，Alice 通过系统外的方式向 Bob 传递信息，只要这个过程足够快，他们就有可能“看到”时钟误差造成的时钟读数减退（也就是出现了异常行为）；另一方面，物理时钟同步算法通过在时钟之间不断交换信息并按照一定规则调整时钟读数，将时钟误差控制在一定范围内。只要算法的各个参数设置得当，就能保证：即使 Alice 向 Bob 传递信息的速度达到物理极限——光速，他们也无法“看到”时钟读数的减退现象。于是，Strong Clock Condition 就被满足了。</li></ul><h2 id="现实世界">现实世界</h2><p>分布式系统是一个模拟系统。如果仅仅使用逻辑时钟，就相当于在使用一种系统内部自洽的方式对时间进行了模拟。由于逻辑时钟跟物理时间无关，因此我们站在系统内是不能感知到现实世界的时间流逝的。Alice 和 Bob 之所以能发现系统的时间戳产生异常，是因为他们之间存在一种系统外的信息传递方式。</p><p>假设我们生活在模拟系统内部，我们会发现，Bob在一个较早的逻辑时刻（对应较小的时间戳）接收到了来自Alice在较晚的逻辑时刻（对应较大的时间戳）的信息，相当于接收到了来自未来的信息，而且这个信息是通过不在这个系统内的某种机制传递的。据此，我们也许不需要特意“向外看”，就能推断出在这个系统外部，还有一个世界（我们的这个现实世界）。</p><p>同理，在我们当前生活的这个现实世界中，信息传递的速度受限于光速，而且时间永远向前流逝。也许某一天，我们发现了某种超越光速的信息传递手段，或者我们接收到了来自未来的信息（意味着我们可以预知未来了），那么，也许就说明，在我们这个世界的底层，还有一个更大的未知世界存在在那里。</p><h2 id="总结">总结</h2><blockquote><p>部分来自于网上</p></blockquote><p>时间、时钟、事件顺序是三个不同的东西，现实中人们常常混淆，用时钟作为时间，用时间判断事件的前后顺序。但其实我们几乎无法获知物理时间，我们说的时间都是时钟，而时钟存在漂移，进而无法用于确定事件顺序。因此，需要用消息传递的方式来实现一个逻辑时钟，进而确定事件顺序。</p><h2 id="References">References</h2><ul><li><a href="https://mp.weixin.qq.com/s/FZnJLPeTh-bV0amLO5CnoQ">分布式领域最重要的一篇论文，到底讲了什么？</a></li><li><a href="https://zhuanlan.zhihu.com/p/27503041">事件和时间：Time, Clocks, and the Ordering of Events in a Distributed System 读后感 - 知乎</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Distributed</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PaperNote</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Talk about Redlock</title>
    <link href="/2023/11/02/Talks/talk-about-redlock/"/>
    <url>/2023/11/02/Talks/talk-about-redlock/</url>
    
    <content type="html"><![CDATA[<p>最近看了下之前业界关于 Redlock 的争论，发现还是挺有意思的，正好把自己最近学的知识串了起来，这里就简单总结一下。</p><h2 id="Martin-的观点">Martin 的观点</h2><h3 id="使用分布式锁的目的">使用分布式锁的目的</h3><p>Martin 表示，你必须先清楚你在使用分布式锁的目的是什么？</p><p>他认为有两个目的。</p><p><strong>第一，效率。</strong></p><p>使用分布式锁的互斥能力，是避免不必要地做同样的两次工作（例如一些昂贵的计算任务）。如果锁失效，并不会带来「恶性」的后果，例如发了 2 次邮件等，无伤大雅。</p><p><strong>第二，正确性。</strong></p><p>使用锁用来防止并发进程互相干扰。如果锁失效，会造成多个进程同时操作同一条数据，产生的后果是<strong>数据严重错误、永久性不一致、数据丢失</strong>等恶性问题，就像给患者服用了重复剂量的药物，后果很严重。</p><p>他认为，如果你是为了前者——效率，那么使用单机版 Redis 就可以了，即使偶尔发生锁失效（宕机、主从切换），都不会产生严重的后果。而使用 Redlock 太重了，没必要。</p><p><strong>而如果是为了正确性，Martin 认为 Redlock 根本达不到安全性的要求，也依旧存在锁失效的问题。</strong></p><h3 id="NPC-问题">NPC 问题</h3><p>这些异常场景主要包括三大块，这也是分布式系统会遇到的三座大山：<strong>NPC</strong>。</p><ul><li>N：Network Delay，网络延迟</li><li>P：Process Pause，进程暂停（GC）</li><li>C：Clock Drift，时钟漂移</li></ul><p>Martin 用一个进程暂停（GC）的例子，指出了 Redlock 安全性问题：</p><ol><li>客户端 1 请求锁定节点 A、B、C、D、E</li><li>客户端 1 的拿到锁后，进入 GC（时间比较久）</li><li>所有 Redis 节点上的锁都过期了</li><li>客户端 2 获取到了 A、B、C、D、E 上的锁</li><li>客户端 1 GC 结束，认为成功获取锁</li><li>客户端 2 也认为获取到了锁，发生「冲突」</li></ol><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/unsafe-lock.png" alt="Unsafe access to a resource protected by a distributed lock"></p><blockquote><p>即使是使用没有 GC 的编程语言，在发生网络延迟、时钟漂移时，也都有可能导致 Redlock 出现问题，这里 Martin 只是拿 GC 举例。</p></blockquote><p>因为 Redis 用的时钟不是具有单调性的时钟，所以在发生时间跳跃时，也会导致 Redlock 锁失效</p><ol><li>客户端 1 获取节点 A、B、C 上的锁，但由于网络问题，无法访问 D 和 E</li><li>节点 C 上的时钟「向前跳跃」，导致锁到期</li><li>客户端 2 获取节点 C、D、E 上的锁，由于网络问题，无法访问 A 和 B</li><li>客户端 1 和 2 现在都相信它们持有了锁（冲突）</li></ol><p>Martin 还说明了，如果时钟不失效，网络延迟也有可能带来相同的问题：</p><ol><li>客户端通过 Redlock 成功获取到锁（通过了大多数节点加锁成功、加锁耗时检查逻辑）</li><li>客户端开始操作共享资源，此时发生网络延迟、进程 GC 等耗时很长的情况</li><li>此时，锁过期自动释放</li><li>客户端开始操作 MySQL（此时的锁可能会被别人拿到，锁失效）</li></ol><blockquote><p>但是 Martin 在博客中举的例子是错误的，被 antirez 怼了回去哈哈</p></blockquote><h3 id="解决方法">解决方法</h3><p>相对应的，Martin 提出一种被叫作 fecing token 的方案，保证分布式锁的正确性。</p><p>这个模型流程如下：</p><ol><li>客户端在获取锁时，锁服务可以提供一个「递增」的 token</li><li>客户端拿着这个 token 去操作共享资源</li><li>共享资源可以根据 token 拒绝「后来者」的请求</li></ol><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/fencing-tokens.png" alt="Using fencing tokens to make resource access safe"></p><p>这样一来，无论 NPC 哪种异常情况发生，都可以保证分布式锁的安全性，因为它是建立在「异步模型」上的。</p><p>而 Redlock 无法提供类似 fecing token 的方案，所以它无法保证安全性。</p><p>他还表示，<strong>一个好的分布式锁，无论 NPC 怎么发生，可以不在规定时间内给出结果，但并不会给出一个错误的结果。也就是只会影响到锁的「性能」（或称之为活性），而不会影响它的「正确性」。</strong></p><h3 id="结论">结论</h3><p><strong>1、Redlock 不伦不类</strong>（<em>neither fish nor fowl</em>）：它对于效率来讲，Redlock 比较重，没必要这么做，而对于正确性来说，Redlock 是不够安全的。</p><p><strong>2、时钟假设不合理</strong>：该算法对系统时钟做出了危险的假设（假设多个节点机器时钟都是一致的），如果不满足这些假设，锁就会失效。</p><p><strong>3、无法保证正确性</strong>：Redlock 不能提供类似 fencing token 的方案，所以解决不了正确性的问题。为了正确性，请使用有「共识系统」的软件，例如 Zookeeper。</p><h2 id="Antirez-的反驳">Antirez 的反驳</h2><h3 id="时钟问题">时钟问题</h3><p>对于对方提到的「时钟修改」问题，Antirez 反驳到：</p><ol><li><strong>手动修改时钟</strong>：不要这么做就好了，否则你直接修改 Raft 日志，那 Raft 也会无法工作…</li><li><strong>时钟跳跃</strong>：通过「恰当的运维」，保证机器时钟不会大幅度跳跃（每次通过微小的调整来完成），实际上这是可以做到的</li></ol><h3 id="网络延迟，GC-问题">网络延迟，GC 问题</h3><p>这里先复习一下 Redlock 的流程：</p><ol><li>客户端先获取「当前时间戳 T1」</li><li>客户端依次向这 5 个 Redis 实例发起加锁请求（用前面讲到的 SET 命令），且每个请求会设置超时时间（毫秒级，要远小于锁的有效时间），如果某一个实例加锁失败（包括网络超时、锁被其它人持有等各种异常情况），就立即向下一个 Redis 实例申请加锁</li><li>如果客户端从 3 个（大多数）以上 Redis 实例加锁成功，则再次获取「当前时间戳T2」，如果 T2 - T1 &lt; 锁的过期时间，此时，认为客户端加锁成功，否则认为加锁失败</li><li>加锁成功，去操作共享资源（例如修改 MySQL 某一行，或发起一个 API 请求）</li><li>加锁失败，向「全部节点」发起释放锁请求</li></ol><p>Antirez 强调：如果在 1-3 发生了网络延迟、进程 GC 等耗时长的异常情况，那在第 3 步 T2 - T1，是可以检测出来的，如果超出了锁设置的过期时间，那这时就认为加锁会失败，之后释放所有节点的锁就好了！</p><p>Antirez 继续论述，如果对方认为，发生网络延迟、进程 GC 是在步骤 3 之后，也就是客户端确认拿到了锁，去操作共享资源的途中发生了问题，导致锁失效，那这<strong>不止是 Redlock 的问题，任何其它锁服务例如 Zookeeper，都有类似的问题，这不在讨论范畴内。</strong></p><h3 id="质疑-fencing-token-机制">质疑 fencing token 机制</h3><p>这一部分对我的启发是最大的。</p><p>Antirez 提出了两个问题：</p><h4 id="Fencing-token-必须要求共享资源服务器有拒绝旧-Token-的能力">Fencing token 必须要求共享资源服务器有拒绝旧 Token 的能力</h4><p>例如，要操作 MySQL，从锁服务拿到一个递增数字的 token，然后客户端要带着这个 token 去改 MySQL 的某一行，这就需要利用 MySQL 的「事物隔离性」来做。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-operator">/</span><span class="hljs-operator">/</span> 两个客户端必须利用事物和隔离性达到目的  <br><span class="hljs-operator">/</span><span class="hljs-operator">/</span> 注意 token 的判断条件  <br><span class="hljs-keyword">UPDATE</span> <span class="hljs-keyword">table</span> T <span class="hljs-keyword">SET</span> val <span class="hljs-operator">=</span> $new_val <span class="hljs-keyword">WHERE</span> id <span class="hljs-operator">=</span> $id <span class="hljs-keyword">AND</span> current_token <span class="hljs-operator">&lt;</span> $token<br></code></pre></td></tr></table></figure><p>但如果操作的不是 MySQL 呢？例如向磁盘上写一个文件，或发起一个 HTTP 请求，那这个方案就无能为力了，这对要操作的资源服务器，提出了更高的要求。</p><p>一般的，这里要求共享资源服务器能实现原子性的 CAS 操作（即 <em>compare-and-set</em> 操作），如果该系统能实现 CAS，某种程度上就相当于该系统能够实现 linearizable，那么还用分布式锁做什么呢，直接访问就好了。</p><p>在使用分布式锁的大部分情境下，<strong>我们对共享资源服务器是没有额外控制的</strong>。</p><blockquote><p>Antirez posted:</p><p>From Martin post: “However, the storage server remembers that it has already processed a write with a higher token number (34), and so it rejects the request with token 33.”<br>This is not eventual consistency, this is refusing any new write with ID &lt; past_ID, which requires linearizability.</p></blockquote><blockquote><p>“You don’t need a token service if you are going to set the token on the locked resource, perform work and then unset the token. your lock is completely superfluous in that scenario.”</p></blockquote><blockquote><p>“Most of the times when you need a distributed lock system that can guarantee mutual exclusivity, when this property is violated you already lost. Distributed locks are very useful exactly when <strong>we have no other control in the shared resource.</strong>”</p></blockquote><h4 id="Redlock-提供的随机值也能达到-Fencing-Token-的作用">Redlock 提供的随机值也能达到 Fencing Token 的作用</h4><ol><li>客户端使用 Redlock 拿到锁</li><li>客户端在操作共享资源之前，先把这个锁的 VALUE，在要操作的共享资源上做标记</li><li>客户端处理业务逻辑，最后，在修改共享资源时，判断这个标记是否与之前一样，一样才修改（类似 CAS 的思路）</li></ol><p>还是以 MySQL 为例，举个例子就是这样的：</p><ol><li>客户端使用 Redlock 拿到锁</li><li>客户端要修改 MySQL 表中的某一行数据之前，先把锁的 VALUE 更新到这一行的某个字段中（这里假设为 current_token 字段)</li><li>客户端处理业务逻辑</li><li>客户端修改 MySQL 的这一行数据，把 VALUE 当做 WHERE 条件，再修改</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">UPDATE</span> <span class="hljs-keyword">table</span> T <span class="hljs-keyword">SET</span> val <span class="hljs-operator">=</span> $new_val <span class="hljs-keyword">WHERE</span> id <span class="hljs-operator">=</span> $id <span class="hljs-keyword">AND</span> current_token <span class="hljs-operator">=</span> $redlock_value<br></code></pre></td></tr></table></figure><p>但这里还有个小问题：<strong>两个客户端通过这种方案，先「标记」再「检查+修改」共享资源，那这两个客户端的操作顺序无法保证</strong></p><p>而用 Martin 提到的 fecing token，因为这个 token 是单调递增的数字，资源服务器可以拒绝小的 token 请求，保证了操作的「顺序性」。</p><p>Antirez 的解释是：<strong>分布式锁的本质，是为了「互斥」，只要能保证两个客户端在并发时，一个成功，一个失败就好了，不需要关心「顺序性」。</strong></p><h3 id="结论-2">结论</h3><p>1、作者同意对方关于「时钟跳跃」对 Redlock 的影响，但认为时钟跳跃是可以避免的，取决于基础设施和运维。<br>2、Redlock 在设计时，充分考虑了 NPC 问题，在 Redlock 步骤 3 之前出现 NPC，可以保证锁的正确性，但在步骤 3 之后发生 NPC，不止是 Redlock 有问题，其它分布式锁服务同样也有问题，所以不在讨论范畴内。</p><h2 id="总结">总结</h2><p><strong>一个分布式锁，在极端情况下，不一定是安全的。</strong></p><p>Redlock 只有建立在「时钟正确」的前提下，才能正常工作，如果你可以保证这个前提，那么可以拿来使用。</p><p><em>如何正确的使用分布式锁？</em></p><p><strong>1、使用分布式锁，在上层完成「互斥」目的，虽然极端情况下锁会失效，但它可以最大程度把并发请求阻挡在最上层，减轻操作资源层的压力。</strong></p><p><strong>2、但对于要求数据绝对正确的业务，在资源层一定要做好「兜底」，设计思路可以借鉴 fecing token 的方案来做。</strong></p><h2 id="Other’s-Option">Other’s Option</h2><h3 id="Flavio-Junqueira">Flavio Junqueira</h3><p>However, this is not entirely true if acquiring the lock also implies that the shared resource protected by the lock needs to be involved.</p><p>Say that every time a client acquires a lock to exclusively access a resource, it goes to the resource and before anything else it marks the resource in such a way that clients that acquired the lock previously cannot access the resource. In the scenario above, client <em>C1</em> thinks that it still holds the lock, but when it tries to access the shared resource, it fails because it has an earlier mark from <em>C2</em>.</p><p>That is:</p><ul><li>Get the lock</li><li>Mark the resource (like an epoch number)</li><li>Do something</li></ul><p>Flavio 还提到，如果共享资源是分布式的呢？</p><p>这个问题就又回到了 Antirez 反驳时说的观点：如果资源是分布式的，那么如果要让标记成功，即后续所有的读都要看到之前最近的写，也就是要支持 Linearizable，那么还有什么必要用锁呢？</p><h4 id="How-to-obtain-an-epoch-number">How to obtain an epoch number</h4><p>A simple way to obtain an epoch number to use with the scheme described above is through <em>cversion</em> in ZooKeeper. For example, if the lock znode is /lock, then the <code>cversion</code> of / strictly increases with the number of children. Consequently, every time the /lock znode is created, the version is incremented. Incrementing a value and conditionally updating a znode with that value is also a valid option.</p><h4 id="Summary">Summary</h4><p>The idea is general idea is to make sure the shared resource is consistent by preventing old writers from coming back and messing with the state. It might not always be possible to introduce such epochs with legacy systems, but we do have examples of systems that make use of this scheme.</p><h3 id="Etcd">Etcd</h3><p>The basic idea of the lease mechanism is: a server grants a token, which is called a lease, to a requesting client. When the server grants a lease, it associates a TTL with the lease. When the server detects the passage of time longer than the TTL, it revokes the lease. While the client holds a non revoked lease it can claim that it owns access to a resource associated with the lease.</p><p>The most important aspect of the lease mechanism is that TTL is defined as a physical time interval. Both of the server and client measures passing of time with their own clocks. It allows a situation that the server revokes the lease but the client still claims it owns the lease.</p><p><strong>Actually, the lease mechanism itself doesn’t guarantee mutual exclusion. Owning a lease cannot guarantee the owner holds a lock of the resource.</strong></p><h4 id="version-number-validation">version number validation</h4><p>In the case of controlling mutual accesses to keys of etcd itself with etcd lock, mutual exclusion is implemented based on the mechanism of version number validation (it is sometimes called compare and swap in other systems like Consul).</p><p>In etcd’s RPCs like <code>Put</code> or <code>Txn</code>, we can specify required conditions about revision number and lease ID for the operations. If the conditions are not satisfied, the operation can fail. With this mechanism, etcd provides distributed locking for clients. It means that a client knows that it is acquiring a lock of a key when its requests are completed by etcd cluster successfully.</p><h2 id="References">References</h2><ul><li><a href="https://news.ycombinator.com/item?id=11065933">Hacker News</a></li><li><a href="https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html">How to do distributed locking</a></li><li><a href="http://antirez.com/news/101">Is Redlock safe?</a></li><li><a href="https://mp.weixin.qq.com/s/s8xjm1ZCKIoTGT3DCVA4aw">深度剖析：Redis分布式锁到底安全吗？</a></li><li><a href="https://redis.io/docs/manual/patterns/distributed-locks/">Distributed locks with redis</a></li><li><a href="http://baotiao.github.io/2017/09/12/distributed-lock.html">talk about consensus algorithm and distributed lock</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==&amp;mid=2657261514&amp;idx=1&amp;sn=47b1a63f065347943341910dddbb785d&amp;chksm=84479e13b3301705ea29c86f457ad74010eba8a8a5c12a7f54bcf264a4a8c9d6adecbe32ad0b&amp;scene=178&amp;cur_album_id=1550842358601187329#rd">基于 Redis 的分布式锁到底安全吗（上）？</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==&amp;mid=2657261521&amp;idx=1&amp;sn=7bbb80c8fe4f9dff7cd6a8883cc8fc0a&amp;chksm=84479e08b330171e89732ec1460258a85afe73299c263fcc7df3c77cbeac0573ad7211902649&amp;scene=178&amp;cur_album_id=1550842358601187329#rd">基于Redis的分布式锁到底安全吗（下）？</a></li><li><a href="https://web.archive.org/web/20160213111418/https://fpj.me/2016/02/10/note-on-fencing-and-distributed-locks/">note-on-fencing-and-distributed-locks</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Distributed</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Talk</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>DDIA: Chapter 8 The Trouble with Distributed Systems</title>
    <link href="/2023/11/02/Books/Design%20Data-Intensive%20Applications/chapter-8-the-trouble-with-distributed-systems/"/>
    <url>/2023/11/02/Books/Design%20Data-Intensive%20Applications/chapter-8-the-trouble-with-distributed-systems/</url>
    
    <content type="html"><![CDATA[<h2 id="Faults-and-Partial-Failures">Faults and Partial Failures</h2><p>An individual computer with good software is usually either fully functional or entirely broken, but not something in between. Thus, computers hide the fuzzy physical reality on which they are implemented and present <strong>an idealized system model</strong> that operates with mathematical perfection.</p><p>In a distributed system, there may well be some parts of the system that are broken in some unpredictable way, even though other parts of the system are working fine. This is known as a <em>partial failure</em>. The difficulty is that partial failures are <em>nondeterministic</em>: if you try to do anything involving multiple nodes and the network, it may sometimes work and sometimes unpredictably fail.</p><h2 id="Unreliable-Networks">Unreliable Networks</h2><h3 id="Network-Faults-in-Practice">Network Faults in Practice</h3><p>Handling network faults doesn’t necessarily mean tolerating them: if your network is normally fairly reliable, a valid approach may be to simply show an error message to users while your network is experiencing problems.</p><h3 id="Detecting-Faults">Detecting Faults</h3><p>Unfortunately, the uncertainty about the network makes it difficult to tell whether a node is working or not.</p><p>You can retry a few times (TCP retries transparently, but you may also retry at the application level), wait for a timeout to elapse, and eventually declare the node dead if you don’t hear back within the timeout.</p><h3 id="Timeouts-and-Unbounded-Delays">Timeouts and Unbounded Delays</h3><p>Imagine a fictitious system with a network that guaranteed a maximum delay for packets—every packet is either delivered within some time d, or it is lost, but delivery never takes longer than d. Furthermore, assume that you can guarantee that a nonfailed node always handles a request within some time r. In this case, you could guarantee that every successful request receives a response within time 2 d + r—and if you don’t receive a response within that time, you know that either the network or the remote node is not working. If this was true, 2 d + r would be a reasonable timeout to use.</p><p>Unfortunately, most systems we work with have neither of those guarantees: asynchronous networks have <em>unbounded delays</em> (that is, they try to deliver packets as quickly as possible, but there is no upper limit on the time it may take for a packet to arrive), and most server implementations cannot guarantee that they can handle requests within some maximum time.</p><h4 id="Network-congestion-and-queueing">Network congestion and queueing</h4><p>The variability of packet delays on computer networks is most often due to queueing:</p><ul><li>If there is so much incoming data that the switch queue fills up, the packet is dropped, so it needs to be resent—even though the network is functioning fine.</li><li>When a packet reaches the destination machine, if all CPU cores are currently busy, the incoming request from the network is queued by the operating system until the application is ready to handle it.</li><li>TCP performs <em>flow control</em>, in which a node limits its own rate of sending in order to avoid overloading a network link or the receiving node.</li></ul><h4 id="Synchronous-Versus-Asynchronous-Networks">Synchronous Versus Asynchronous Networks</h4><p>Why do datacenter networks and the internet use packet switching? The answer is that they are optimized for <em>bursty traffic</em>.</p><p>With careful use of <em>quality of service</em> (QoS, prioritization and scheduling of packets) and <em>admission control</em> (rate-limiting senders), it is possible to emulate circuit switching on packet networks, or provide statistically bounded delay.</p><p>However, currently deployed technology does not allow us to make any guarantees about delays or reliability of the network: we have to assume that network congestion, queueing, and unbounded delays will happen. Consequently, there’s no “correct” value for timeouts—they need to be determined experimentally.</p><h2 id="Unreliable-Clocks">Unreliable Clocks</h2><p>This fact sometimes makes it difficult to determine the order in which things happened when multiple machines are involved.</p><h3 id="Monotonic-Versus-Time-of-Day-Clocks">Monotonic Versus Time-of-Day Clocks</h3><p>Modern computers have at least two different kinds of clocks: a <em>time-of-day clock</em> and a <em>monotonic clock</em>. Although they both measure time, it is important to distinguish the two, since they serve different purposes.</p><h4 id="Time-of-day-clocks">Time-of-day clocks</h4><p>A time-of-day clock does what you intuitively expect of a clock: it returns the current date and time according to some calendar.</p><blockquote><p>For example, <code>clock_gettime(CLOCK_REALTIME)</code> on Linux.</p></blockquote><p>Time-of-day clocks are usually synchronized with NTP, which means that a timestamp from one machine (ideally) means the same as a timestamp on another machine. In particular, if the local clock is too far ahead of the NTP server, it may be forcibly reset and appear to jump back to a previous point in time. <strong>These jumps, as well as the fact that they often ignore leap seconds, make time-of-day clocks unsuitable for measuring elapsed time</strong>.</p><h4 id="Monotonic-clocks">Monotonic clocks</h4><p>A monotonic clock is suitable for measuring a duration (time interval), such as a timeout or a service’s response time: <code>clock_gettime(CLOCK_MONOTONIC)</code> on Linux and <code>System.NanoTime()</code> in Java are monotonic clocks, for example.</p><p>The name comes from the fact that they are guaranteed to always move forward (whereas a time-of-day clock may jump back in time).</p><p>In a distributed system, using a monotonic clock for measuring elapsed time (e.g., timeouts) is usually fine, because it doesn’t assume any synchronization between different nodes’ clocks and is not sensitive to slight inaccuracies of measurement.</p><h3 id="Clock-Synchronization-and-Accuracy">Clock Synchronization and Accuracy</h3><p>Monotonic clocks don’t need synchronization, but time-of-day clocks need to be set according to an NTP server or other external time source in order to be useful.</p><p>Our methods for getting a clock to tell the correct time aren’t nearly as reliable or accurate as you might hope：</p><ul><li>The quartz clock in a computer is not very accurate: it drifts (runs faster or slower than it should).</li><li>If a computer’s clock differs too much from an NTP server, it may refuse to synchronize, or the local clock will be forcibly reset。</li><li>NTP synchronization can only be as good as the network delay, so there is a limit to its accuracy when you’re on a congested network with variable packet delays.</li><li>Leap seconds result in a minute that is 59 seconds or 61 seconds long, which messes up timing assumptions in systems that are not designed with leap seconds in mind.</li><li>In virtual machines, the hardware clock is virtualized, which raises additional challenges for applications that need accurate timekeeping.</li></ul><h3 id="Relying-on-Synchronized-Clocks">Relying on Synchronized Clocks</h3><p>The problem with clocks is that while they seem simple and easy to use, they have a surprising number of pitfalls:</p><ul><li>A day may not have exactly 86,400 seconds.</li><li>Time-of-day clocks may move backward in time.</li><li>The time on one node may be quite different from the time on another node.</li></ul><h4 id="Timestamps-for-ordering-events">Timestamps for ordering events</h4><p>Let’s consider one particular situation in which it is tempting, but dangerous, to rely on clocks: ordering of events across multiple nodes. For example, if two clients write to a distributed database, who got there first?</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231102205020195.png" alt="The write by client B is causally later than the write by client A, but B’s write has an earlier timestamp."></p><blockquote><p>The write x = 1 has a timestamp of 42.004 seconds, but the write x = 2 has a timestamp of 42.003 seconds, even though x = 2 occurred unambiguously later. When node 2 receives these two events, it will incorrectly conclude that x = 1 is the more recent value and drop the write x = 2. In effect, client B’s increment operation will be lost.</p></blockquote><p>This conflict resolution strategy is called last write wins (LWW), and it is widely used in both multi-leader replication and leaderless databases.</p><ul><li>Database writes can mysteriously disappear: a node with a lagging clock is unable to overwrite values previously written by a node with a fast clock until the clock skew between the nodes has elapsed.</li><li>LWW cannot distinguish between writes that occurred sequentially in quick succession.</li><li>It is possible for two nodes to independently generate writes with the same timestamp, especially when the clock only has millisecond resolution.</li></ul><p>Could NTP synchronization be made accurate enough that such incorrect orderings cannot occur? Probably not, because NTP’s synchronization accuracy is itself limited by the network round-trip time, in addition to other sources of error such as quartz drift. <strong>For correct ordering, you would need the clock source to be significantly more accurate than the thing you are measuring (namely network delay)</strong>.</p><p>这种时候<em>逻辑时钟</em>就能派上用场了，还是上面的那种情况：</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/IMG_2D4CCAC1628F-1.jpeg" alt="IMG_2D4CCAC1628F-1"></p><p>因为 <code>set x=1</code> 和 <code>increase x+=1</code> 是有因果关系的，所以用 Happened Before 这种关系维护的全局排序是能反映这两个操作的因果关系的（<code>increase x+=1</code> 的时间戳一定大于 <code>set x=1</code>，因为在 N3 里它后于 <code>set x=1</code> 发生）。</p><h4 id="Clock-readings-have-a-confidence-interval">Clock readings have a confidence interval</h4><blockquote><p>“置信区间”</p></blockquote><p>The uncertainty bound can be calculated based on your time source. If you have a GPS receiver or atomic (caesium) clock directly attached to your computer, the expected error range is reported by the manufacturer. If you’re getting the time from a server, the uncertainty is based on the expected quartz drift since your last sync with the server, plus the NTP server’s uncertainty, plus the network round-trip time to the server (to a first approximation, and assuming you trust the server).</p><p>Unfortunately, most systems don’t expose this uncertainty: for example, when you call <code>clock_gettime()</code>, the return value doesn’t tell you the expected error of the timestamp, so you don’t know if its confidence interval is five milliseconds or five years.</p><h4 id="Synchronized-clocks-for-global-snapshots">Synchronized clocks for global snapshots</h4><p>The most common implementation of snapshot isolation requires a monotonically increasing transaction ID. If a write happened later than the snapshot (i.e., the write has a greater transaction ID than the snapshot), that write is invisible to the snapshot transaction.</p><p>However, when a database is distributed across many machines, potentially in multiple datacenters, a global, monotonically increasing transaction ID (across all partitions) is difficult to generate, <strong>because it requires coordination.</strong></p><p>Spanner implements snapshot isolation across datacenters in this way. It uses the clock’s confidence interval as reported by the TrueTime API, and is based on the following observation: if you have two confidence intervals, each consisting of an earliest and latest possible timestamp (A = [Aearliest, Alatest] and B = [Bearliest, Blatest]), and those two intervals do not overlap (i.e., Aearliest &lt; Alatest &lt; Bearliest &lt; Blatest), then B definitely happened after A—there can be no doubt. Only if the intervals overlap are we unsure in which order A and B happened.</p><p>Using clock synchronization for distributed transaction semantics is an area of active research. These ideas are interesting, but they have not yet been implemented in mainstream databases outside of Google.</p><h3 id="Process-Pauses">Process Pauses</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go">while (<span class="hljs-literal">true</span>) &#123; <br> request = getIncomingRequest(); <br> <span class="hljs-comment">// Ensure that the lease always has at least 10 seconds remaining </span><br> <span class="hljs-keyword">if</span> (lease.expiryTimeMillis - System.currentTimeMillis() &lt; <span class="hljs-number">10000</span>) &#123;<br>  lease = lease.renew(); <br> &#125; <br> <span class="hljs-keyword">if</span> (lease.isValid()) &#123; <br>  process(request); <br> &#125; <br>&#125;<br></code></pre></td></tr></table></figure><p><em>What’s wrong with this code?</em></p><p>Firstly, <strong>it’s relying on synchronized clocks</strong>: the expiry time on the lease is set by a different machine (where the expiry may be calculated as the current time plus 30 seconds, for example), and it’s being compared to the local system clock. If the clocks are out of sync by more than a few seconds, this code will start doing strange things.</p><p>Secondly, even if we change the protocol to only use the local monotonic clock, there is another problem: <strong>the code assumes that very little time passes</strong> between the point that it checks the time (<code>System.CurrentTimeMillis()</code>) and the time when the request is processed (<code>process (request)</code>).</p><p>Is it crazy to assume that a thread might be paused for so long? Unfortunately not. There are various reasons why this could happen:</p><ul><li>Many programming language runtimes (such as the Java Virtual Machine) have a <em>garbage collector</em> (GC) that occasionally needs to stop all running threads. These <em>“stop-the-world” GC pauses</em> have sometimes been known to last for several minutes.</li><li>In virtualized environments, a virtual machine can be suspended (pausing the execution of all processes and saving the contents of memory to disk) and resumed (restoring the contents of memory and continuing execution).</li><li>If the application performs synchronous disk access, a thread may be paused waiting for a slow disk I/O operation to complete.</li><li>If the operating system is configured to allow swapping to disk (paging), a simple memory access may result in a page fault that requires a page from disk to be loaded into memory. The thread is paused while this slow I/O operation takes place.</li></ul><p><strong>You can’t assume anything about timing, because arbitrary context switches and parallelism may occur.</strong></p><h4 id="Limiting-the-impact-of-garbage-collection">Limiting the impact of garbage collection</h4><p>An emerging idea is to treat GC pauses like brief planned outages of a node, and to let other nodes handle requests from clients while one node is collecting its garbage.</p><p>A variant of this idea is to use the garbage collector only for short-lived objects (which are fast to collect) and to restart processes periodically, before they accumulate enough long-lived objects to require a full GC of long-lived objects.</p><h3 id="Knowledge-Truth-and-Lies">Knowledge, Truth, and Lies</h3><p>So far in this chapter we have explored the ways in which distributed systems are different from programs running on a single computer: <strong>there is no shared memory, only message passing via an unreliable network with variable delays, and the systems may suffer from partial failures, unreliable clocks, and processing pauses.</strong></p><h4 id="The-Truth-Is-Defined-by-the-Majority">The Truth Is Defined by the Majority</h4><p>A distributed system cannot exclusively rely on a single node, because a node may fail at any time, potentially leaving the system stuck and unable to recover. Instead, many distributed algorithms rely on a <em>quorum</em>, that is, voting among the nodes: decisions require some minimum number of votes from several nodes in order to reduce the dependence on any one particular node.</p><h5 id="The-leader-and-the-lock">The leader and the lock</h5><p>Frequently, a system requires there to be only one of some thing:</p><ul><li>Only one node is allowed to be the leader for a database partition, to avoid split brain.</li><li>Only one transaction or client is allowed to hold the lock for a particular resource or object, to prevent concurrently writing to it and corrupting it.</li><li>Only one user is allowed to register a particular username, because a username must uniquely identify a user.</li></ul><p>Below shows a data corruption bug due to an incorrect implementation of locking:</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231102210713994.png" alt="Incorrect implementation of a distributed lock: client 1 believes that it still has a valid lease, even though it has expired, and thus corrupts a file in storage."></p><p>If the client holding the lease is paused for too long, its lease expires. Another client can obtain a lease for the same file, and start writing to the file. When the paused client comes back, it believes (incorrectly) that it still has a valid lease and proceeds to also write to the file.</p><h5 id="Fencing-tokens">Fencing tokens</h5><p>When using a lock or lease to protect access to some resource, we need to ensure that a node that is under a false belief of being “the chosen one” cannot disrupt the rest of the system. A fairly simple technique that achieves this goal is called <em>fencing</em>:</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231102210844751.png" alt="Making access to storage safe by allowing writes only in the order of increasing fencing tokens."></p><blockquote><p>This approach is under arguments:</p><p>Distributed locks are very useful exactly when <strong>we have no other control in the shared resource.</strong></p></blockquote><p>If ZooKeeper is used as lock service, the transaction ID zxid or the node version cversion can be used as fencing token. Since they are guaranteed to be monotonically increasing, they have the required properties.</p><h3 id="Byzantine-Faults">Byzantine Faults</h3><p>Distributed systems problems become much harder if there is a risk that nodes may “lie” (send arbitrary faulty or corrupted responses)—for example, if a node may claim to have received a particular message when in fact it didn’t. Such behavior is known as a <em>Byzantine fault</em>, and the problem of reaching consensus in this untrusting environment is known as the <em>Byzantine Generals Problem</em>.</p><p>A system is <em>Byzantine fault-tolerant</em> if it continues to operate correctly even if some of the nodes are malfunctioning and not obeying the protocol, or if malicious attackers are interfering with the network.</p><p>A bug in the software could be regarded as a Byzantine fault, but if you deploy the same software to all nodes, then a Byzantine fault-tolerant algorithm cannot save you. Most Byzantine fault-tolerant algorithms require a supermajority of more than twothirds of the nodes to be functioning correctly (i.e., if you have four nodes, at most one may malfunction).</p><h3 id="System-Model-and-Reality">System Model and Reality</h3><p>Algorithms need to be written in a way that does not depend too heavily on the details of the hardware and software configuration on which they are run. This in turn requires that we somehow formalize the kinds of faults that we expect to happen in a system.</p><p>We do this by defining a <em>system model</em>, which is an abstraction that describes what things an algorithm may assume.</p><p>With regard to timing assumptions, three system models are in common use:</p><ul><li><em>Synchronous model</em><ul><li>The synchronous model assumes bounded network delay, bounded process pauses, and bounded clock error.</li><li>This does not imply exactly synchronized clocks or zero network delay; it just means you know that network delay, pauses, and clock drift will never exceed some fixed upper bound.</li></ul></li><li><em>Partially synchronous model</em><ul><li>Partially synchronous model Partial synchrony means that a system behaves like a synchronous system <em>most of the time</em>, but it sometimes exceeds the bounds for network delay, process pauses, and clock drift.</li><li>This is a realistic model of many systems: most of the time, networks and processes are quite well behaved—otherwise we would never be able to get anything done—but we have to reckon with the fact that any timing assumptions may be shattered occasionally.</li></ul></li><li><em>Asynchronous model</em><ul><li>asynchronous model In this model, an algorithm is not allowed to make any timing assumptions — in fact, it does not even have a clock (so it cannot use timeouts).</li></ul></li></ul><p>Moreover, besides timing issues, we have to consider node failures. The three most common system models for nodes are:</p><ul><li><em>Crash-stop faults</em><ul><li>In the crash-stop model, an algorithm may assume that a node can fail in only one way, namely by crashing.</li></ul></li><li><em>Crash-recovery faults</em><ul><li>We assume that nodes may crash at any moment, and perhaps start responding again after some unknown time. In the crash-recovery model, nodes are assumed to have stable storage (i.e., nonvolatile disk storage) that is preserved across crashes, while the in-memory state is assumed to be lost.</li></ul></li><li><em>Byzantine (arbitrary) faults</em><ul><li>Nodes may do absolutely anything, including trying to trick and deceive other nodes.</li></ul></li></ul><p>For modeling real systems, the partially synchronous model with crash-recovery faults is generally the most useful model.</p><h4 id="Correctness-of-an-algorithm">Correctness of an algorithm</h4><p>To define what it means for an algorithm to be correct, we can describe its <em>properties</em>.</p><blockquote><p>For example, the output of a sorting algorithm has the property that for any two distinct elements of the output list, the element further to the left is smaller than the element further to the right.</p></blockquote><h5 id="Safety-and-liveness">Safety and liveness</h5><p>To clarify the situation, it is worth distinguishing between two different kinds of properties: <em>safety</em> and <em>liveness</em> properties.</p><p>What distinguishes the two kinds of properties? A giveaway is that liveness properties often include the word “eventually” in their definition. (And yes, you guessed it - <em>eventual consistency</em> is a liveness property.)</p><p>Safety is often informally defined as <em>nothing bad happens</em>, and liveness as <em>something good eventually happens</em>.</p><p>The actual definitions of safety and liveness are precise and mathematical:</p><ul><li>If a safety property is violated, we can point at a particular point in time at which it was broken. After a safety property has been violated, the violation cannot be undone—the damage is already done.</li><li>A liveness property works the other way round: it may not hold at some point in time. There is always hope that it may be satisfied in the future (namely by receiving a response).</li></ul><p>An advantage of distinguishing between safety and liveness properties is that it helps us deal with difficult system models.</p><p>For distributed algorithms, it is common to require that safety properties <em>always</em> hold, in all possible situations of a system model. That is, even if all nodes crash, or the entire network fails, the algorithm must nevertheless ensure that it does not return a wrong result (i.e., that the safety properties remain satisfied).</p><p>However, with liveness properties we are allowed to make caveats: for example, we could say that a request needs to receive a response only if a majority of nodes have not crashed, and only if the network <em>eventually</em> recovers from an outage. The definition of the partially synchronous model requires that eventually the system returns to a synchronous state—that is, any period of network interruption lasts only for a finite duration and is then repaired.</p>]]></content>
    
    
    <categories>
      
      <category>Design Data-Intensive Applications</category>
      
    </categories>
    
    
    <tags>
      
      <tag>BookNote</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Paper Note: Chubby</title>
    <link href="/2023/10/31/Papers/chubby/"/>
    <url>/2023/10/31/Papers/chubby/</url>
    
    <content type="html"><![CDATA[<h2 id="FAQ">FAQ</h2><p><em>What is an advisory lock?</em></p><p>An “advisory lock” is simply a tool/API provided by Postgres to create arbitrary locks that can be acquired by applications. These locks, however, are not enforced in any meaningful way by the database – it’s up to application code to give them meaning (the same way any other non-database distributed lock would work).</p><p><em>What is a write-through cache?</em></p><p>A write-through cache is a caching strategy where data is simultaneously written into the cache and the corresponding database or backing store.</p><p>When data is written, it is first written to the cache and then immediately written to the main memory (or disk).</p><p>The main advantage of a write-through cache is that it offers a high degree of data reliability and consistency, as any change to the data is immediately propagated to the main memory. However, the trade-off is that write operations can be slower compared to other caching strategies (like write-back cache), because every write operation has to be done twice – once to the cache, and once to the main memory.</p><p><em>What is a sequencer?</em></p><p>Sequencer is an opaque byte-string that describes the state of the lock immediately after acquisition. It contains the name of the lock, the mode in which it was acquired (exclusive or shared), and the lock generation number.</p><p>Client can get a sequencer from the corresponding <em>handle</em>, the client passes the sequencer to servers (such as file servers) if it expects the operation to be protected by the lock. The recipient server is expected to test whether the sequencer is still valid and has the appropriate mode.</p><h2 id="Analyze">Analyze</h2><h3 id="Key-Features">Key Features</h3><ul><li>provide coarse-grained locking as well as reliable storage for a loosely-coupled distributed system.</li><li>the design emphasis is on availability and reliability, as opposed to high performance</li></ul><h3 id="Two-Questions">Two Questions</h3><h4 id="Why-a-lock-service-among-a-client-library">Why a lock service among a client library ?</h4><ol><li>Our developers sometimes do not plan for high availability in the way one would wish, a lock server makes it easier to maintain existing program structure and communication patterns.</li><li>Many of our services that elect a primary or that partition data between their components need a mechanism for advertising the results. The lock service itself is well-suited for this task, both because this reduces the number of servers on which a client depends, and because the consistency features of the protocol are shared.</li><li>A lock-based interface is more familiar to our programmers.</li><li>A lock service reduces the number of servers needed for a reliable client system to make progress.</li></ol><h4 id="Why-coarse-grained-locks-over-fine-grained-ones">Why coarse-grained locks over fine-grained ones ?</h4><ol><li>Coarse-grained locks impose far less load on the lock server.</li><li>It is good for coarsegrained locks to survive lock server failures, there is little concern about the overhead of doing so.</li><li>It is straightforward for clients to implement their own fine-grained locks tailored to their application.</li><li>An application might partition its locks into groups and use Chubby’s coarse-grained locks to allocate these lock groups to application-specific lock servers.</li></ol><h3 id="Basic-Structures">Basic Structures</h3><h4 id="System-View">System View</h4><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231031162256235.png" alt="image-20231031162256235"></p><ul><li>A Chubby <em>cell</em> consists of a small set of servers (typically five) known as replicas, placed so as to reduce the likelihood of correlated failure.</li><li>Only the master initiates reads and writes of this database.</li><li>Read requests are satisfied by the master alone.</li><li>Clients can find the master by sending master location requests to the replicas listed in the DNS.</li><li>The current master polls the DNS periodically and eventually notices the replica’s change (like failed and then being replaced).</li></ul><h4 id="Data-View">Data View</h4><p>Chubby exports a file system interface similar to, but simpler than that of UNIX. It consists of a strict tree of files and directories in the usual way, with name components separated by slashes.</p><p>The design differs from UNIX in a ways that ease distribution. To allow the files in different directories to be served from different Chubby masters, we do not expose operations that can move files from one directory to another, we do not maintain directory modified times, and we avoid path-dependent permission semantics (that is, access to a file is controlled by the permissions on the file itself rather than on directories on the path leading to the file).</p><ul><li>The name space contains only files and directories, collectively called <em>nodes</em>.</li><li>Nodes may be either permanent or ephemeral.</li><li>Each node has various meta-data, including three names of access control lists (ACLs) used to control reading, writing and changing the ACL names for the node.</li><li>ACLs are themselves files located in an ACL directory, which is a well-known part of the cell’s local name space.</li><li>Clients open nodes to obtain <em>handles</em> that are analogous to UNIX file descriptors.</li></ul><h3 id="The-distribute-lock">The distribute lock</h3><p>分布式锁的问题其实包含三个部分，分别是</p><ul><li>一致性协议</li><li>分布式锁的实现</li><li>分布式锁的使用</li></ul><p>三个部分自下而上完成了在分布式环境中对锁需求，下面将从这三个方面介绍 Chubby 的设计。</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/lock.png" alt="Lock"></p><h4 id="Consensus-Protocol">Consensus Protocol</h4><p>一致性协议其实并不是锁需求直接相关的，假设我们有一个永不宕机的节点和永不中断的网络，那么一个单点的存储即可支撑上层的锁的实现及使用。但这种假设在互联网环境中是不现实的，所以才引入了一致性协议，来保证我们可以通过副本的方式来容忍节点或网络的异常，同时又不引起正确性的风险，作为一个整体对上层提供高可用的服务。</p><p>Chubby 采用的是一个有强主的 Multi-Paxos，其概要实现如下：</p><ul><li>多个副本组成一个集群，副本通过一致性协议选出一个 Master，集群在一个确定的租约时间内保证这个 Master 的领导地位；</li><li>Master周期性的向所有副本刷新延长自己的租约时间；</li><li>每个副本通过一致性协议维护一份数据的备份，而只有Master可以发起读写操作；</li><li>Master挂掉或脱离集群后，其他副本发起选主，得到一个新的Master；</li></ul><blockquote><p>可以近似看做一个不会宕机不会断网的节点，能保证所有成功写入的操作都能被后续成功的读取读到。</p></blockquote><h4 id="The-Implement">The Implement</h4><h5 id="Interface">Interface</h5><p>Chubby 的对外接口是外部使用者直接面对的使用 Chubby 的方式，是连接分布式锁的实现及使用之间的桥梁：</p><ul><li>Chubby 提供类似 UNIX 文件系统的数据组织方式，包括<em>Files</em>和<em>Directory</em>来存储数据或维护层级关系，统称 <em>Node</em>；提供跟 Client 同生命周期的 <em>Ephemeral</em> 类型 Node 来方便实现节点存活监控；通过类似于 UNIX 文件描述符的 <em>Handle</em> 方便对 Node 的访问；Node 除记录数据内容外还维护如 ACL、版本号及 Checksum 等 <em>metadata</em>。</li><li>提供众多方便使用的<strong>API</strong>，包括获取及关闭 Handle 的 Open 及 Close 接口；获取释放锁的 Aquire，Release 接口；读取和修改 Node 内容的 GetContentAndStat，SetContent，Delete 接口；以及其他访问元信息、Sequencer，ACL 的相关接口。</li><li>提供 <em>Event</em> 的事件通知机制来避免客户端轮训的检查数据或 Lock 的变化。包括 Node 内容变化的事件；子 Node 增删改的事件；Chubby 服务端发生故障恢复的事件；Handle 失效事件。客户端收到事件应该做出对应的响应。</li></ul><h5 id="Lock">Lock</h5><p>每一个 File 或者 Directory 都可以作为读写锁使用，接受用户的 Aquire，Release 等请求。锁依赖下层的一致性服务来保证其操作顺序。Chubby 提供的是 <strong>Advisory Lock</strong> 的实现，相对于 <strong>Mandatory Lock</strong>，由于可以访问加锁 Node 的数据而方便数据共享及管理调试。分布式锁面对的最大挑战来自于客户端节点和网络的不可靠，Chubby 提供了两种锁实现的方式：</p><p><em>完美实现</em>：</p><ul><li>Aquire Lock 的同时，Master 生成一个包含 Lock 版本号和锁类型的 Sequencer；</li><li>Chubby Server 在 Lock 相关节点的元信息中记录这个版本号，Lock 版本号会在每次被成功 Aquire 时加一；</li><li>成功 Aquire Lock 的 Handle 中也会记录这个 Sequencer；</li><li>该 Handle 的后续操作都可以通过比较元信息中的 Lock 版本号和 Sequencer 判断锁是否有效，从而接受或拒绝；</li><li>用户直接调用 Release 或 Handle 由于所属 Client Session 过期而失效时，锁被释放并修改对应的元信息。</li></ul><p><em>简易实现</em>：</p><ul><li>Handle Aquire Lock 的同时指定一个叫做 lock-delay 的时长；</li><li>获得 Lock 的 Handle 可以安全的使用锁功能，而不需要获得 Sequencer；</li><li>获得 Lock 的 Handle 失效后，Server 会在 lock-delay 的时间内拒绝其他加锁操作。</li><li>而正常的 Release 操作释放的锁可以立刻被再次获取；</li><li>注意，用户需要保证在指定的 lock-delay 时间后不会再有依赖锁保护的操作；</li></ul><p>对比两种实现方式，简易版本可以使用在无法检查 Sequencer 的场景从而更一般化，但也因为 lock-delay 的设置牺牲了一定的可用性，同时需要用户在业务层面保证 lock-delay 之后不会再有依赖锁保护的操作。</p><h5 id="Cache">Cache</h5><p>Chubby 对自己的定位是需要支持大量的 Client，并且读请求远大于写请求的场景，因此引入一个对读请求友好的 Client 端 Cache，来减少大量读请求对 Chubby Master 的压力便十分自然，客户端可以完全不感知这个 Cache 的存在。Cache 对读请求的极度友好体现在它牺牲写性能实现了一个一致语义的 Cache：</p><ul><li>Cache 可以缓存几乎所有的信息，包括数据，数据元信息，Handle 信息及 Lock；</li><li>Master 收到写请求时，会先阻塞写请求，通过返回所有客户端的 KeepAlive 来通知客户端 Invalid 自己的 Cache；</li><li>Client 直接将自己的 Cache 清空并标记为 Invalid，并发送 KeepAlive 向 Master 确认；</li><li>Master 收到所有 Client 确认或等到超时后再执行写请求。</li></ul><h5 id="Session-and-KeepAlive">Session and KeepAlive</h5><p>Session 可以看做是 Client 在 Master 上的一个投影，Master 通过 Session 来掌握并维护 Client：</p><ul><li>每个 Session 包括一个租约时间，在租约时间内 Client 是有效的，Session 的租约时间在 Master 视角和 Client 视角由于网络传输时延及两端的时钟差异可能略有不同；</li><li>Master 和 Client 之间通过 KeepAlive 进行通信，Client 发起 KeepAlive，会被 Master 阻塞在本地，直到 Session 租约临近过期，此时 Master 会延长租约时间，并返回阻塞的 KeepAlive 通知 Client。除此之外，Master 还可能在 Cache 失效或 Event 发生时返回 KeepAlive；</li><li>Master 除了正常的在创建连接及租约临近过期时延长租约时间外，故障恢复也会延长 Session 的租约；</li><li>Client 的租约过期会先阻塞本地的所有请求，进入 jeopardy 状态，等待额外的45s，以期待与 Master 的通信恢复。如果事与愿违，则返回用户失败。</li></ul><p>Session 及 KeepAlive 给了 Chubby Server 感知和掌握 Client 存活的能力，这对锁的实现也是非常重要的，因为这给了 Master 一个判断是否要释放失效 Lock 的时机。最后总结下，这些机制之间的关系，如下图：</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/mechansim.png" alt="Chubby Mechansim"></p><h4 id="The-Usage">The Usage</h4><p>锁的使用跟上面提到的锁的实现是紧密相关的，由于客户端节点及网络的不可靠，即使 Chubby 提供了直观如 Aquire，Realease 这样的锁操作，使用者仍然需要做出更多的努力来配合完成锁的语义，Chubby 论文中以一个选主场景对如何使用锁给出了详细的说明，以完美方案为例：</p><ul><li>所有 Primary 的竞争者，<strong>Open</strong> 同一个 Node，之后用得到的 Handle 调用 <strong>Aquire</strong> 来获取锁；</li><li>只有一个成功获得锁，成为 Primary，其他竞争者称为 Replicas；</li><li>Primary 将自己的标识通过 <strong>SetContent</strong> 写入 Node；</li><li>Replicas 调用 <strong>GetContentsAndStat</strong> 获得当前的 Primary 标识，并注册该 Node 的内容修改 Event，以便发现锁的 Release 或 Primary 的改变；</li><li>Primary 调用 <strong>GetSequencer</strong> 从当前的 Handle 中获得 sequencer，并将其传递给所有需要锁保护的操作的 Server；</li><li>Server 通过 <strong>CheckSequencer</strong> 检查其 sequencer 的合法性，拒绝旧的 Primary 的请求。</li></ul><p>如果是简单方案，则不需要 Sequencer，但需要在 <strong>Aquire</strong> 操作时指定 lock-delay，并保证所有需要锁保护的操作会在最后一次 Session 刷新后的 lock-delay 时间内完成。</p><h2 id="References">References</h2><ul><li><a href="http://catkang.github.io/2017/09/29/chubby.html">Chubby的锁服务</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Distributed</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PaperNote</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Paper Note: BigTable</title>
    <link href="/2023/10/30/Papers/bigtable/"/>
    <url>/2023/10/30/Papers/bigtable/</url>
    
    <content type="html"><![CDATA[<h2 id="FAQ">FAQ</h2><p><em>What is a single-row transaction?</em></p><p>在 Bigtable 变更（例如读取、写入和删除请求）中，行级更改始终属于原子操作。这包括对单行中的多个列进行的变更，前提是它们包含在同一变更操作中。Bigtable 不支持以原子方式更新多个行的事务。</p><p>但是，Bigtable 支持某些需要在其他数据库中执行事务的写入操作。实际上，Bigtable 使用单行事务来完成这些操作。这些操作包括读取和写入操作，且所有读取和写入均以原子方式执行，但仍然只是在行级的原子操作：</p><ul><li><strong>读取-修改-写入 (Read-modify-write) 操作</strong>（包括增量和附加）。在读取-修改-写入 (read-modify-write) 操作中，Cloud Bigtable 会读取现有值，对现有值进行增量或附加操作，并将更新后的值写入表中。</li><li><strong>检查并更改 (Check-and-mutate) 操作</strong>（也称为条件更改或条件写入）。在检查并更改 (check-and-mutate) 操作中，Bigtable 会对行进行检查以了解其是否符合指定条件。如果符合条件，Bigtable 则会将新值写入该行中。</li></ul><p><em>What is SSTable format?</em></p><p>SSTable (Sorted Strings Table) is a file format used in Apache Cassandra, a popular NoSQL database. An SSTable is a data structure that provides a persistent, ordered immutable map from keys to values, where both keys and values are arbitrary byte streams. It contains a series of key-value pairs sorted by keys, which enables efficient lookup and range queries. It’s used to store and retrieve data in a highly optimized manner. The SSTable also supports internal indexing, which makes accessing a particular data point faster.</p><h2 id="Analyze">Analyze</h2><h3 id="Key-Features">Key Features</h3><ul><li>A distributed storage system for managing structured data</li><li>Scalability</li><li>High performance</li><li>High availability</li></ul><h3 id="Basic-Structures">Basic Structures</h3><h4 id="Data-View">Data View</h4><ul><li>A Bigtable cluster stores a number of tables.</li><li>Each table consists of a set of tablets.</li><li>Each tablet contains all data associated with a row range.</li><li>Each row range is called a tablet, which is the unit of distribution and load balancing.</li><li>The Google <em>SSTable</em> file format is used internally to store Bigtable data.</li><li>Each SSTable contains a sequence of blocks (typically each block is 64 KB in size, but this is configurable). A block index (stored at the end of the SSTable) is used to locate blocks.</li></ul><h4 id="System-View">System View</h4><ul><li>Bigtable uses the distributed Google File System (GFS) to store log and data files.</li><li>Bigtable relies on a highly-available and persistent distributed lock service called Chubby.<ul><li>to ensure that there is at most one active master at any time</li><li>to store the bootstrap location of Bigtable data</li><li>to discover tablet servers and finalize tablet server deaths</li><li>to store Bigtable schema information (the column family information for each table)</li><li>to store access control lists</li></ul></li></ul><p>Three components:</p><ul><li>A library that is linked into every client.</li><li>One master server.</li><li>Many tablet servers.</li></ul><p>The master is responsible for assigning tablets to tablet servers, detecting the addition and expiration of tablet servers, balancing tablet-server load, and garbage collection of files in GFS.</p><p>Each tablet server manages a set of tablets (typically we have somewhere between ten to a thousand tablets per tablet server).</p><h3 id="Basic-Operations">Basic Operations</h3><h4 id="Locate-a-Tablet">Locate a Tablet</h4><p>有点像多级页表的结构：Chubby 中存储了 Root tablet 的位置信息，Root tablet 中存储了其他 METADATA tablet 的位置信息，METADATA tablet 中存储了所有其他 User Table 的信息。</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231030194906112.png" alt="image-20231030194906112"></p><p>用户端会缓存 tablet 的位置信息，如果一开始没有，就会沿着上图的这个结构层次去寻找。</p><h4 id="Tablet-Assignment">Tablet Assignment</h4><p>Bigtable uses Chubby to keep track of tablet servers. When a tablet server starts, it creates, and acquires an exclusive lock on, a uniquely-named file in a specific Chubby directory. The master monitors this directory (the <em>servers</em> directory) to discover tablet servers.</p><p>When a master is started:</p><ol><li>The master grabs a unique master lock in Chubby.</li><li>The master scans the <em>servers</em> directory in Chubby to find the live servers.</li><li>The master communicates with every live tablet server to discover what tablets are already assigned to each server.</li><li>The master scans the METADATA table to learn the set of tablets.</li><li>Whenever this scan encounters a tablet that is not already assigned, the master adds the tablet to the set of unassigned tablets, which makes the tablet eligible for tablet assignment.</li></ol><h4 id="Read-Request">Read Request</h4><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231030200933745.png" alt="image-20231030200933745"></p><p>Steps:</p><ol><li>Check for well-formedness and proper authorization.</li><li>Seek in memtable</li><li>If not found, seek in SSTable Files from new to old. First use bloom filter to decide whether the data resides in the file, if true, look into the sparse index to find an approriate block, then perform a disk read.</li></ol><h4 id="Write-Request">Write Request</h4><p>Steps:</p><ol><li>Check for well-formedness and proper authorization.</li><li>A valid mutation is written to the commit log.</li><li>After the write has been committed, its contents are inserted into the memtable.</li></ol><h4 id="Compactions">Compactions</h4><p>Three kinds of compactions are mentioned:</p><ul><li><em>minor compaction</em><ul><li>When the memtable size reaches a threshold, the memtable is frozen, a new memtable is created, and the frozen memtable is converted to an SSTable and written to GFS.</li></ul></li><li><em>merging compaction</em><ul><li>A merging compaction reads the contents of a few SSTables and the memtable, and writes out a new SSTable.</li></ul></li><li><em>major compaction</em><ul><li>A merging compaction that rewrites all SSTables into exactly one SSTable.</li></ul></li></ul><h3 id="Performance">Performance</h3><h4 id="Locality-groups">Locality groups</h4><p>Clients can group multiple column families together into a locality group. A separate SSTable is generated for each locality group in each tablet.</p><p>For example:</p><p>Page metadata in Webtable can be in one locality group, and the contents of the page can be in a different group: an application that wants to read the metadata does not need to read through all of the page contents.</p><h4 id="Caching-for-read-performance">Caching for read performance</h4><p>Two levels of caching:</p><ul><li><em>The Scan Cache</em><ul><li>caches the key-value pairs returned by the SSTable interface to the tablet server code.</li><li>useful for applications that tend to read the same data repeatedly.</li></ul></li><li><em>The Block Cache</em><ul><li>caches SSTables blocks that were read from GFS.</li><li>useful for applications that tend to read data that is close to the data they recently read.</li></ul></li></ul><h4 id="Commit-log-implementation">Commit-log implementation</h4><p>原本是每个 tablet 都有自己的提交日志，这样对底层的 GFS 不友好，相当于每时每刻都在做大量不同文件的顺序写操作（某种程序上就相当于是随机写了），破坏了 SSTable 顺序写的特性，会造成严重的性能开销。</p><p>所以作者决定每一台 tablet server 只有一个提交日志，即所有的 tablets 共享该日志。有一个问题是当服务器失效后，假设有其他 100 台服务器要重新分配之前的 tablets，那么这个日志就会被读取 100 次。解决方法就是按照 <code>〈table, row name, log sequence number〉</code> 先排个序，这样每个服务器就只会读相应的一部分。</p><p>所以在 minor compaction 时，当 memtable 写入到磁盘时 commit log 并不会被清空，而是更新 redo point，即重新记录该 tablet 的 memtable 对应的日志开始的地方。重建 memtable 时就从 redo point 那里开始重新应用对应的更改。</p>]]></content>
    
    
    <categories>
      
      <category>Distributed</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PaperNote</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Paper Note: MapReduce</title>
    <link href="/2023/10/30/Papers/mapreduce/"/>
    <url>/2023/10/30/Papers/mapreduce/</url>
    
    <content type="html"><![CDATA[<h2 id="Analyze">Analyze</h2><h3 id="Key-Features">Key Features</h3><ul><li>Processing and generating large data sets.</li><li>Exploits a restricted programming model to parallelize the user program automatically and to provide transparent fault-tolerance.</li></ul><h4 id="Details">Details</h4><p>By distributing the workload to many machines and let them execute the tasks in parallel.</p><p>Specifically, input files are split into <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> pieces and master assign each one to an idle worker. Worker process it with the <em>map</em> function and save each key/value pair to one of the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span> files according to the partioning function. When finishing processing all <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> pieces, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span> reduce workers will read data from the corresponding intermediate files, process it with the <em>reduce</em> function and save to output file eventually.</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231029205513215.png" alt="image-20231029205513215"></p><h4 id="Limit">Limit</h4><p>Task has to fit in the form of <em>map</em> and <em>reduce</em>.</p><h3 id="Reliability">Reliability</h3><p>It can tolerant both worker and master failures.</p><h4 id="How">How</h4><p>The master will send heartbeat to the workers, a worker will be marked as failed when there is no response received by the master in a certain amount of time, and its task will be rescheduled.</p><p>MapReduce is resilient to large-scale worker failures, if there are workers alive, the progress can be prompted.</p><p>However, if master fails, Google’s choice is to abort the MapReduce computation. To achieve reliability, we can store the state on ZooKeeper or etcd, or just write periodic checkpoints to local disk.</p><p>When the master has seen more than one failure on a particular record, it indicates that the record should be skipped when it issues the next re-execution of the corresponding Map or Reduce task.</p><h3 id="Performance">Performance</h3><p>High</p><h4 id="Several-Tricks">Several Tricks</h4><p><em>Backup Tasks</em></p><p>When a MapReduce operation is close to completion, the master schedules backup executions of the remaining <em>in-progress</em> tasks.</p><p><em>Locality</em></p><p>Network bandwidth is a relatively scarce resource. When running large MapReduce operations on a significant fraction of the workers in a cluster, most input data is read locally and consumes no network bandwidth.</p><h3 id="Scalability">Scalability</h3><p>High.</p><p>More machines, better performance.</p><h2 id="References">References</h2><ul><li><a href="https://tanxinyu.work/mapreduce-thesis/">Blog</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Distributed</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PaperNote</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Paper Note: ZooKeeper</title>
    <link href="/2023/10/30/Papers/zookeeper/"/>
    <url>/2023/10/30/Papers/zookeeper/</url>
    
    <content type="html"><![CDATA[<h2 id="Analyze">Analyze</h2><h3 id="Key-Features">Key Features</h3><ul><li>Coordination in large-scale distributed systems by providing general “coordination kernel” APIs that support a lot of use cases.</li><li>Good performance</li><li>Fault tolerance / high availability</li></ul><h4 id="Details">Details</h4><p>ZooKeeper can be used for group messaging, shared registers, and distributed lock services.</p><h3 id="Reliability">Reliability</h3><p>By replicating the ZooKeeper data on each server that compses the service.</p><p>The data is periodically snapshotted.</p><h4 id="Fuzzy-Snapshot">Fuzzy Snapshot</h4><p>We do not lock the ZooKeeper state to take the snapshot.</p><p>Because of the orders guaranteed by ZooKeeper and the changes are idempotent, we can snapshot an intermediate state and convert it to a final state by just applying the state changes in order.</p><h3 id="Performance">Performance</h3><p>A trade-off: Weaken consistency to gain better performance.</p><ul><li>Write request should be redirected to the leader.</li><li>Read request can be processed locally in each replica.<ul><li>Could read stale data.</li></ul></li><li>More servers, bigger read throughput.</li></ul><p>Guaranteeing FIFO client order enables clients to submit operations asynchronously. With asynchronous operations, a client is able to have multiple outstanding operations at a time.</p><p>To detect when a tablet server is no longer serving its tablets, the master periodically asks each tablet server for the status of its lock.</p>]]></content>
    
    
    <categories>
      
      <category>Distributed</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PaperNote</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>DDIA: Chapter 7 Transactions</title>
    <link href="/2023/10/29/Books/Design%20Data-Intensive%20Applications/chapter-7-transactions/"/>
    <url>/2023/10/29/Books/Design%20Data-Intensive%20Applications/chapter-7-transactions/</url>
    
    <content type="html"><![CDATA[<p>A transaction is a way for an application to group several reads and writes together into a logical unit.</p><p>Transactions are not a law of nature; they were created with a purpose, namely to <em>simplify the programming model</em> for applications accessing a database.</p><blockquote><p>相当于数据库提供了一层重要的抽象，在编写应用程序时不用再去考虑那些能被事务处理的错误与问题了。</p></blockquote><h2 id="The-Meaning-of-ACID">The Meaning of ACID</h2><p>The safety guarantees provided by transactions are often described by the well known acronym ACID, which stands for <em>Atomicity</em>, <em>Consistency</em>, <em>Isolation</em>, and <em>Durability</em>.</p><blockquote><p>However, in practice, one database’s implementation of ACID does not equal another’s implementation. The high-level idea is sound, but the devil is in the details. ACID has unfortunately become mostly a marketing term.</p></blockquote><blockquote><p>Systems that do not meet the ACID criteria are sometimes called BASE, which stands for <em>Basically Available</em>, <em>Soft state</em>, and <em>Eventual consistency</em>. This is even more vague than the definition of ACID. It seems that the only sensible definition of BASE is “not ACID”; i.e., it can mean almost anything you want.)</p></blockquote><h3 id="Atomicity">Atomicity</h3><blockquote><p>“All or nothing”</p></blockquote><p>If the writes are grouped together into an atomic transaction, and the transaction cannot be completed (<em>committed</em>) due to a fault, then the transaction is <em>aborted</em> and the database must discard or undo any writes it has made so far in that transaction.</p><p>Atomicity simplifies this problem: if a transaction was aborted, the application can be sure that it didn’t change anything, so it can safely be retried.</p><p><strong>The ability to abort a transaction on error and have all writes from that transaction discarded is the defining feature of ACID atomicity.</strong></p><h3 id="Consistency">Consistency</h3><blockquote><p>“It looks correct to me”</p></blockquote><p>The word <em>consistency</em> is terribly overloaded:</p><ul><li>Discussed <em>replica consistency</em> and the issue of <em>eventual consistency</em> that arises in asynchronously replicated systems.</li><li><em>Consistent hashing</em> is an approach to partitioning that some systems use for rebalancing.</li><li>In the CAP theorem, the word <em>consistency</em> is used to mean <em>linearizability</em>.</li><li>In the context of ACID, <em>consistency</em> refers to an application-specific notion of the database being in a “good state.”</li></ul><p>The idea of ACID consistency is that you have certain statements about your data (invariants) that must always be true.</p><p>For example, in an accounting system, credits and debits across all accounts must always be balanced.</p><p>This idea of consistency depends on the application’s <strong>notion of invariants</strong>, and <strong>it’s the application’s responsibility to define its transactions correctly so that they preserve consistency</strong>.</p><p><strong>Atomicity, isolation, and durability are properties of the database, whereas consistency (in the ACID sense) is a property of the application.</strong></p><p>The application may rely on the database’s atomicity and isolation properties in order to achieve consistency, but it’s not up to the database alone. Thus, the letter C doesn’t really belong in ACID.</p><h3 id="Isolation">Isolation</h3><blockquote><p>“As if alone”</p></blockquote><p><em>Isolation</em> in the sense of ACID means that concurrently executing transactions are isolated from each other: they cannot step on each other’s toes. The classic database textbooks formalize isolation as <em>serializability</em>, which means that each transaction can pretend that it is the only transaction running on the entire database.</p><p>The database ensures that when the transactions have committed, the result is the same as if they had run <em>serially</em> (one after another), even though in reality they may have run concurrently.</p><h3 id="Durability">Durability</h3><blockquote><p>“Survive failures”</p></blockquote><p><em>Durability</em> is the promise that once a transaction has committed successfully, any data it has written will not be forgotten, even if there is a hardware fault or the database crashes.</p><h2 id="Single-Object-and-Multi-Object-Operations">Single-Object and Multi-Object Operations</h2><p>In ACID, atomicity and isolation describe what the database should do if a client makes several writes within the same transaction:</p><ul><li><em>Atomicity</em><ul><li>If an error occurs halfway through a sequence of writes, the transaction should be aborted, and the writes made up to that point should be discarded.</li><li>In other words, the database saves you from having to worry about partial failure, by giving an <em>all-or-nothing</em> guarantee.</li></ul></li><li><em>Isolation</em><ul><li>Concurrently running transactions shouldn’t interfere with each other.</li></ul></li></ul><p>Such <em>multi-object transactions</em> are often needed if several pieces of data need to be kept in sync.</p><h3 id="Single-object-writes">Single-object writes</h3><blockquote><p>“Transactions should be introduced when write large objects into database.”</p></blockquote><p>Atomicity and isolation also apply when a single object is being changed. For example, imagine you are writing a 20 KB JSON document to a database.</p><p>Atomicity can be implemented using a log for crash recovery, and isolation can be implemented using a lock on each object (allowing only one thread to access an object at any one time).</p><h3 id="The-need-for-multi-object-transactions">The need for multi-object transactions</h3><p>However, in many other cases writes to several different objects need to be coordinated:</p><ul><li>In a relational data model, a row in one table often has a foreign key reference to a row in another table. Multi-object transactions allow you to ensure that these references remain valid.</li><li>When denormalized information needs to be updated, you need to update several documents in one go. Transactions are very useful in this situation to prevent denormalized data from going out of sync.</li><li>In databases with secondary indexes (almost everything except pure key-value stores), the indexes also need to be updated every time you change a value.</li></ul><h3 id="Handling-errors-and-aborts">Handling errors and aborts</h3><blockquote><p>“Retrying is not perfect.”</p></blockquote><p>Retrying an aborted transaction is a simple and effective error handling mechanism, it isn’t perfect:</p><ul><li>If the transaction actually succeeded, but the network failed while the server tried to acknowledge the successful commit to the client (so the client thinks it failed), then retrying the transaction causes it to be performed twice — <strong>unless you have an additional application-level deduplication mechanism in place</strong>.</li><li>If the error is due to overload, retrying the transaction will make the problem worse, not better.</li><li>If the transaction also has side effects outside of the database, those side effects may happen even if the transaction is aborted.</li><li>If the client process fails while retrying, any data it was trying to write to the database is lost.</li></ul><h2 id="Weak-Isolation-Levels">Weak Isolation Levels</h2><blockquote><p>“Stronger isolation, worse performance.”</p></blockquote><p>If two transactions don’t touch the same data, they can safely be run in parallel, because neither depends on the other.</p><p>Databases have long tried to hide concurrency issues from application developers by providing <em>transaction isolation</em>. In theory, isolation should make your life easier by letting you pretend that no concurrency is happening.</p><p><em>Serializable</em> isolation means that the database guarantees that transactions have the same effect as if they ran <em>serially</em> (i.e., one at a time, without any concurrency). However, serializable isolation has a performance cost, and many databases don’t want to pay that price.</p><p>It’s therefore common for systems to use weaker levels of isolation, which protect against some concurrency issues, but not all.</p><h3 id="Read-Committed">Read Committed</h3><blockquote><p>“No dirty reads and no dirty writes.”</p></blockquote><p>The most basic level of transaction isolation is <em>read committed</em>. It makes two guarantees:</p><ol><li>When reading from the database, you will only <strong>see data that has been committed</strong> (<em>no dirty reads</em>).</li><li>When writing to the database, you will only <strong>overwrite data that has been committed</strong> (<em>no dirty writes</em>).</li></ol><h4 id="No-dirty-reads">No dirty reads</h4><blockquote><p>“Any writes by a transaction only become visible to others when that transaction commits”</p></blockquote><p>Imagine a transaction has written some data to the database, but the transaction has not yet committed or aborted. Can another transaction see that uncommitted data? If yes, that is called a <em>dirty read</em>.</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231027210404555.png" alt="image-20231027210404555"></p><h4 id="No-dirty-writes">No dirty writes</h4><p>Transactions running at the read committed isolation level must prevent dirty writes, usually by delaying the second write until the first write’s transaction has committed or aborted.</p><blockquote><p>With dirty writes, conflicting writes from different transactions can be mixed up.</p></blockquote><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231027210613103.png" alt="image-20231027210613103"></p><h4 id="Implementing-read-committed">Implementing read committed</h4><p>Most commonly, databases prevent dirty writes by using row-level locks: when a transaction wants to modify a particular object (row or document), it must first acquire a lock on that object. It must then hold that lock until the transaction is committed or aborted.</p><p>How about dirty reads?</p><p>One option would be to use the same lock, but it is not practicing, since one long-running write transaction can force many read-only transactions to wait until the long-running transaction has completed.</p><p>Another approach is better: For every object that is written, the database remembers both the old committed value and the new value set by the transaction that currently holds the write lock. While the transaction is ongoing, any other transactions that read the object are simply given the old value. Only when the new value is committed do transactions switch over to reading the new value.</p><h3 id="Snapshot-Isolation-and-Repeatable-Read">Snapshot Isolation and Repeatable Read</h3><p>However, there are still plenty of ways in which you can have concurrency bugs when using this isolation level:</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231027211047138.png" alt="image-20231027211047138"></p><p>This anomaly is called a <em>nonrepeatable</em> read or <em>read skew</em>: if Alice were to read the balance of account 1 again at the end of the transaction, she would see a different value ($600) than she saw in her previous query.</p><p>Read skew is considered acceptable under read committed isolation: the account balances that Alice saw were indeed committed at the time when she read them.</p><p>In Alice’s case, this is not a lasting problem, because she will most likely see consistent account balances if she reloads the online banking website a few seconds later.</p><p><em>Snapshot isolation</em> is the most common solution to this problem. The idea is that each transaction reads from a <em>consistent snapshot</em> of the database—that is, the transaction sees all the data that was committed in the database at the start of the transaction.</p><h4 id="Implementing-snapshot-isolation">Implementing snapshot isolation</h4><p>From a performance point of view, a key principle of snapshot isolation is <em>readers never block writers, and writers never block readers</em>.</p><p>To implement snapshot isolation, databases use a generalization of the mechanism. The database must potentially keep several different committed versions of an object, because various in-progress transactions may need to see the state of the database at different points in time. Because it maintains several versions of an object side by side, this technique is known as <em>multiversion concurrency control</em> (MVCC).</p><p>If a database only needed to provide read committed isolation, but not snapshot isolation, it would be sufficient to keep two versions of an object: the committed version and the overwritten-but-not-yet-committed version. However, storage engines that support snapshot isolation typically use MVCC for their read committed isolation level as well. A typical approach is that read committed uses a separate snapshot for each query, while snapshot isolation uses the same snapshot for an entire transaction.</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231027211726343.png" alt="image-20231027211726343"></p><p>With append-only B-trees, every write transaction (or batch of transactions) creates a new B-tree root, and a particular root is a consistent snapshot of the database at the point in time when it was created.</p><h3 id="Preventing-Lost-Updates">Preventing Lost Updates</h3><p>There are several other interesting kinds of conflicts that can occur between concurrently writing transactions. The best known of these is the <em>lost update</em> problem, illustrated below:</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231027212233622.png" alt="image-20231027212233622"></p><p>The lost update problem can occur if an application reads some value from the database, modifies it, and writes back the modified value (a <em>read-modify-write</em> cycle).</p><p>This pattern occurs in various different scenarios:</p><ul><li>Incrementing a counter or updating an account balance。</li><li>Making a local change to a complex value, e.g., adding an element to a list within a JSON document (requires parsing the document, making the change, and writing back the modified document)</li><li>Two users editing a wiki page at the same time, where each user saves their changes by sending the entire page contents to the server, overwriting whatever is currently in the database.</li></ul><p>Because this is such a common problem, a variety of solutions have been developed.</p><h4 id="Atomic-write-operations">Atomic write operations</h4><p>Many databases provide atomic update operations, which remove the need to implement read-modify-write cycles in application code. They are usually the best solution if your code can be expressed in terms of those operations.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">UPDATE</span> counters <span class="hljs-keyword">SET</span> <span class="hljs-keyword">value</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">value</span> <span class="hljs-operator">+</span> <span class="hljs-number">1</span> <span class="hljs-keyword">WHERE</span> key <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;foo&#x27;</span>;<br></code></pre></td></tr></table></figure><h4 id="Automatically-detecting-lost-updates">Automatically detecting lost updates</h4><p>An alternative is to allow them to execute in parallel and, if the transaction manager detects a lost update, abort the transaction and force it to retry its read-modify-write cycle.</p><h4 id="Compare-and-set">Compare-and-set</h4><p>The purpose of this operation is to avoid lost updates by allowing an update to happen only if the value has not changed since you last read it.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- This may or may not be safe, depending on the database implementation </span><br><span class="hljs-keyword">UPDATE</span> wiki_pages <span class="hljs-keyword">SET</span> content <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;new content&#x27;</span> <span class="hljs-keyword">WHERE</span> id <span class="hljs-operator">=</span> <span class="hljs-number">1234</span> <span class="hljs-keyword">AND</span> content <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;old content&#x27;</span>;<br></code></pre></td></tr></table></figure><h4 id="Conflict-resolution-and-replication">Conflict resolution and replication</h4><p>Locks and compare-and-set operations assume that there is a single up-to-date copy of the data. However, databases with multi-leader or leaderless replication usually allow several writes to happen concurrently and replicate them asynchronously, so they cannot guarantee that there is a single up-to-date copy of the data.</p><p>A common approach in such replicated databases is to allow concurrent writes to create several conflicting versions of a value (also known as siblings), and to <strong>use application code</strong> or special data structures to resolve and merge these versions after the fact.</p><h3 id="Write-Skew-and-Phantoms">Write Skew and Phantoms</h3><p>This is an example of <em>write skew</em>:</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231027212947963.png" alt="image-20231027212947963"></p><h4 id="Characterizing-write-skew">Characterizing write skew</h4><p>The anomalous behavior was only possible because the transactions ran concurrently.</p><p>You can think of write skew as a generalization of the lost update problem. Write skew can occur if two transactions read the same objects, and then update some of those objects (different transactions may update different objects).</p><p>All of these examples follow a similar pattern:</p><ol><li>A <code>SELECT</code> query checks whether some requirement is satisfied by searching for rows that match some search condition.</li><li>Depending on the result of the first query, the application code decides how to continue.</li><li>If the application decides to go ahead, it makes a write (<code>INSERT</code>, <code>UPDATE</code>, or <code>DELETE</code>) to the database and commits the transaction.</li></ol><p>The effect of this write <strong>changes the precondition</strong> of the decision of step 2. In other words, if you were to repeat the SELECT query from step 1 after commiting the write, you would get a different result, because the write changed the set of rows matching the search condition.</p><p>This effect, where a write in one transaction changes the result of a search query in another transaction, is called a <em>phantom</em>. Snapshot isolation avoids phantoms in read-only queries, but in read-write transactions like the examples we discussed, phantoms can lead to particularly tricky cases of write skew.</p><h3 id="Serializability">Serializability</h3><p>Serializable isolation is usually regarded as the strongest isolation level. It guarantees that even though transactions may execute in parallel, the end result is the same as if they had executed one at a time, <em>serially</em>, without any concurrency. In other words, the database prevents all possible race conditions.</p><h4 id="Actual-Serial-Execution">Actual Serial Execution</h4><p>The simplest way of avoiding concurrency problems is to remove the concurrency entirely: to execute only one transaction at a time, in serial order, on a single thread.</p><p>This approach looks silly, but it is definitely valuable:</p><ul><li>RAM became cheap enough that for many use cases is now feasible to keep the entire active dataset in memory. (transactions can execute much faster)</li><li>Database designers realized that OLTP transactions are usually short and only make a small number of reads and writes.</li></ul><p>A system designed for single-threaded execution can sometimes perform better than a system that supports concurrency, because it can avoid the coordination overhead of locking.</p><p>Summary:</p><ul><li>Every transaction must be small and fast, because it takes only one slow transaction to stall all transaction processing.</li><li>It is limited to use cases where the active dataset can fit in memory.</li><li>Write throughput must be low enough to be handled on a single CPU core.</li></ul><h4 id="Two-Phase-Locking-2PL">Two-Phase Locking (2PL)</h4><p>In 2PL, writers don’t just block other writers; they also block readers and vice versa. Snapshot isolation has the mantra <em>readers never block writers, and writers never block readers</em>, which captures this key difference between snapshot isolation and two-phase locking.</p><p>2PL provides serializability, it protects against all the race conditions discussed earlier, including lost updates and write skew.</p><h5 id="Implementation-of-two-phase-locking">Implementation of two-phase locking</h5><p>The lock can either be in <em>shared mode</em> or in <em>exclusive mode</em>. The lock is used as follows:</p><ul><li>If a transaction wants to read an object, it must first acquire the lock in shared mode.</li><li>If a transaction wants to write to an object, it must first acquire the lock in exclusive mode.</li><li>If a transaction first reads and then writes an object, it may upgrade its shared lock to an exclusive lock.</li><li>After a transaction has acquired the lock, it must continue to hold the lock until the end of the transaction (commit or abort).</li></ul><blockquote><p>This is where the name “two phase” comes from: the first phase (while the transaction is executing) is when the locks are acquired, and the second phase (at the end of the transaction) is when all the locks are released.</p></blockquote><h5 id="Performance-of-two-phase-locking">Performance of two-phase locking</h5><p>Transaction throughput and response times of queries are significantly worse under two-phase locking than under weak isolation. This is partly due to the overhead of acquiring and releasing all those locks, but more importantly due to reduced concurrency.</p><p>Although deadlocks can happen with the lock-based read committed isolation level, they occur much more frequently under 2PL serializable isolation。</p><h5 id="Predicate-locks">Predicate locks</h5><p>How to prevent phantoms with serializable isolation?</p><blockquote><p>In the meeting room booking example this means that if one transaction has searched for existing bookings for a room within a certain time window, another transaction is not allowed to concurrently insert or update another booking for the same room and time range.</p></blockquote><p>Conceptually, we need a <em>predicate lock</em>. It works similarly to the shared/exclusive lock described earlier, but rather than belonging to a particular object (e.g., one row in a table), it belongs to <strong>all objects that match some search condition</strong>, such as:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> bookings <br> <span class="hljs-keyword">WHERE</span> room_id <span class="hljs-operator">=</span> <span class="hljs-number">123</span> <span class="hljs-keyword">AND</span> <br>  end_time <span class="hljs-operator">&gt;</span> <span class="hljs-string">&#x27;2018-01-01 12:00&#x27;</span> <span class="hljs-keyword">AND</span> <br>  start_time <span class="hljs-operator">&lt;</span> <span class="hljs-string">&#x27;2018-01-01 13:00&#x27;</span>;<br></code></pre></td></tr></table></figure><p>A predicate lock restricts access as follows:</p><ul><li>If transaction A wants to read objects matching some condition, like in that SELECT query, it must acquire a shared-mode predicate lock on the conditions of the query. If another transaction B currently has an exclusive lock on any object matching those conditions, <strong>A must wait until B releases its lock before it is allowed to make its query</strong>.</li><li>If transaction A wants to insert, update, or delete any object, it must first check whether either the old or the new value matches any existing predicate lock.</li></ul><p>The key idea here is that a predicate lock applies even to objects that do not yet exist in the database, but which might be added in the future (phantoms).</p><h4 id="Serializable-Snapshot-Isolation-SSI">Serializable Snapshot Isolation (SSI)</h4><p>An algorithm called <em>serializable snapshot isolation</em> (SSI) is very promising. It provides full serializability, but has only a small performance penalty compared to snapshot isolation.</p><h5 id="Pessimistic-versus-optimistic-concurrency-control">Pessimistic versus optimistic concurrency control</h5><p>Two-phase locking is a so-called <em>pessimistic</em> concurrency control mechanism: it is based on the principle that if anything might possibly go wrong (as indicated by a lock held by another transaction), it’s better to wait until the situation is safe again before doing anything.</p><p>Serial execution is, in a sense, pessimistic to the extreme: it is essentially equivalent to each transaction having an exclusive lock on the entire database (or one partition of the database) for the duration of the transaction.</p><p>By contrast, serializable snapshot isolation is an <em>optimistic</em> concurrency control technique. Optimistic in this context means that instead of blocking if something potentially dangerous happens, transactions continue anyway, in the hope that everything will turn out all right.</p><p>If there is enough spare capacity, and if contention between transactions is not too high, optimistic concurrency control techniques tend to perform better than pessimistic ones.</p><p>On top of snapshot isolation, SSI adds an algorithm for detecting serialization conflicts among writes and determining which transactions to abort.</p><h5 id="Decisions-based-on-an-outdated-premise">Decisions based on an outdated premise</h5><blockquote><p>“read first then write, indicates the decision of writing may depend on the result of reading.”</p></blockquote><p>We observed a recurring pattern when discussing write skew: a transaction reads some data from the database, examines the result of the query, and decides to take some action (write to the database) based on the result that it saw.</p><p>The transaction is taking an action based on a <em>premise</em> (a fact that was true at the beginning of the transaction.)</p><p>To be safe, the database needs to assume that any change in the query result (the premise) means that writes in that transaction may be invalid.</p><blockquote><p>In other words, there may be <em><strong>a causal dependency</strong></em> between the queries and the writes in the transaction.</p></blockquote><p><strong>In order to provide serializable isolation, the database must detect situations in which a transaction may have acted on an outdated premise and abort the transaction in that case.</strong></p><p>How does the database know if a query result might have changed? There are two cases to consider:</p><ul><li>Detecting reads of a stale MVCC object version (uncommitted write occurred before the read)</li><li>Detecting writes that affect prior reads (the write occurs after the read)</li></ul><h5 id="Detecting-stale-MVCC-reads">Detecting stale MVCC reads</h5><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231029163540054.png" alt="image-20231029163540054"></p><blockquote><p>简单来说，在事务准备提交时，数据库会检查它读过的数据是否发生了改变（即那些数据是不是被其他事务提交过），如果是的话，就中断本次事务。</p></blockquote><p>However, by the time transaction 43 wants to commit, transaction 42 has already committed. This means that the write that was ignored when reading from the consistent snapshot has now taken effect, and transaction 43’s premise is no longer true.</p><p>In order to prevent this anomaly, the database <strong>needs to track when a transaction ignores another transaction’s writes due to MVCC visibility rules</strong>. When the transaction wants to commit, the database checks whether any of the ignored writes have now been committed. If so, the transaction must be aborted.</p><p>注意这种方法只适用于并发写发生在读之前，因为数据库需要跟踪的是那些因为可见性规则被忽略的写操作，如果并发写发生在读之后，是不会有“因为可见性规则被忽略的写操作”的。</p><h5 id="Detecting-writes-that-affect-prior-reads">Detecting writes that affect prior reads</h5><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231029164043852.png" alt="In serializable snapshot isolation, detecting when one transaction modifies another transaction’s reads."></p><p>When a transaction writes to the database, it must look in the indexes for any other transactions that have recently read the affected data. This process is similar to acquiring a write lock on the affected key range, but rather than blocking until the readers have committed, the lock acts as a tripwire: it simply notifies the transactions that the data they read may no longer be up to date.</p><p>Transaction 43 notifies transaction 42 that its prior read is outdated, and vice versa. Transaction 42 is first to commit, and it is successful: although transaction 43’s write affected 42, 43 hasn’t yet committed, so the write has not yet taken effect. However, when transaction 43 wants to commit, the conflicting write from 42 has already been committed, so 43 must abort.</p><h5 id="Performance-of-serializable-snapshot-isolation">Performance of serializable snapshot isolation</h5><p>Compared to two-phase locking, the big advantage of serializable snapshot isolation is that one transaction doesn’t need to block waiting for locks held by another transaction.</p>]]></content>
    
    
    <categories>
      
      <category>Design Data-Intensive Applications</category>
      
    </categories>
    
    
    <tags>
      
      <tag>BookNote</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>DDIA: Chapter 6 Partioning</title>
    <link href="/2023/10/24/Books/Design%20Data-Intensive%20Applications/chapter-6-partioning/"/>
    <url>/2023/10/24/Books/Design%20Data-Intensive%20Applications/chapter-6-partioning/</url>
    
    <content type="html"><![CDATA[<p>The main reason for wanting to partition data is <em>scalability</em>.</p><p>Normally, partitions are defined in such a way that each piece of data (each record, row, or document) belongs to exactly one partition.</p><h2 id="Partitioning-and-Replication">Partitioning and Replication</h2><p>Partitioning is usually <strong>combined with</strong> replication so that copies of each partition are stored on multiple nodes. This means that, even though each record belongs to exactly one partition, it may still be stored on several different nodes for fault tolerance.</p><p>A node may store more than one partition. If a leader–follower replication model is used, the combination of partitioning and replication can look like below. Each partition’s leader is assigned to one node, and its followers are assigned to other nodes. <strong>Each node may be the leader for some partitions and a follower for other partitions.</strong></p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231024201601908.png" alt="image-20231024201601908"></p><h2 id="Partitioning-of-Key-Value-Data">Partitioning of Key-Value Data</h2><blockquote><p>The goal with partitioning is to spread the data and the query load evenly across nodes.</p></blockquote><p>If the partitioning is unfair, so that some partitions have more data or queries than others, we call it <em>skewed</em>. A partition with disproportionately high load is called a <em>hot spot</em>.</p><h3 id="Partitioning-by-Key-Range">Partitioning by Key Range</h3><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231024201851533.png" alt="image-20231024201851533"></p><p>However, the downside of key range partitioning is that certain access patterns can lead to hot spots.</p><h3 id="Partitioning-by-Hash-of-Key">Partitioning by Hash of Key</h3><blockquote><p>“More balanced but lose the ability to range queries.”</p></blockquote><p>Because of this risk of skew and hot spots, many distributed datastores use a hash function to determine the partition for a given key.</p><p>Once you have a suitable hash function for keys, you can assign each partition a range of hashes (rather than a range of keys), and every key whose hash falls within a partition’s range will be stored in that partition.</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231024202105170.png" alt="image-20231024202105170"></p><p>This technique is good at distributing keys fairly among the partitions. The partition boundaries can be evenly spaced, or they can be chosen pseudorandomly (in which case the technique is sometimes known as <em>consistent hashing</em>).</p><p>By using the hash of the key for partitioning we lose a nice property of key-range partitioning: the ability to do efficient range queries (any range query has to be sent to all partitions).</p><p>A table in Cassandra can be declared with a compound primary key consisting of several columns. Only the first part of that key is hashed to determine the partition, but the other columns are used as a concatenated index for sorting the data in Cassandra’s SSTables.</p><h3 id="Skewed-Workloads-and-Relieving-Hot-Spots">Skewed Workloads and Relieving Hot Spots</h3><p>However, hashing a key can’t avoid them entirely: in the extreme case where all reads and writes are for the same key, you still end up with all requests being routed to the same partition.</p><blockquote><p>比如微博大 V 发新动态，很多人去评论之类的。</p></blockquote><p>Today, <strong>most data systems are not able to automatically compensate for such a highly skewed workload, so it’s the responsibility of the application to reduce the skew</strong>.</p><p>For example, if one key is known to be very hot, a simple technique is to add a random number to the beginning or end of the key.</p><h3 id="Partitioning-and-Secondary-Indexes">Partitioning and Secondary Indexes</h3><p>The situation becomes more complicated if secondary indexes are involved.</p><blockquote><p>A secondary index usually doesn’t identify a record uniquely but rather is a way of searching for occurrences of a particular value: find all actions by user 123, find all articles containing the word hogwash, find all cars whose color is red, and so on.</p></blockquote><p>Secondary indexes are the bread and butter of relational databases, and they are common in document databases too.</p><h4 id="Partitioning-Secondary-Indexes-by-Document">Partitioning Secondary Indexes by Document</h4><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231024203140532.png" alt="image-20231024203140532"></p><p>In this indexing approach, each partition is completely separate: each partition maintains its own secondary indexes, covering only the documents in that partition. For that reason, a document-partitioned index is also known as a local index.</p><p>This approach to querying a partitioned database is sometimes known as <em>scatter/gather</em>, and it can make read queries on secondary indexes quite expensive.</p><blockquote><p>总结一下，这种方式写入快，因为只涉及到一个分区的索引更新；读的速度慢，对于一个特定索引，需要查询所有分区才行。</p></blockquote><h4 id="Partitioning-Secondary-Indexes-by-Term">Partitioning Secondary Indexes by Term</h4><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231024203505316.png" alt="image-20231024203505316"></p><p>A global index must also be partitioned, but it can be partitioned differently from the primary key index. We call this kind of index <em>term-partitioned</em>, because the term we’re looking for determines the partition of the index.</p><p>The advantage of a global (term-partitioned) index over a document-partitioned index is that it can make reads more efficient: rather than doing scatter/gather over all partitions, a client only needs to make a request to the partition containing the term that it wants. The downside of a global index is that writes are slower and more complicated.</p><blockquote><p>总结一下，这种方式写入慢，因为要涉及到多个分区中索引的更改；读的速度很快，只需要读包含那个索引的分区即可。</p></blockquote><h3 id="Rebalancing-Partitions">Rebalancing Partitions</h3><p>The process of moving load from one node in the cluster to another is called <em>rebalancing</em>.</p><p>Rebalancing is usually expected to meet some minimum requirements:</p><ul><li>After rebalancing, the load (data storage, read and write requests) should be shared fairly between the nodes in the cluster.</li><li>While rebalancing is happening, the database should continue accepting reads and writes.</li><li>No more data than necessary should be moved between nodes, to make rebalancing fast and to minimize the network and disk I/O load.</li></ul><h4 id="Strategies-for-Rebalancing">Strategies for Rebalancing</h4><p>最愚蠢的分区方式是 <code>hash mod N</code>，一旦 N 发生改变，数据会大量迁移，此时可以考虑使用一致性哈希。</p><h5 id="Fixed-number-of-partitions">Fixed number of partitions</h5><p>Fortunately, there is a fairly simple solution: create many more partitions than there are nodes, and assign several partitions to each node.</p><p>Now, if a node is added to the cluster, the new node can steal a few partitions from every existing node until partitions are fairly distributed once again.</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231024204202142.png" alt="image-20231024204202142"></p><p>This approach to rebalancing is used in Riak, Elasticsearch, Couchbase, and Voldemort.</p><p>In this configuration, the number of partitions is usually <strong>fixed</strong> when the database is first set up and not changed afterward.</p><h5 id="Dynamic-partitioning">Dynamic partitioning</h5><p>For databases that use key range partitioning, a fixed number of partitions with fixed boundaries would be very inconvenient: if you got the boundaries wrong, you could end up with all of the data in one partition and all of the other partitions empty.</p><p>For that reason, key range–partitioned databases such as HBase and RethinkDB create partitions dynamically.</p><p>An advantage of dynamic partitioning is that the number of partitions adapts to the total data volume.</p><h4 id="Operations-Automatic-or-Manual-Rebalancing">Operations: Automatic or Manual Rebalancing</h4><p>Fully automated rebalancing can be convenient, because there is less operational work to do for normal maintenance. However, it can be unpredictable. If it is not done carefully, this process can overload the network or the nodes and harm the performance of other requests while the rebalancing is in progress.</p><p>For that reason, it can be a good thing to have a human in the loop for rebalancing. It’s slower than a fully automatic process, but it can help prevent operational surprises.</p><h3 id="Request-Routing">Request Routing</h3><p>A question remains: When a client wants to make a request, how does it know which node to connect to?</p><p>This is an instance of a more general problem called <em>service discovery</em>, which isn’t limited to just databases.</p><p>On a high level, there are a few different approaches to this problem:</p><ul><li>Allow clients to contact any node. If that node coincidentally owns the partition to which the request applies, it can handle the request directly; otherwise, it forwards the request to the appropriate node, receives the reply, and passes the reply along to the client.</li><li>Send all requests from clients to a routing tier first, which determines the node that should handle each request and forwards it accordingly.</li><li>Require that clients be aware of the partitioning and the assignment of partitions to nodes.</li></ul><blockquote><p>感觉有个中间层是最好的，比如 gataway 就能顺便把这个事做了</p></blockquote><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231024211807713.png" alt="image-20231024211807713"></p><p>Many distributed data systems rely on a separate coordination service such as Zoo‐ Keeper to keep track of this cluster metadata, as illustrated in below:</p><blockquote><p>Each node registers itself in ZooKeeper, and ZooKeeper maintains the authoritative mapping of partitions to nodes. Other actors, such as the routing tier or the partitioning-aware client, can subscribe to this information in ZooKeeper. Whenever a partition changes ownership, or a node is added or removed, ZooKeeper notifies the routing tier so that it can keep its routing information up to date.</p></blockquote><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231024211919440.png" alt="image-20231024211919440"></p>]]></content>
    
    
    <categories>
      
      <category>Design Data-Intensive Applications</category>
      
    </categories>
    
    
    <tags>
      
      <tag>BookNote</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>DDIA: Chapter 5 Replication</title>
    <link href="/2023/10/23/Books/Design%20Data-Intensive%20Applications/chapter-5-replication/"/>
    <url>/2023/10/23/Books/Design%20Data-Intensive%20Applications/chapter-5-replication/</url>
    
    <content type="html"><![CDATA[<h2 id="Replication-Versus-Partitioning">Replication Versus Partitioning</h2><p>There are two common ways data is distributed across multiple nodes:</p><ul><li><em>Replication</em><ul><li>Keeping a copy of the <strong>same data</strong> on several different nodes, potentially in different locations. Replication provides <strong>redundancy</strong> and can also help improve performance.</li></ul></li><li><em>Partitioning</em><ul><li>Splitting a big database into <strong>smaller subsets</strong> called partitions so that different partitions can be assigned to different nodes (also known as <em>sharding</em>).</li></ul></li></ul><p>These are separate mechanisms, but they often go hand in hand:</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231022225932806.png" alt="image-20231022225932806"></p><p>Here are several reasons why you might want to replicate data:</p><ul><li>To reduce latency.</li><li>To increase availability.</li><li>To increase read throughput.</li></ul><h2 id="Leaders-and-Followers">Leaders and Followers</h2><p>The most common solution for this is called <em>leader-based replication</em>.</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231022230551280.png" alt="image-20231022230551280"></p><h3 id="Synchronous-Versus-Asynchronous-Replication">Synchronous Versus Asynchronous Replication</h3><p>An important detail of a replicated system is whether the replication happens <em>synchronously</em> or <em>asynchronously</em>.</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231022230716125.png" alt="image-20231022230716125"></p><ul><li>The replication to follower 1 is <em>synchronous</em></li><li>The replication to follower 2 is <em>asynchronous</em></li></ul><blockquote><p>By the way，这图更像是在表达 write needs to be agreed on a majority of nodes.</p></blockquote><p>The advantage of synchronous replication is that the follower is guaranteed to have an <strong>up-to-date</strong> copy of the data that is <strong>consistent</strong> with the leader.</p><p>The disadvantage is that if the synchronous follower doesn’t respond (because it has crashed, or there is a network fault, or for any other reason), the write cannot be processed.</p><p>For this reason, it is impractical for all followers to be synchronous. In practice, if you enable synchronous replication on a database, it usually means that <strong>one of the followers is synchronous, and the others are asynchronous.</strong></p><blockquote><p>This configuration is sometimes also called <em>semi-synchronous</em></p></blockquote><p>Completely asynchronous will weaken durability. Weakening durability may sound like a bad trade-off, but asynchronous replication is nevertheless widely used, especially if there are many followers or if they are geographically distributed.</p><h3 id="Implementation-of-Replication-Logs">Implementation of Replication Logs</h3><h4 id="Statement-based-replication">Statement-based replication</h4><p>In the simplest case, the leader logs every write request (statement) that it executes and sends that statement log to its followers. For a relational database, this means that every <code>INSERT</code>, <code>UPDATE</code>, or <code>DELETE</code> statement is forwarded to followers.</p><p>One problem with this approach is that any statement that calls a nondeterministic function, such as <code>NOW()</code> to get the current date and time or <code>RAND()</code> to get a random number, is likely to generate a different value on each replica. (Recall how to solve this problem in vm-ft)</p><h4 id="Write-ahead-log-WAL-shipping">Write-ahead log (WAL) shipping</h4><p>We can use the exact same log to build a replica on another node <strong>which storage engine uses</strong>: besides writing the log to disk, the leader also sends it across the network to its followers.</p><p>The main disadvantage is that the log describes the data <strong>on a very low level</strong>: a WAL contains details of which bytes were changed in which disk blocks. This makes replication <strong>closely coupled to the storage engine</strong>.</p><p>If the replication protocol allows the follower to use a newer software version than the leader, you can perform a zero-downtime upgrade of the database software by first upgrading the followers and then performing a failover to make one of the upgraded nodes the new leader.</p><h4 id="Logical-row-based-log-replication">Logical (row-based) log replication</h4><p>An alternative is to use different log formats for replication and for the storage engine, which allows the replication log to be <strong>decoupled from the storage engine</strong> internals.</p><blockquote><p>This kind of replication log is called a logical log, to distinguish it from the storage engine’s (physical) data representation.</p></blockquote><p>A logical log for a relational database is usually a sequence of records describing writes to database tables at the granularity of a row.</p><h3 id="Problems-with-Replication-Lag">Problems with Replication Lag</h3><p>Leader-based replication requires all writes to go through a single node, but readonly queries can go to any replica. For workloads that consist of mostly reads and only a small percentage of writes (a common pattern on the web), there is an attractive option.</p><p>In this read-scaling architecture, you can increase the capacity for serving read-only requests simply by adding more followers.</p><p>这种方法只适用于异步复制，但异步复制就会带来数据不一致的问题：用户可能会从副本中读到过时的数据，但是这种不一致只是暂时的（比如可能由网络延迟带来），所有追随者的数据<strong>最终</strong>会与领导者的数据一致，这种一致性就被称作最终一致性。</p><blockquote><p>You may get different results, because not all writes have been reflected in the follower. This inconsistency is just a temporary state—if you stop writing to the database and wait a while, the followers will eventually catch up and become consistent with the leader. For that reason, this effect is known as <em>eventual consistency</em>.</p></blockquote><blockquote><p>一致性和性能不能兼得，比如强一致性就要求读写操作都必须经过领导者，我们可以退一步，使用最终一致性，这样就能将读操作分摊到各个副本上。<br>很多案例都不需要强一致性的，比如各种信息的评论和点赞，慢一点没啥太大影响。</p></blockquote><h4 id="Reading-Your-Own-Writes">Reading Your Own Writes</h4><p>Many applications let the user submit some data and then view what they have submitted. With asynchronous replication, there is a problem:</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231023215614516.png" alt="image-20231023215614516"></p><p>In this situation, we need <em>read-after-write consistency</em>, also known as <em>read-your-writes consistency</em>. This is a guarantee that if the user reloads the page, they will always see any updates they submitted themselves. (It makes no promises about other users)</p><p><em>How to deal</em></p><p>How can we implement read-after-write consistency in a system with leader-based replication?</p><ul><li>When reading something that the user may have modified, read it from the leader; otherwise, read it from a follower.</li><li>Track the time of the last update and, for one minute after the last update, make all reads from the leader.</li><li>The client can remember the timestamp of its most recent write—then the system can ensure that the replica serving any reads for that user reflects updates at least until that timestamp.<ul><li>If a replica is not sufficiently up to date:<ul><li>The read can be handled by another replica.</li><li>The query can wait until the replica has caught up.</li></ul></li><li>The timestamp could be a logical timestamp (something like the log sequence number)</li></ul></li></ul><p>How about the same user is accessing your service form multiple device?</p><p>In this case you may want to provide <em>cross-device</em> read-after-write consistency.</p><blockquote><p>Like collaborate editor? OneNote…</p></blockquote><h4 id="Monotonic-Reads">Monotonic Reads</h4><p>Second example of an anomaly that can occur when reading from asynchronous followers is that it’s possible for a user to see things <em>moving backward in time</em>.</p><p>情况如下：对于相同的两次查询，可能会被重定向到两个不同的副本当中，因为使用的是异步复制，所以有可能第一个被访问的副本数据比较新，而第二个副本的数据比较旧，从用户的角度，就会出现第二次查询反而数据变少的情况。</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231023220403916.png" alt="image-20231023220403916"></p><p>Monotonic reads is a guarantee that this kind of anomaly does not happen. It’s <strong>a lesser guarantee than strong consistency</strong>, but <strong>a stronger guarantee than eventual consistency.</strong></p><p>When you read data, you may see an old value, monotonic reads only means that if one user makes several reads in sequence, they will not see time go backward，that is they will not read older data after having previously read newer data.</p><p><em>How to deal</em></p><p>One way of achieving monotonic reads is to make sure that each user always makes their reads from the same replica (different users can read from different replicas).</p><h4 id="Summary">Summary</h4><ul><li><em>Read-after-write consistency</em><ul><li>Users should always see data that they submitted themselves.</li></ul></li><li><em>Monotonic reads</em><ul><li>After users have seen the data at one point in time, they shouldn’t later see the data from some earlier point in time.</li></ul></li><li><em>Consistent prefix reads</em><ul><li>Users should see the data in a state that makes causal sense: for example, seeing a question and its reply in the correct order.</li></ul></li></ul><h4 id="Consistent-Prefix-Reads">Consistent Prefix Reads</h4><p>Third example of replication lag anomalies concerns violation of causality.</p><p>即在逻辑上具有先后顺序的数据在到达时不再具有此关系，或者说，乱序了。</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231023221102161.png" alt="image-20231023221102161"></p><p>Preventing this kind of anomaly requires another type of guarantee: <em>consistent prefix reads</em>. This guarantee says that if a sequence of writes happens in a certain order, then anyone reading those writes will see them <strong>appear in the same order.</strong></p><blockquote><p>This is a particular problem in partitioned (sharded) databases.</p></blockquote><p><em>How to deal</em></p><p>One solution is to make sure that any writes that are causally related to each other are written to the same partition.</p><p>There are also algorithms that we will discuss in next chapter.</p><h4 id="Solutions-for-Replication-Lag">Solutions for Replication Lag</h4><p>It would be better if application developers didn’t have to worry about subtle replication issues and could just trust their databases to “do the right thing.”<br>This is why <em>transactions</em> exist: they are a way for a database to provide stronger guarantees so that the application can be simpler.</p><h3 id="Multi-Leader-Replication">Multi-Leader Replication</h3><p>A natural extension of the leader-based replication model is to allow more than one node to accept writes.</p><blockquote><p>允许在多个 Leader 里同时进行写操作，很自然地想到这种模式下要面对的一个重要问题就是如何解决并发时的写冲突。</p></blockquote><h4 id="Use-Cases-for-Multi-Leader-Replication">Use Cases for Multi-Leader Replication</h4><h5 id="Multi-datacenter-operation">Multi-datacenter operation</h5><p>In a multi-leader configuration, you can have a leader in each datacenter. Within each datacenter, regular leader-follower replication is used; between datacenters, each datacenter’s leader <strong>replicates its changes to the leaders in other datacenters.</strong></p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231023221853133.png" alt="image-20231023221853133"></p><p>Let’s compare how the single-leader and multi-leader configurations fare in a multi-datacenter deployment:</p><ul><li><em>Performance</em><ul><li>The inter-datacenter network delay is hidden from users, which means the perceived performance may be better.</li></ul></li><li><em>Tolerance of datacenter outages</em><ul><li>In a multi-leader configuration, each datacenter can continue operating independently of the others</li></ul></li><li><em>Tolerance of network problems</em><ul><li>A multi-leader configuration with asynchronous replication can usually tolerate network problems better: a temporary network interruption does not prevent writes being processed.</li></ul></li></ul><h4 id="Handling-Write-Conflicts">Handling Write Conflicts</h4><p>The biggest problem with multi-leader replication is that write conflicts can occur, which means that conflict resolution is required.</p><p>For example, consider a wiki page that is simultaneously being edited by two users, as shown below:</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231023222244150.png" alt="image-20231023222244150"></p><h5 id="Conflict-avoidance">Conflict avoidance</h5><p>The simplest strategy for dealing with conflicts is to avoid them: if the application can ensure that all writes for a particular record go through the same leader, then conflicts cannot occur.</p><p>For example, in an application where a user can edit their own data, you can ensure that requests from a particular user are always routed to the same datacenter and use the leader in that datacenter for reading and writing. Different users may have different “home” datacenters.</p><h5 id="Converging-toward-a-consistent-state">Converging toward a consistent state</h5><p>If each replica simply applied writes in the order that it saw the writes, the database would end up in an inconsistent state (this will be OK in a single-leader database).</p><p>Thus, the database must resolve the conflict in a <em>convergent</em> way, which means that all replicas must arrive at the same final value when all changes have been replicated.</p><p>There are various ways of achieving convergent conflict resolution:</p><ul><li>Give each write a unique ID, pick the write with the highest ID as the winner, and throw away the other writes. If a timestamp is used, this technique is known as <em>last write wins</em> (LWW).<ul><li>It is dangerously prone to data loss.</li></ul></li><li>Record the conflict in an explicit data structure that preserves all information, and write application code that resolves the conflict at some later time (perhaps by prompting the user).</li></ul><h5 id="Custom-conflict-resolution-logic">Custom conflict resolution logic</h5><p>As the most appropriate way of resolving a conflict may depend on the application, most multi-leader replication tools let you write conflict resolution logic using application code.</p><ul><li><em>On write</em><ul><li>As soon as the database system detects a conflict in the log of replicated changes, it calls the conflict handler.</li></ul></li><li><em>On read</em><ul><li>When a conflict is detected, all the conflicting writes are stored. The next time the data is read, these multiple versions of the data are returned to the application.</li></ul></li></ul><h4 id="Multi-Leader-Replication-Topologies">Multi-Leader Replication Topologies</h4><p>A <em>replication topology</em> describes the communication paths along which writes are propagated from one node to another.</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231023223225109.png" alt="image-20231023223225109"></p><p>To prevent infinite replication loops, each node is given a unique identifier, and in the replication log, each write is tagged with the identifiers of all the nodes it has passed through.</p><p>With multi-leader replication, writes may arrive in the wrong order at some replicas:</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231023223425441.png" alt="image-20231023223425441"></p><p>This is a problem of <em>causality</em>, simply attaching a timestamp to every write is not sufficient, because clocks cannot be trusted to be sufficiently in sync to correctly order these events at leader 2.</p><p>To order these events correctly, a technique called version vectors can be used.</p><h3 id="Leaderless-Replication">Leaderless Replication</h3><blockquote><p>这种模式下，用户在执行写操作时需要把请求发到各个副本上。</p></blockquote><h4 id="Writing-to-the-Database-When-a-Node-Is-Down">Writing to the Database When a Node Is Down</h4><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231023224727922.png" alt="image-20231023224727922"></p><p>To solve that problem, when a client reads from the database, it doesn’t just send its request to one replica: <em>read requests</em> are also sent to several nodes <em>in parallel</em>. The client may get different responses from different nodes; i.e., the up-to-date value from one node and a stale value from another. Version numbers are used to determine which value is newer.</p><h5 id="Read-repair-and-anti-entropy">Read repair and anti-entropy</h5><p>The replication scheme should ensure that eventually all the data is copied to every replica. Two mechanisms are often used in Dynamo-style datastores:</p><ul><li><em>Read repair</em><ul><li>When a client makes a read from several nodes in parallel, it can detect any stale responses. The client sees that replica 3 has a stale value and writes the newer value back to that replica. This approach works well for <strong>values that are frequently read.</strong></li></ul></li><li><em>Anti-entropy process</em><ul><li>Some datastores have a <strong>background</strong> process that constantly looks for differences in the data between replicas and copies any missing data from one replica to another.</li></ul></li></ul><p>Note that without an anti-entropy process, values that are rarely read may be missing from some replicas and thus have reduced durability, because read repair is only performed when a value is read by the application.</p><h5 id="Quorums-for-reading-and-writing">Quorums for reading and writing</h5><p>More generally, if there are <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span> replicas, every write must be confirmed by <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span> nodes to be considered successful, and we must query at least <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> nodes for each read.</p><p>As long as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi><mo>+</mo><mi>r</mi><mo>&gt;</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">w + r &gt; n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span>, we expect to get an up-to-date value when reading, because at least one of the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> nodes we’re reading from must be up to date. Reads and writes that obey these <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span> values are called <em>quorum</em> reads and writes.</p><blockquote><p>You can think of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span> as the minimum number of votes required for the read or write to be valid.<br>Normally, reads and writes are always sent to all <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span> replicas in parallel. The parameters <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> determine how many nodes we wait for.</p></blockquote><p>However, you can vary the numbers as you see fit. For example, a workload with few writes and many reads may benefit from setting <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi><mo>=</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">w = n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">r = 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span>. This makes reads faster, but has the disadvantage that just one failed node causes all database writes to fail.</p><h4 id="Limitations-of-Quorum-Consistency">Limitations of Quorum Consistency</h4><p>If you have <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span> replicas, and you choose <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> such that <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi><mo>+</mo><mi>r</mi><mo>&gt;</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">w + r &gt; n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span>, you can generally expect every read to return the most recent value written for a key. This is the case because the set of nodes to which you’ve written and the set of nodes from which you’ve read <strong>must overlap</strong>.</p><p>With a smaller <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> you are more likely to read stale values, because it’s more likely that your read didn’t include the node with the latest value. On the upside, this configuration allows <strong>lower latency and higher availability</strong>.</p><p>However, even with w + r &gt; n, there are likely to be edge cases where stale values are returned:</p><ul><li>If a write happens concurrently with a read, the write may be reflected on only some of the replicas. In this case, it’s undetermined whether the read returns the old or the new value.</li><li>If a node carrying a new value fails, and its data is restored from a replica carrying an old value, the number of replicas storing the new value may fall below w, breaking the quorum condition.</li><li>Even if everything is working correctly, there are edge cases in which you can get unlucky with the timing.</li></ul><p>The parameters <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> allow you to adjust the probability of stale values being read, but it’s wise to not take them as absolute guarantees.</p><h4 id="Monitoring-staleness">Monitoring staleness</h4><p>For leader-based replication, the database typically exposes metrics for the replication lag, which you can feed into a monitoring system. This is possible because writes are applied to the leader and to followers in the same order, and each node has a position in the replication log.</p><p>Eventual consistency is a deliberately vague guarantee, but for operability it’s important to be able to quantify “eventual.”</p><h4 id="Sloppy-Quorums-and-Hinted-Handoff">Sloppy Quorums and Hinted Handoff</h4><p>Quorums reading and writing make databases with leaderless replication appealing for use cases that require high availability and low latency, and that can tolerate occasional stale reads.</p><h3 id="Detecting-Concurrent-Writes">Detecting Concurrent Writes</h3><h4 id="Last-write-wins-discarding-concurrent-writes">Last write wins (discarding concurrent writes)</h4><p>One approach for achieving eventual convergence is to declare that each replica need only store the most “recent” value and allow “older” values to be overwritten and discarded.</p><p>For example, we can attach a timestamp to each write, pick the biggest timestamp as the most “recent,” and discard any writes with an earlier timestamp. This conflict resolution algorithm, called <em>last write wins</em> (LWW).</p><p>LWW achieves the goal of eventual convergence, but at the cost of durability: if there are several concurrent writes to the same key, even if they were all reported as successful to the client (because they were written to w replicas), only one of the writes will survive and the others will be silently discarded.</p><h4 id="The-“happens-before”-relationship-and-concurrency">The “happens-before” relationship and concurrency</h4><p>How do we decide whether two operations are concurrent or not?</p><p>An operation A <em>happens before</em> another operation B if B knows about A, or depends on A, or builds upon A in some way. Whether one operation happens before another operation is the key to defining what concurrency means. In fact, we can simply say that two operations are <em>concurrent</em> if neither happens before the other.</p><p>It may seem that two operations should be called concurrent if they occur “at the same time” — but in fact, it is not important whether they literally overlap in time because of problems with clocks in distributed systems.</p><p>We simply call <strong>two operations concurrent if they are both unaware of each other, regardless of the physical time at which they occurred.</strong></p>]]></content>
    
    
    <categories>
      
      <category>Design Data-Intensive Applications</category>
      
    </categories>
    
    
    <tags>
      
      <tag>BookNote</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>DDIA: Chapter 4 Encoding and Evolution</title>
    <link href="/2023/10/21/Books/Design%20Data-Intensive%20Applications/chapter-4-encoding-and-evolution/"/>
    <url>/2023/10/21/Books/Design%20Data-Intensive%20Applications/chapter-4-encoding-and-evolution/</url>
    
    <content type="html"><![CDATA[<h2 id="Formats-for-Encoding-Data">Formats for Encoding Data</h2><p>这里提到了两种兼容性，后面分析数据编码格式时都会用到：</p><p>In order for the system to continue running smoothly, we need to maintain compatibility in both directions:</p><ul><li><em>Backward compatibility</em><ul><li>Newer code can read data that was written by older code.</li></ul></li><li><em>Forward compatibility</em><ul><li>Older code can read data that was written by newer code.</li></ul></li></ul><blockquote><p>直译有一个问题, 英语的&quot;前后&quot;在时间和空间上统一, 而汉语却是相反. 比如 forward 在空间上指前进, 在时间上指未来. 但是汉语中的&quot;前&quot;在空间上指前进, 在时间上却指过去.</p></blockquote><p>向后兼容很好理解：指新的版本的软／硬件可以使用老版本的软／硬件产生的数据。</p><p><em>Forward compatibility</em> 译为向前兼容极容易混乱，这里可以想成向未来兼容：指老的版本的软／硬件可以使用新版本的软／硬件产生的数据。</p><p>以下是几个例子：</p><ul><li><p>Intel 的 x86指令集 CPU 是<strong>向后兼容</strong>的，因为新款 CPU 依然可以运行老版本的软件。Intel 保证老版本 CPU 有的指令集新版本一定还保留着，这种只增加不删除的策略，保证了我们换 CPU 时，不需要更换很多软件。</p></li><li><p>Windows 操作系统是<strong>向后兼容</strong>的，大部分针对 Windows 7开发的软件依然可以很好的运行在 Windows 10下。Windows 通过保证系统 API 的稳定不变，只增加不删除的策略，保证了老系统上开发的软件可以很容易的在新系统上运行。</p></li><li><p>用于设计网页的 HTML 语言是<strong>向前兼容</strong>的，当旧的浏览器遇到新版本的 HTML 语言时，可以简单的忽略不支持的标签，仍然可以正常显示。</p></li></ul><p>本章主要讲了以下几种数据编码格式：</p><ul><li>JSON</li><li>XML</li><li>Protocol Buffers</li><li>Thrift</li><li>Avro</li></ul><p>In particular, we will look at how they handle schema changes and how they support systems where old and new data and code need to coexist.</p><p>We need some kind of translation between the two representations. The translation from the in-memory representation to a byte sequence is called encoding (also known as serialization or marshalling), and the reverse is called decoding (parsing, deserialization, unmarshalling).</p><h3 id="Language-Specific-Formats">Language-Specific Formats</h3><p>Many programming languages come with built-in support for encoding in-memory objects into byte sequences. For example, Java has <code>java.Io.Serializable</code>, Ruby has <code>Marshal</code>, Python has <code>pickle</code>, and so on.</p><p>Language-specific formats have a number of deeper problems:</p><ul><li>The encoding is often tied to a particular programming language, and reading the data in another language is very difficult. (有“语言隔离”现象)</li><li>In order to restore data in the same object types, the decoding process needs to be able to instantiate arbitrary classes. (有安全性问题)</li><li>Versioning data is often an afterthought in these libraries. (不具有兼容性, 既不支持向后兼容也不支持向未来兼容)</li><li>Efficiency (CPU time taken to encode or decode, and the size of the encoded structure) is also often an afterthought. (效率不高)</li></ul><h3 id="JSON-XML-and-Binary-Variants">JSON, XML, and Binary Variants</h3><p>They also have some subtle problems:</p><ul><li>There is a lot of ambiguity around the encoding of numbers.</li><li>JSON and XML have good support for Unicode character strings (i.e., humanreadable text), but they don’t support binary strings (sequences of bytes without a character encoding).</li><li>There is optional schema support for both XML and JSON. Use of XML schemas is fairly widespread, but many JSON-based tools don’t bother using schemas.</li></ul><p>An Example of JSON Schema:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;$schema&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;https://json-schema.org/draft/2020-12/schema&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;$id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;https://example.com/product.schema.json&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;title&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Product&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;description&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;A product from Acme&#x27;s catalog&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;object&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;properties&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;productId&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;description&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;The unique identifier for a product&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;integer&quot;</span><br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;productName&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;description&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Name of the product&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;string&quot;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><h3 id="Binary-encoding">Binary encoding</h3><p>For data that is used only internally within your organization, there is less pressure to use a lowest-common-denominator encoding format. For example, you could choose a format that is more compact or faster to parse.</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;userName&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Martin&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;favoriteNumber&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1337</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;interests&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-string">&quot;daydreaming&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-string">&quot;hacking&quot;</span><br>    <span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>Let’s look at an example of MessagePack, a binary encoding for JSON.</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231021213534010.png" alt="image-20231021213534010"></p><p>All the binary encodings of JSON are similar in this regard. It’s not clear whether such a small space reduction (and perhaps a speedup in parsing) is worth the loss of human-readability.</p><h4 id="Thrift-and-Protocol-Buffers">Thrift and Protocol Buffers</h4><p>Thrift 和 Protocol Buffers 都是二进制编码库，它们都需要数据模式 (data schema)来编码数据。</p><p>Thrift 的数据模式样例如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs idl">struct Person &#123; <br>    1: required string       userName, <br>    2: optional i64          favoriteNumber, <br>    3: optional list&lt;string&gt; interests <br>&#125;<br></code></pre></td></tr></table></figure><p>Protocol Buffers 的也非常类似：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs idl">message Person &#123; <br>    required string user_name = 1; <br>    optional int64 favorite_number = 2; <br>    repeated string interests = 3; <br>&#125;<br></code></pre></td></tr></table></figure><p>Thrift and Protocol Buffers each come with a code generation tool that takes a schema definition like the ones shown here, and produces classes that implement the schema in various programming languages.</p><h5 id="BinaryProtocol-In-Thrift">BinaryProtocol In Thrift</h5><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231021214141082.png" alt="image-20231021214141082"></p><p>The differece compare to <em>MessagePack</em> is that there are no field names (<code>userName</code>, <code>favoriteNumber</code>, <code>interests</code>). Instead, the encoded data contains field tags, which are numbers (1, 2, and 3). Those are the numbers that appear in the schema definition. Field tags are like aliases for fields—they are a compact way of saying what field we’re talking about, without having to spell out the field name.</p><h5 id="CompactProtocol-In-Thrift">CompactProtocol In Thrift</h5><p>The Thrift CompactProtocol encoding reduces length by packing the field type and tag number into a single byte, and by using variable-length integers.</p><blockquote><p>Rather than using a full eight bytes for the number 1337, it is encoded in two bytes, with the top bit of each byte used to indicate whether there are still more bytes to come.</p></blockquote><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231021214428131.png" alt="image-20231021214428131"></p><h5 id="Protocol-Buffers">Protocol Buffers</h5><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231021214522240.png" alt="image-20231021214522240"></p><h5 id="Summary">Summary</h5><p>总结一下，由于 schema 在数据传输两边的程序中都有一份，所以我们可以将传输的数据中的 field name 换为 field tags，然后再加上可变长度的数字编码，就能最小化字节序列的长度。</p><p>现在可以来分析一下 Thrift 和 Protocol Buffers 是如何实现向后兼容以及向未来兼容的。</p><p>Background: Schemas inevitably need to change over time.</p><ul><li>Change the name of a field in the schema<ul><li>OK, since the encoded data never refers to field names, but field tags.</li></ul></li><li>Add new fields to the schema<ul><li>If old code (which doesn’t know about the new tag numbers you added) tries to read data written by new code, including a new field with a tag number it doesn’t recognize, it can simply ignore that field. (这就实现了向未来兼容，老的版本的软件可以使用新版本的软件产生的数据。)</li><li>If you add a new field, you cannot make it required to maintain backward compatibility.</li></ul></li><li>Removing a field is just like adding a field, with backward and forward compatibility concerns reversed.<ul><li>Remove a field that is optional.</li><li>Never use the same tag number again</li></ul></li></ul><h4 id="Avro">Avro</h4><p>Apache Avro is another binary encoding format. It was started in 2009 as a subproject of Hadoop, as a result of Thrift not being a good fit for Hadoop’s use cases</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231021215733312.png" alt="image-20231021215733312"></p><p>To parse the binary data, you go through the fields <strong>in the order that they appear in the schema</strong> and use the schema to <strong>tell you the datatype of each field</strong>.</p><p>This means that the binary data can only be decoded correctly if the code reading the data is using the <strong>exact same schema</strong> as the code that wrote the data.</p><p>How does Avro support schema evolution?</p><h5 id="The-writer’s-schema-and-the-reader’s-schema">The writer’s schema and the reader’s schema</h5><ul><li>When an application wants to <strong>encode</strong> some data, it uses the schema called <em>the writer’s schema.</em></li><li>When an application wants to <strong>decode</strong> some data, it uses the schema called <em>the reader’s schema.</em></li></ul><p><strong>The key idea with Avro is that the writer’s schema and the reader’s schema don’t have to be the same—they only need to be compatible.</strong></p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231021220033860.png" alt="image-20231021220033860"></p><p>在 Avro 里，</p><ul><li>向后兼容意味着 a new version of the schema as reader and an old version as writer.（新软件可以读旧数据）</li><li>向未来兼容意味着 a new version of the schema as writer and an old version as reader.（旧软件可以读新数据）</li></ul><p>To maintain compatibility, you may only add or remove a field that has a default value.</p><p>如果增加一个没有默认值的属性，新的读者无法从旧数据里获得该值，破坏了向后兼容。如果删除一个没有默认值的属性，旧的读者无法从新数据里获得该值，破坏了向未来兼容。</p><p>这里也隐含了一个问题，写者的数据模式放在哪里？</p><p>The answer depends on the context in which Avro is being used：</p><ul><li><em>Large file with lots of records</em><ul><li>The writer of that file can just include the writer’s schema once at the beginning of the file.</li></ul></li><li><em>Database with individually written records</em><ul><li>To include a version number at the beginning of every encoded record, and to keep a list of schema versions in your database,</li></ul></li><li><em>Sending records over a network connection</em><ul><li>Negotiate the schema version on connection setup and then use that schema for the lifetime of the connection.</li></ul></li></ul><h5 id="Dynamically-generated-schemas">Dynamically generated schemas</h5><p>The difference is that Avro is friendlier to <em>dynamically generated</em> schemas. By contrast, if you were using Thrift or Protocol Buffers for this purpose, the field tags would likely have to be assigned by hand.</p><p>Thrift and Protocol Buffers rely on code generation: after a schema has been defined, you can generate code that implements this schema in a programming language of your choice.</p><h3 id="The-Merits-of-Schemas">The Merits of Schemas</h3><p>They have a number of nice properties:</p><ul><li>They can be much <strong>more compact</strong> than the various “binary JSON” variants, since they can omit field names from the encoded data.</li><li>The schema is a valuable form of documentation, and because the schema is required for decoding, you can be sure that it is up to date (whereas manually maintained documentation may easily diverge from reality).</li><li>Keeping a database of schemas allows you to check forward and backward compatibility of schema changes, before anything is deployed.</li><li>For users of statically typed programming languages, the ability to generate code from the schema is useful, since it enables type checking at compile time.</li></ul><h2 id="Modes-of-Dataflow">Modes of Dataflow</h2><p>We will explore some of the most common ways how data flows between processes:</p><ul><li>Via databases</li><li>Via service calls</li><li>Via asynchronous message passing</li></ul><h3 id="Dataflow-Through-Databases">Dataflow Through Databases</h3><p>如果与数据库交互时只有一个线程，通常情况下“旧版本”的线程写入数据，“新版本”的线程读入数据。很明显这种情况下，数据库需要维护向后兼容性。（storing something in the database as sending a message to your future self.）</p><p>如果有多个线程对数据库进行读写，就会存在旧读者读新数据的情况，所以向未来兼容也是必要的。</p><p>The encoding formats discussed previously support such preservation of unknown fields, but sometimes you need to take care at an application level. For example, if you decode a database value into model objects in the application, and later reencode those model objects, the unknown field might be lost in that translation process.</p><h3 id="Dataflow-Through-Services-REST-and-RPC">Dataflow Through Services: REST and RPC</h3><p>REST 比较常见，没啥好说的，这里主要总结一下 RPC。</p><p>虽然说 RPC 提供了一层类似于调用本地函数的抽象，但是由于网络请求的独特性，两者还是有本质上的不同：</p><ul><li>网络请求是不可预测的：请求或者响应可能会丢失，也有可能会变慢。</li><li>如果网络请求超时了，客户端不能确定到底是服务端崩溃了，还是网络变慢了。</li><li>如果网络请求超时了，很多情况下客户端都需要重新发送，所以服务端的接口可能要实现幂等性来解决多次发送的问题。</li><li>客户端和服务端可能不是同一种编程语言，所以 RPC 框架需要在两者之间转换数据结构。</li></ul><p>Various RPC frameworks have been built on top of all the encodings mentioned in this chapter:</p><ul><li>Thrift and Avro come with RPC support included.</li><li>gRPC is an RPC implementation using Protocol Buffers.</li><li>Finagle uses Thrift.</li><li><a href="http://Rest.Li">Rest.Li</a> uses JSON over HTTP.</li></ul><p>We can make a simplifying assumption in the case of dataflow through services: it is reasonable to assume that all the servers will be updated first, and all the clients second. Thus, <strong>you only need backward compatibility on requests, and forward compatibility on responses.</strong></p><p>The backward and forward compatibility properties of an RPC scheme are inherited from whatever encoding it uses:</p><ul><li>Thrift, gRPC (Protocol Buffers), and Avro RPC can be evolved according to the compatibility rules of the respective encoding format.</li><li>In SOAP, requests and responses are specified with XML schemas. These can be evolved, but there are some subtle pitfalls.</li><li>RESTful APIs most commonly use JSON (without a formally specified schema) for responses, and JSON or URI-encoded/form-encoded request parameters for requests. Adding optional request parameters and adding new fields to response objects are usually considered changes that maintain compatibility.</li></ul><h3 id="Message-Passing-Dataflow">Message-Passing Dataflow</h3><p>Using a message broker has several advantages compared to direct RPC:</p><ul><li>It can act as a buffer if the recipient is unavailable or overloaded, and thus improve system reliability.</li><li>It can automatically redeliver messages to a process that has crashed, and thus prevent messages from being lost.</li><li>It logically decouples the sender from the recipient.</li><li>…</li></ul><h4 id="Message-brokers">Message brokers</h4><p>In general, message brokers are used as follows: one process sends a message to a named queue or topic, and the broker ensures that the message is delivered to one or more consumers of or subscribers to that queue or topic. There can be many producers and many consumers on the same topic.</p>]]></content>
    
    
    <categories>
      
      <category>Design Data-Intensive Applications</category>
      
    </categories>
    
    
    <tags>
      
      <tag>BookNote</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>DDIA: Chapter 2 Data Models and Query Languages</title>
    <link href="/2023/10/20/Books/Design%20Data-Intensive%20Applications/chapter-2-data-models-and-query-languages/"/>
    <url>/2023/10/20/Books/Design%20Data-Intensive%20Applications/chapter-2-data-models-and-query-languages/</url>
    
    <content type="html"><![CDATA[<h2 id="Relational-Model-Versus-Document-Model">Relational Model Versus Document Model</h2><p>首先谈到了 NoSQL 的诞生：</p><p>There are several driving forces behind the adoption of NoSQL databases, including:</p><ul><li>A need for greater scalability than relational databases can easily achieve, includ‐ ing very large datasets or very high write throughput</li><li>A widespread preference for free and open source software over commercial database products</li><li>Specialized query operations that are not well supported by the relational model</li><li>Frustration with the restrictiveness of relational schemas, and a desire for a more dynamic and expressive data model</li></ul><p>然后通过下图的这份简历来说明了 one-to-many 这种关系</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231019222823030.png" alt="image-20231019222823030"></p><p>One-to-many 关系在关系数据库中可以有许多种表达方式：</p><ul><li>通过正则化将 “many” 放入其他表中</li><li>Later versions of the SQL standard added support for structured datatypes and XML data; this allowed multi-valued data to be stored within a single row, with support for querying and indexing inside those documents.</li><li>将 “many” 的信息先编码为 JSON 或者 XML，直接存入到数据库中的一个文本列中，缺点是无法利用数据库进行查询</li></ul><p>如果把简历表示为 JSON 数据的话：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;user_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">251</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;first_name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Bill&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;last_name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Gates&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;summary&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Co-chair of the Bill &amp; Melinda Gates... Active blogger.&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;region_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;us:91&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;industry_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">131</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;photo_url&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;/p/7/000/253/05b/308dd6e.jpg&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;positions&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;job_title&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Co-chair&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;organization&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Bill &amp; Melinda Gates Foundation&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;job_title&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Co-founder, Chairman&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;organization&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Microsoft&quot;</span><br>        <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;education&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;school_name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Harvard University&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;start&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1973</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;end&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1975</span><br>        <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;school_name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Lakeside School, Seattle&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;start&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">null</span></span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;end&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">null</span></span><br>        <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;contact_info&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;blog&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;http://thegatesnotes.com&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;twitter&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;http://twitter.com/BillGates&quot;</span><br>    <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>The lack of a schema is often cited as an advantage. The JSON representation has better <strong>locality</strong> than the multi-table schema in Figure 2-1. If you want to fetch a profile in the relational example, you need to either perform multiple queries (query each table by user_id) or perform a messy multi- way join between the users table and its subordinate tables. In the JSON representa‐ tion, all the relevant information is in one place, and one query is sufficient.</p><p>然后本章谈到了第三种关系，也是最难处理的一种关系：many-to-one.</p><p>In relational databases, it’s normal to refer to rows in other tables by ID, because joins are easy. In document databases, joins are not needed for one-to-many tree structures, and support for joins is often weak.</p><p>one-to-many 是一个树的结构，从某种意义上来说，它是自洽的，每个子节点都只属于一个父节点，此时用 document database 就是比较容易的,而 many-to-one 则必须通过 join 来获得完整信息。</p><p>Document database 虽然在最近十多年才开始兴起，其实从历史的角度来说，它才是最早数据库的模样：</p><ul><li>IMS 系统的数据模型是一个简单的层次模型，one-to-one 和 one-to-many 都能支持得很好，但无法支持 many-to-many</li><li>为了解决层次模型的缺陷，有两种方案被提了出来：relational model 和 network model<ul><li>network model 有点像现在的 graph model，但要原始得多，书上也专门花了一些篇幅来说明两者的不一样</li></ul></li></ul><p>However, when it comes to representing many-to-one and many-to-many relation‐ ships, relational and document databases are not fundamentally different: in both cases, the related item is referenced by a unique identifier, which is called a foreign key in the relational model and a document reference in the document model. That identifier is resolved at read time by using a join or follow-up queries.</p><h2 id="relational-versus-document-database">relational versus document database</h2><p>The main arguments in favor of the document data model are <strong>schema flexibility, better performance due to locality</strong>, and that for some applications it <strong>is closer to the data structures</strong> used by the application. The relational model counters by providing <strong>better support for joins, and many-to-one and many-to-many relationships</strong>.</p><p>这其实就体现了两种类型的数据库的使用范围的不同，书中先谈到了 document database 的缺陷：</p><p>The document model has limitations: for example, you cannot refer directly to a nested item within a document, but instead you need to say something like “the second item in the list of positions for user 251” (much like an access path in the hierarchical model). However, as long as documents are not too deeply nested, that is not usually a problem.</p><p>However, if your application does use many-to-many relationships, the document model becomes less appealing. It’s possible to reduce the need for joins by denormal‐ izing, but then the application code needs to do additional work to keep the denor‐ malized data consistent.</p><blockquote><p>[!summary]<br>Denormalizing means more efforts to keep data consistent.</p></blockquote><p>再谈到了它的优点：</p><p><strong>Schema Flexibility</strong></p><p>Document databases are sometimes called schemaless, but that’s misleading, as the code that reads the data usually assumes some kind of structure—i.e., there is an implicit schema, but it is not enforced by the database. A more accurate term is schema-on-read (the structure of the data is implicit, and only interpreted when the data is read), in contrast with schema-on-write (the traditional approach of relational databases, where the schema is explicit and the database ensures all written data con‐ forms to it).</p><p>The schema-on-read approach is advantageous if the items in the collection don’t all have the same structure for some reason (i.e., the data is heterogeneous) for example, because there are many different types of objects, and it is not practical to put each type of object in its own table.</p><p>Schema-on-read 和 schema-on-write 的说法我是第一次遇见，挺有意思的，和编程语言中的静态检查以及动态检查非常类似。</p><p><strong>Data locality for queries</strong></p><p>A document is usually stored as a single continuous string, encoded as JSON, XML, or a binary variant thereof (such as MongoDB’s BSON). If your application often needs to access the entire document (for example, to render it on a web page), there is a performance advantage to this storage locality.</p><p>Locality 带来了好处，也带来了坏处：<strong>读必须一起读，写必须一起写</strong></p><p>The locality advantage only applies if you need large parts of the document at the same time. The database typically needs to load the entire document, even if you access only a small portion of it, which can be wasteful on large documents. On updates to a document, the entire document usually needs to be rewritten—only modifications that don’t change the encoded size of a document can easily be per‐ formed in place. For these reasons, it is generally recommended that you keep documents fairly small and avoid writes that increase the size of a document.</p><p>最后谈到了两种不同数据库都在往对方的领域发展：</p><p>On the document database side, RethinkDB supports relational-like joins in its query language, and some MongoDB drivers automatically resolve database references (effectively performing a client-side join, although this is likely to be slower than a join performed in the database since it requires additional network round-trips and is less optimized).</p><h2 id="Query-Languages-for-Data">Query Languages for Data</h2><p>这里首先谈到了编写代码的两种方式：</p><p>Let’s generalize and say that there are two ways in which we can write code: imperative and declarative. We could define the difference as follows:</p><ul><li><strong>Imperative programming</strong>: telling the “machine” <em>how</em> to do something, and as a result <em>what</em> you want to happen will happen.</li><li><strong>Declarative programming</strong>: telling the “machine” <em>what</em> you would like to happen, and let the computer figure out <em>how</em> to do it.</li></ul><p>具体的可以查看 [[imperative-vs-declarative]]</p><p>A declarative query language is attractive because it is typically more concise and easier to work with than an imperative API. But more importantly, it also hides implementation details of the database engine, which makes it possible for the database system to introduce performance improvements without requiring any changes to queries.</p><p>The fact that SQL is more limited in functionality gives the database much more room for automatic optimizations.</p><p>Imperative code is very hard to parallelize across multiple cores and multiple machines, because it specifies instructions that must be performed in a particular order. Declarative languages have a better chance of getting faster in parallel execution because they specify only the pattern of the results, not the algorithm that is used to determine the results. The database is free to use a parallel implementation of the query language, if appropriate.</p><p>这一段也说明了声明式代码的优点：</p><ul><li>精确简单</li><li>隐藏了具体的实现细节，方便系统自动优化<ul><li>A declarative query language offers more opportunities for a query optimizer to improve the performance of a query.</li></ul></li><li>性能更好</li></ul><h3 id="MapReduce-Querying">MapReduce Querying</h3><p>MapReduce is neither a declarative query language nor a fully imperative query API, but somewhere in between: the logic of the query is expressed with snippets of code, which are called repeatedly by the processing framework. It is based on the map (also known as collect) and reduce (also known as fold or inject) functions that exist in many functional programming languages.</p><p>The map and reduce functions are somewhat restricted in what they are allowed to do. They must be pure functions, which means <strong>they only use the data that is passed to them as input, they cannot perform additional database queries, and they must not have any side effects.</strong> These restrictions allow the database to run the functions anywhere, in any order, and rerun them on failure.</p><p>MapReduce is a fairly low-level programming model for distributed execution on a cluster of machines. Higher-level query languages like SQL can be implemented as a pipeline of MapReduce operations.</p><h2 id="Graph-Like-Data-Models">Graph-Like Data Models</h2><p>如果 many-to-many 关系在你的数据中非常常见，你可能就要考虑使用 graph-like data model 了。</p><p>The relational model can handle simple cases of many-to-many relationships, but as the connections within your data become more complex, it becomes more natural to start modeling your data as a graph.</p><p>Graphs are good for evolvability: as you add features to your application, a graph can easily be extended to accommodate changes in your application’s data structures.</p><p>后文说了两种不同的图模型：</p><ul><li>property graph model</li><li>triple-store model</li></ul><p>以及三种图模型中的声明式查询语言</p><p>由于不是经常用到图模型，后面的内容也就简单看了看，有需要时再倒回来看看。</p>]]></content>
    
    
    <categories>
      
      <category>Design Data-Intensive Applications</category>
      
    </categories>
    
    
    <tags>
      
      <tag>BookNote</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>DDIA: Chapter 3 Storage and Retrieval</title>
    <link href="/2023/10/20/Books/Design%20Data-Intensive%20Applications/chapter-3-storage-and-retrieval/"/>
    <url>/2023/10/20/Books/Design%20Data-Intensive%20Applications/chapter-3-storage-and-retrieval/</url>
    
    <content type="html"><![CDATA[<p>这一章主要讲的是数据库更底层的一些东西。</p><p>In order to tune a storage engine to perform well on your kind of workload, you need to have a rough idea of what the storage engine is doing under the hood.</p><h2 id="Data-Structures-That-Power-Your-Database">Data Structures That Power Your Database</h2><h3 id="Index">Index</h3><p>Any kind of index usually slows down writes, because the index also needs to be updated every time data is written.</p><p>This is an important trade-off in storage systems: <strong>well-chosen indexes speed up read queries, but every index slows down writes.</strong></p><p>所以在默认情况下，数据库不会对所有 key 都建立索引，一般都由应用的开发者来确定。</p><h4 id="Hash-Index">Hash Index</h4><p>以最简单的方式实现一个 key-value store, 每次 Put 就是在数据文件后面追加，每次 Get 就依次遍历数据文件寻找对应数据。</p><p>遍历寻找数据太慢了，所以我们可以为这个简单的数据库增加索引，即在内存中维护一个 Hashmap，key 为键值对的键，value 为该键值对在数据文件中的字节偏移值。</p><p>Whenever you append a new key-value pair to the file, you also update the hash map to reflect the offset of the data you just wrote (this works both for inserting new keys and for updating existing keys).</p><p>在这种情况下，无论新增还是修改，都是在文件末尾追加。</p><p>A storage engine like Bitcask is well suited to situations where the value for each key is updated frequently.</p><p>文件太大后自然需要压缩：</p><blockquote><p>Compaction means throwing away duplicate keys in the log, and keeping only the most recent update for each key.</p></blockquote><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231020212531910.png" alt="image-20231020212531910"></p><p>我们自然地可以将整个数据文件分为一个个大小固定的文件，当一个文件写满之后，就去写下一个文件，如果文件数量过多，就可以另起一个线程去压缩合并。由于只是在生成新文件，所以压缩合并的同时也可以依旧进行查询，压缩完成后，再用新文件去替换旧文件。</p><p>在实现这个简单的 key-value store 时有几点需要注意：</p><ul><li><em>Crash recovery</em><ul><li>If the database is restarted, the in-memory hash maps are lost. Bitcask speeds up recovery by storing a snapshot of each segment’s hash map on disk, which can be loaded into memory more quickly.</li></ul></li><li><em>Partially written records</em><ul><li>The database may crash at any time, including halfway through appending a record to the log. Bitcask files include checksums, allowing such corrupted parts of the log to be detected and ignored.</li></ul></li><li><em>Concurrency control</em><ul><li>As writes are appended to the log in a strictly sequential order, a common implementation choice is to have only one writer thread.</li></ul></li></ul><p>Append-only 模式也有自己的优点：</p><ul><li>Appending and segment merging are sequential write operations, which are generally <strong>much faster than random writes</strong>, especially on magnetic spinning-disk hard drives.</li><li>Concurrency and crash recovery are <strong>much simpler</strong> if segment files are appendonly or immutable.</li><li>Merging old segments avoids the problem of data files getting fragmented over time.</li></ul><p>缺点也有：</p><ul><li>The hash table must fit in memory.</li><li>Range queries are not efficient.<ul><li>只能遍历整个 Hashmap</li></ul></li></ul><h4 id="SSTables-and-LSM-Trees">SSTables and LSM-Trees</h4><p>我们对上文提到的数据文件做一点小小的改进：要求所有的键值对都以键来排序，这种格式就是 Sorted String Table (SSTable).</p><p>SSTable’s advantages over log segments with hash index:</p><ul><li>Merging segments is simple and efficient, even if the files are bigger than the available memory.<ul><li>合并两个有序的列表只需要 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span> 的时间复杂度</li><li>并且可以在外部使用归并排序</li></ul></li><li>In order to find a particular key in the file, you no longer need to keep an index of all the keys in memory. This is called a <em>sparse-index</em>, which will significantly reduce the table size.<ul><li>由于记录的键是有序的，我们可以每隔一定间隔记录一个，寻找某个记录时，根据它的键去遍历一个小区间就行</li><li><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231020214252490.png" alt="image-20231020214252490"></li><li>Since read requests need to scan over several key-value pairs in the requested range anyway, it is possible to group those records into a block and compress it before writing it to disk.</li></ul></li></ul><p>数据文件中的记录是有序的，在写入数据时，我们肯定不能每次直接往文件中写入，而是应该先在内存中处理，到达一定大小后再写入到文件中。</p><p>We can now make our storage engine work as follows:</p><ul><li>When a write comes in, add it to an in-memory balanced tree data structure (for example, a red-black tree). This in-memory tree is sometimes called a <em>memtable</em>.</li><li>When the memtable gets bigger than some threshold—typically a few megabytes — write it out to disk as an SSTable file. This can be done efficiently because the tree already maintains the key-value pairs sorted by key. The new SSTable file becomes the most recent segment of the database. While the SSTable is being written out to disk, writes can continue to a new memtable instance.</li><li>In order to serve a read request, first try to find the key in the memtable, then in the most recent on-disk segment, then in the next-older segment, etc.</li><li>From time to time, run a merging and compaction process in the background to combine segment files and to discard overwritten or deleted values.</li></ul><p>注意，这样只能保证单个文件内的记录是有序的，而不能在多个文件之间来保证有序性。</p><p>当数据库崩溃时，memtable 中的记录也会消失，所以我们可以在磁盘上维护一个 WAL日志，用来记录这个 memtable 的写入情况。</p><p>这种算法即是 LSM-Tree 的原型。</p><p>The LSM-tree algorithm can be slow when looking up keys that do not exist in the database. In order to optimize this kind of access, storage engines often use additional Bloom filters.</p><p>There are also different strategies to determine the order and timing of how SSTables are compacted and merged. The most common options are size-tiered and leveled compaction.</p><p>Because the disk writes are sequential the LSM-tree can support remarkably high write throughput.</p><h5 id="Summary">Summary</h5><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/dmlWriteProcess.png" alt="Memtable &amp; SSTable (Sorted String Table)"></p><p>Some conventions:</p><ul><li><strong>On-disk <code>SSTable</code> indexes are always loaded into memory</strong></li><li><strong>All writes go directly to the <code>MemTable</code> index</strong></li><li><strong>Reads check the MemTable first and then the SSTable indexes</strong></li><li>Periodically, the MemTable is flushed to disk as an SSTable</li><li>Periodically, on-disk SSTables are “collapsed together”</li></ul><p>对于一个写操作：</p><ul><li>先向 WAL 日志中写入，再向 memtable 中写入数据。</li><li>当 memtable 的大小达到一个阈值时，就把整个 memtable 写入到磁盘并清空日志，重新初始化一个 memtable 用于处理后续的写操作。</li></ul><p>对于一个读操作：</p><ul><li>先在 memtable 中查找</li><li>如果未找到，就按照从新到旧的顺序在 SSTable 文件中查找<ul><li>每个 SSTable 在内存中都有对应的索引，通过索引去找对应的一个小范围，然后遍历磁盘中文件的对应范围，确定数据是否存在</li><li>如果不存在，就去查找下一个比较旧的 SSTable</li></ul></li></ul><p>分析之后可以发现，由于 key 可能不存在，就会查找多个 SSTable，造成大量极慢的读磁盘的操作。针对每一个 SSTable，除了在内存中维护它的 sparse index, 我们还可以在内存中维护一个 bloom filter, 用于快速确定该 SSTable 中是否包含此数据。</p><p>引入此优化后，理想情况下一个读操作只需要一次磁盘读写即可完成。</p><h3 id="B-Trees">B-Trees</h3><p>The most widely used indexing structure is quite different: the B-tree.</p><p>By contrast, B-trees break the database down into fixed-size blocks or pages, traditionally 4 KB in size (sometimes bigger), and read or write one page at a time.</p><p>In order to make the database resilient to crashes, it is common for B-tree implementations to include an additional data structure on disk: a write-ahead log (WAL, also known as a redo log). This is an append-only file to which <strong>every B-tree modification must be written before it can be applied to the pages</strong> of the tree itself. When the database comes back up after a crash, this log is used to restore the B-tree back to a consistent state.</p><h3 id="Comparing-B-Trees-and-LSM-Trees">Comparing B-Trees and LSM-Trees</h3><p>As a rule of thumb, <strong>LSM-trees are typically faster for writes, whereas B-trees are thought to be faster for reads</strong>.<br>Reads are typically slower on LSM-trees because they have to check several different data structures and SSTables at different stages of compaction.</p><h4 id="Advantages-of-LSM-trees">Advantages of LSM-trees</h4><p>A B-tree index must write every piece of data at least twice: once to the write-ahead log, and once to the tree page itself (and perhaps again as pages are split).</p><p>Log-structured indexes also rewrite data multiple times due to repeated compaction and merging of SSTables. This effect — one write to the database resulting in multiple writes to the disk over the course of the database’s lifetime — is known as <em>write amplification</em>. It is of particular concern on SSDs, which can only overwrite blocks a limited number of times before wearing out.</p><p>Moreover, LSM-trees are typically able to sustain higher write throughput than B-trees, partly because they sometimes have <strong>lower write amplification</strong>, and partly because they <strong>sequentially write</strong> compact SSTable files rather than having to overwrite several pages in the tree.</p><p>Since LSM-trees are not page-oriented and periodically rewrite SSTables to remove fragmentation, they have lower storage overheads, especially when using leveled compaction</p><h4 id="Downsides-of-LSM-trees">Downsides of LSM-trees</h4><p>A downside of log-structured storage is that the compaction process can sometimes interfere with the performance of ongoing reads and writes.</p><p>The impact on throughput and average response time is usually small, but at higher percentiles the response time of queries to log-structured storage engines can sometimes be quite high, and B-trees can be more predictable.</p><p>If write throughput is high and compaction is not configured carefully, it can happen that compaction cannot keep up with the rate of incoming writes. In this case, the number of unmerged segments on disk keeps growing until you run out of disk space, and reads also slow down because they need to check more segment files.</p><h3 id="Keeping-everything-in-memory">Keeping everything in memory</h3><p>Counterintuitively, the performance advantage of in-memory databases is not due to the fact that they don’t need to read from disk. Even a disk-based storage engine may never need to read from disk if you have enough memory, because the operating system caches recently used disk blocks in memory anyway. Rather, they can be faster because they can <strong>avoid the overheads of encoding in-memory data structures in a form that can be written to disk.</strong></p><p>Besides performance, another interesting area for in-memory databases is providing data models that are difficult to implement with disk-based indexes. For example, Redis offers a database-like interface to various data structures such as priority queues and sets. Because it keeps all data in memory, its implementation is comparatively simple.</p><h2 id="Transaction-Processing-or-Analytics">Transaction Processing or Analytics?</h2><p>这一节也很有意思，数据库大体上可以分为两种用途：transaction processing and data analytics.</p><blockquote><p>Transaction processing just means allowing clients to make low-latency reads and writesas opposed to batch processing jobs, which only run periodically (for example, once per day).</p></blockquote><p>An application typically looks up a small number of records by some key, using an index. Records are inserted or updated based on the user’s input. Because these applications are interactive, the access pattern became known as online transaction processing (OLTP).</p><p>However, databases also started being increasingly used for data analytics, which has very different access patterns. Usually an analytic query needs to scan over a huge number of records, only reading a few columns per record, and calculates aggregate statistics (such as count, sum, or average) rather than returning the raw data to the user.</p><p>In order to differentiate this pattern of using databases from transaction processing, it has been called online analytic processing (OLAP).</p><p>两者还是有很大不同的：</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231020221030359.png" alt="image-20231020221030359"></p><h3 id="Data-Warehousing">Data Warehousing</h3><p>专门针对数据分析的数据库被叫做数据仓库。</p><p>A data warehouse, by contrast, is a separate database that analysts can query to their hearts’ content, without affecting OLTP operations. The data warehouse contains a read-only copy of the data in all the various OLTP systems in the company.</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231020221221532.png" alt="image-20231020221221532"></p><p>Many data warehouses are used in a fairly formulaic style, known as a star schema (also known as dimensional modeling).</p><p>Example:</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231020221306520.png" alt="image-20231020221306520"></p><p>As each row in the fact table represents an event, the dimensions represent the <em>who</em>, <em>what</em>, <em>where</em>, <em>when</em>, <em>how</em>, and <em>why</em> of the event.</p><p>The name “star schema” comes from the fact that when the table relationships are visualized, the fact table is in the middle, surrounded by its dimension tables; the connections to these tables are like the rays of a star.</p><h3 id="Column-Oriented-Storage">Column-Oriented Storage</h3><p>数据仓库存储的数据有以下特点：</p><ul><li>数量多</li><li>Fact table 的列非常多</li></ul><p>查询的特点是：</p><ul><li>查询所有数据</li><li>只访问其中的几列</li></ul><p>In most OLTP databases, storage is laid out in a row-oriented fashion: all the values from one row of a table are stored next to each other. Document databases are similar: an entire document is typically stored as one contiguous sequence of bytes.</p><p>The idea behind column-oriented storage is simple: don’t store all the values from one row together, but store all the values from each column together instead. If each column is stored in a separate file, a query only needs to read and parse those columns that are used in that query, which can save a lot of work.</p><p><img src="https://kkkzoz-1304409899.cos.ap-chengdu.myqcloud.com/img/image-20231020222218346.png" alt="image-20231020222218346"></p><h3 id="Summary-2">Summary</h3><p>There are big differences between the access patterns in those use cases:</p><ul><li>OLTP systems are typically user-facing, which means that they may see a huge volume of requests. In order to handle the load, applications usually only touch a small number of records in each query. The application requests records using some kind of key, and the storage engine uses an index to find the data for the requested key. Disk seek time is often the bottleneck here.</li><li>Data warehouses and similar analytic systems are less well known, because they are primarily used by business analysts, not by end users. They handle a much lower volume of queries than OLTP systems, but each query is typically very demanding, requiring many millions of records to be scanned in a short time. Disk bandwidth (not seek time) is often the bottleneck here, and columnoriented storage is an increasingly popular solution for this kind of workload.</li></ul>]]></content>
    
    
    <categories>
      
      <category>Design Data-Intensive Applications</category>
      
    </categories>
    
    
    <tags>
      
      <tag>BookNote</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
